@inproceedings{Arfib2002,
  author = {Arfib, Daniel and Dudon, Jacques},
  title = {A Digital Emulator of the Photosonic Instrument},
  pages = {1--4},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176388},
  url = {http://www.nime.org/proceedings/2002/nime2002_001.pdf},
  keywords = {Photosonic synthesis, digital emulation, Max-Msp, gestural devices.},
  abstract = {In this paper we describe the digital emulation of a optical photosonic instrument. First we briefly describe theoptical instrument which is the basis of this emulation.Then we give a musical description of the instrument implementation and its musical use and we concludewith the "duo" possibility of such an emulation.}
}

@inproceedings{Baumann2002,
  author = {Baumann, Alain and S\'{a}nchez, Rosa},
  title = {Interdisciplinary Applications of New Instruments},
  pages = {5--9},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176390},
  url = {http://www.nime.org/proceedings/2002/nime2002_005.pdf},
  keywords = {interdisciplinary applications of new instruments, mixed media instruments},
  abstract = {In this paper we will have a short overview of some of the systems we have been developing as an independent company over the last years. We will focus especially on our latest experiments in developing wireless gestural systems using the camera as an interactive tool to generate 2D and 3D visuals and music. }
}

@inproceedings{Bernard2002,
  author = {Bernard, David},
  title = {Experimental Controllers for Live Electronic Music Performance (vs. Copyright).},
  pages = {10--11},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176392},
  url = {http://www.nime.org/proceedings/2002/nime2002_010.pdf},
  keywords = {Live electronic music, experimental instruments, MIDI controllers, audio-visual synchronisation, copyright, SKINS digital hand drum.},
  abstract = {This paper describes the design and development of several musical instruments and MIDI controllers built byDavid Bernard (as part of The Sound Surgery project:www.thesoundsurgery.co.uk) and used in club performances around Glasgow during 1995-2002. It argues that changing technologies and copyright are shifting ourunderstanding of music from "live art" to "recorded medium" whilst blurring the boundaries between sound and visual production.}
}

@inproceedings{Blaine2002,
  author = {Blaine, Tina and Forlines, Clifton},
  title = {JAM-O-WORLD: Evolution of the Jam-O-Drum Multi-player Musical Controller into the Jam-O-Whirl Gaming Interface},
  pages = {12--17},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176394},
  url = {http://www.nime.org/proceedings/2002/nime2002_012.pdf},
  keywords = {Collaboration, computer graphics, embedded sensors, gaming controller, immersive musical gaming experiences, musical controller, multi-player, novice, social interaction.},
  abstract = {This paper discusses the Jam-O-Drum multi-player musical controller and its adaptation into a gaming controller interface known as the Jam-O-Whirl. The Jam-O-World project positioned these two controller devices in a dedicated projection environment that enabled novice players to participate in immersive musical gaming experiences. Players' actions, detected via embedded sensors in an integrated tabletop surface, control game play, real-time computer graphics and musical interaction. Jam-O-World requires physical and social interaction as well as collaboration among players. }
}

@inproceedings{Bongers2002,
  author = {Bongers, Bert and Harris, Yolande},
  title = {A Structured Instrument Design Approach: The Video-Organ},
  pages = {18--23},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176396},
  url = {http://www.nime.org/proceedings/2002/nime2002_018.pdf},
  abstract = {The Video-Organ is an instrument for the live performance of audio-visual material. To design an interface we apply a modular approach, in an attempt to split up the complex task of finding physical interfaces and mappings to control sound and video as generated by the computer. Generally, most modules, or instrumentlets as they are called, consist of a human interface element mapped to a certain effect. To describe the instrumentlets a design space is used consisting of the parameters degrees of freedom, range and precision. This paper is addressing the notion that traditional approaches to composition are challenged and changed in this situation, where the material is both audio and visual, and where the design and development of an instrument becomes involved in the process of performing and composing.}
}

@inproceedings{Burtner2002,
  author = {Burtner, Matthew},
  title = {Noisegate 67 for Metasaxophone: Composition and Performance Considerations of a New Computer Music Controller},
  pages = {24--29},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176398},
  url = {http://www.nime.org/proceedings/2002/nime2002_024.pdf},
  abstract = {Noisegate 67 was the first fully interactive composition written for the Computer Metasaxophone, a new computer controller interface for electroacoustic music. The Metasaxophone is an acoustic tenor saxophone retrofitted with an onboard computer microprocessor and an array of sensors that convert performance data into MIDI control messages. While maintaining full acoustic functionality the Metasaxophone is a versatile MIDI controller. This paper discusses the compositionally driven technical and aesthetic concerns that went into building the Metasaxophone, and the resulting aesthetic implementations in Noisegate 67. By juxtaposing the compositional approach to the saxophone before and after the electronic enhancements an attempt is made to expose working paradigms of composition for metainstruments.}
}

@inproceedings{Camurri2002,
  author = {Camurri, Antonio and Trocca, Riccardo and Volpe, Gualtiero},
  title = {Interactive Systems Design: A KANSEI-based Approach},
  pages = {30--37},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176400},
  url = {http://www.nime.org/proceedings/2002/nime2002_030.pdf},
  abstract = {This paper presents some our recent research on computational models and algorithms for real-time analysis of full-body human movement. The focus here is on techniques to extract in real-time expressive cues relevant to KANSEI and emotional content in human expressive gesture, e.g., in dance and music performances. Expressive gesture can contribute to new perspectives for the design of interactive systems. The EyesWeb open software platform is a main concrete result from our research work. EyesWeb is used in interactive applications, including music and other artistic productions, museum interactive exhibits, therapy and rehabilitation, based on the paradigm of expressive gesture. EyesWeb is freely available from www.eyesweb.org.}
}

@inproceedings{Chadabe2002,
  author = {Chadabe, Joel},
  title = {The Limitations of Mapping as a Structural Descriptive in Electronic Instruments},
  pages = {38--42},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176402},
  url = {http://www.nime.org/proceedings/2002/nime2002_038.pdf},
  keywords = {mapping fly-by-wire algorithmic network interactivity instrument deterministic indeterministic},
  abstract = {Mapping, which describes the way a performer's controls are connected to sound variables, is a useful concept when applied to the structure of electronic instruments modelled after traditional acoustic instruments. But mapping is a less useful concept when applied to the structure of complex and interactive instruments in which algorithms generate control information. This paper relates the functioning and benefits of different types of electronic instruments to the structural principles on which they are based. Structural models of various instruments will be discussed and musical examples played. }
}

@inproceedings{Couturier2002,
  author = {Couturier, Jean-Michel},
  title = {A Scanned Synthesis Virtual Instrument},
  pages = {43--45},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176404},
  url = {http://www.nime.org/proceedings/2002/nime2002_043.pdf},
  keywords = {graphics tablet, meta-parameters, multi-touch tactile surface, scanned synthesis},
  abstract = {This paper describes a virtual musical instrument based on the scanned synthesis technique and implemented in Max-Msp. The device is composed of a computer and three gesture sensors. The timbre of the produced sound is rich and changing. The instrument proposes an intuitive and expressive control of the sound thanks to a complex mapping between gesture and sound. }
}

@inproceedings{DArcangelo2002,
  author = {D'Arcangelo, Gideon},
  title = {Creating a Context for Musical Innovation: A NIME Curriculum},
  pages = {46--49},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176406},
  url = {http://www.nime.org/proceedings/2002/nime2002_046.pdf},
  keywords = {creative expression, input devices, musical controllers},
  abstract = {This paper presents the approaches and expectations of a recently launched course at New York University (NYU) in the design and development of musical controllers. The framework for the course, which is also entitled "New Interfaces for Musical Expression," is largely based on the proceedings of the first NIME workshop held in Seattle, WA in April 2001.}
}

@inproceedings{Fels2002,
  author = {Fels, Sidney S. and Vogt, Florian},
  title = {Tooka: Explorations of Two Person Instruments},
  pages = {50--55},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176408},
  url = {http://www.nime.org/proceedings/2002/nime2002_050.pdf},
  keywords = {Two person musical instruments, intimacy, human-human communication, cooperative music, passive haptic interface},
  abstract = {In this paper we describe three new music controllers, each designed to be played by two players. As the intimacy between two people increases so does their ability to anticipate and predict the other's actions. We hypothesize that this intimacy between two people can be used as a basis for new controllers for musical expression. Looking at ways people communicate non-verbally, we are developing three new instruments based on different communication channels. The Tooka is a hollow tube with a pressure sensor and buttons for each player. Players place opposite ends in their mouths and modulate the pressure in the tube with their tongues and lungs, controlling sound. Coordinated button presses control the music as well. The Pushka, yet to be built, is a semirigid rod with strain gauges and position sensors to track the rod's position. Each player holds opposite ends of the rod and manipulates it together. Bend, end point position, velocity and acceleration and torque are mapped to musical parameters. The Pullka, yet to be built, is simply a string attached at both ends with two bridges. Tension is measured with strain gauges. Players manipulate the string tension at each end together to modulate sound. We are looking at different musical mappings appropriate for two players.}
}

@inproceedings{Ferris2002,
  author = {Ferris, Kieran and Bannon, Liam},
  title = {The Musical Box Garden},
  pages = {56--58},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176410},
  url = {http://www.nime.org/proceedings/2002/nime2002_056.pdf},
  keywords = {Education, play, augmented reality, pervasive computing, disappearing computer, assembly, cardboard box},
  abstract = {The Cardboard Box Garden (CBG) originated from a dissatisfaction with current computer technology as it is presented to children. This paper shall briefly review the process involved in the creation of this installation, from motivation through to design and subsequent implementation and user experience with the CBG. Through the augmentation of an everyday artefact, namely the standard cardboard box, a simple yet powerful interactive environment was created that has achieved its goal of stirring childrens imagination judging from the experience of our users. }
}

@inproceedings{Flety2002,
  author = {Fl\'{e}ty, Emmanuel},
  title = {AtoMIC Pro: a Multiple Sensor Acquisition Device},
  pages = {59--64},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176412},
  url = {http://www.nime.org/proceedings/2002/nime2002_059.pdf},
  keywords = {Gestural controller, Sensor, MIDI, Music. Solution for Multi-sensor Acquisition},
  abstract = {Research and musical creation with gestural-oriented interfaces have recently seen a renewal of interest and activity at Ircam [1][2]. In the course of several musical projects, undertaken by young composers attending the one-year Course in Composition and Computer Music or by guests artists, Ircam Education and Creation departments have proposed various solutions for gesture-controlled sound synthesis and processing. In this article, we describe the technical aspects of AtoMIC Pro, an Analog to MIDI converter proposed as a re-usable solution for digitizing several sensors in different contexts such as interactive sound installation or virtual instruments.The main direction of our researches, and of this one in particular, is to create tools that can be fully integrated into an artistic project as a real part of the composition and performance processes.}
}

@inproceedings{Gadd2002,
  author = {Gadd, Ashley and Fels, Sidney S.},
  title = {MetaMuse: Metaphors for Expressive Instruments},
  pages = {65--70},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176414},
  url = {http://www.nime.org/proceedings/2002/nime2002_065.pdf},
  keywords = {Expressive interface, transparency, metaphor, prop-based controller, granular synthesis.},
  abstract = {We explore the role that metaphor plays in developing expressive devices by examining the MetaMuse system. MetaMuse is a prop-based system that uses the metaphor of rainfall to make the process of granular synthesis understandable. We discuss MetaMuse within a framework we call ''transparency'' that can be used as a predictor of the expressivity of musical devices. Metaphor depends on a literature,or cultural basis, which forms the basis for making transparent device mappings. In this context we evaluate the effect of metaphor in the MetaMuse system.}
}

@inproceedings{Griffith2002,
  author = {Griffith, Niall J. and O'Leary, Sean and O'Shea, Donagh and Hammond, Ed and O'Modhrain, Sile},
  title = {Circles and Seeds: Adapting Kpelle Ideas about Music Performance for Collaborative Digital Music performance},
  pages = {71--72},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176416},
  url = {http://www.nime.org/proceedings/2002/nime2002_071.pdf},
  keywords = {Collaboration, Performance, Metaphor, Gesture},
  abstract = {The use of free gesture in making music has usually been confined to instruments that use direct mappings between movement and sound space. Here we demonstrate the use of categories of gesture as the basis of musical learning and performance collaboration. These are used in a system that reinterprets the approach to learning through performance that is found in many musical cultures and discussed here through the example of Kpelle music. }
}

@inproceedings{Gunther2002,
  author = {Gunther, Eric and Davenport, Glorianna and O'Modhrain, Sile},
  title = {Cutaneous Grooves: Composing for the Sense of Touch},
  pages = {73--79},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176418},
  url = {http://www.nime.org/proceedings/2002/nime2002_073.pdf},
  keywords = {multi-modal,music,tactile composition,vibrotactile},
  abstract = {This paper presents a novel coupling of haptics technology and music, introducing the notion of tactile composition or aesthetic composition for the sense of touch. A system that facilitates the composition and perception of intricate, musically structured spatio-temporal patterns of vibration on the surface of the body is described. An initial test of the system in a performance context is discussed. The fundamental building blocks of a compositional language for touch are considered. }
}

@inproceedings{Hankins2002,
  author = {Hankins, Tim and Merrill, David and Robert, Jocelyn},
  title = {Circular Optical Object Locator},
  pages = {80--81},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176420},
  url = {http://www.nime.org/proceedings/2002/nime2002_080.pdf},
  keywords = {Input devices, music controllers, collaborative, real-time score manipulation.},
  abstract = {The Circular Optical Object Locator is a collaborative and cooperative music-making device. It uses an inexpensive digital video camera to observe a rotating platter. Opaque objects placed on the platter are detected by the camera during rotation. The locations of the objects passing under the camera are used to generate music. }
}

@inproceedings{Hasan2002,
  author = {Hasan, Leila and Yu, Nicholas and Paradiso, Joseph A.},
  title = {The Termenova : A Hybrid Free-Gesture Interface},
  pages = {82--87},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176422},
  url = {http://www.nime.org/proceedings/2002/nime2002_082.pdf},
  keywords = {Theremin, gesture interface, capacitive sensing, laser harp, optical proximity sensing, servo control, musical controller},
  abstract = {We have created a new electronic musical instrument, referred to as the Termenova (Russian for "daughter of Theremin") that combines a free-gesture capacitive sensing device with an optical sensing system that detects the reflection of a hand when it intersects a beam of an array of red lasers. The laser beams, which are made visible by a thin layer of theatrical mist, provide visual feedback and guidance to the performer to alleviate the difficulties of using a non-contact interface as well as adding an interesting component for the audience to observe. The system uses capacitive sensing to detect the proximity of the player's hands; this distance is mapped to pitch, volume, or other continuous effect. The laser guide positions are calibrated before play with position controlled servo motors interfaced to a main controller board; the location of each beam corresponds to the position where the performer should move his or her hand to achieve a pre-specified pitch and/or effect. The optical system senses the distance of the player's hands from the source of each laser beam, providing an additional dimension of musical control. }
}

@inproceedings{Hunt2002,
  author = {Hunt, Andy D. and Wanderley, Marcelo M. and Paradis, Matthew},
  title = {The importance of Parameter Mapping in Electronic Instrument Design},
  pages = {88--93},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176424},
  url = {http://www.nime.org/proceedings/2002/nime2002_088.pdf},
  keywords = {electronic musical instruments,human-computer interaction,mapping strategies},
  abstract = {In this paper we challenge the assumption that an electronic instrument consists solely of an interface and a sound generator. We emphasise the importance of the mapping between input parameters and system parameters, and claim that this can define the very essence of an instrument.}
}

@inproceedings{Huott2002,
  author = {Huott, Robert},
  title = {An Interface for Precise Musical Control},
  pages = {94--98},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176428},
  url = {http://www.nime.org/proceedings/2002/nime2002_094.pdf},
  keywords = {musical controller, Tactex, tactile interface, tuning systems},
  abstract = {This paper is a design report on a prototype musical controller based on fiberoptic sensing pads from Tactex Controls [8]. It will discuss elements of form factor, technical design, and tuning/sound generation systems tested while building the device I have dubbed 'the Ski'. The goal is the creation of a fine musical instrument with which a skilled performer can play music from standard repertoire as well as break sonic ground in modern forms.}
}

@inproceedings{Magnusson2002,
  author = {Magnusson, Thor},
  title = {IXI software},
  pages = {101--101},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176384},
  url = {http://www.nime.org/proceedings/2002/nime2002_101.pdf},
  keywords = {Further info on our website http//www.ixi-software.net.},
  abstract = {We are interested in exhibiting our programs at your demo section at the conference. We believe that the subject of your conference is precisely what we are experimenting with in our musical software. }
}

@inproceedings{Jorda2002,
  author = {Jord\`{a}, Sergi},
  title = {Afasia: the Ultimate Homeric One-man-multimedia-band},
  pages = {102--107},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176432},
  url = {http://www.nime.org/proceedings/2002/nime2002_102.pdf},
  keywords = {Multimedia interaction, musical robots, real-time musical systems.},
  abstract = {In this paper we present Afasia, an interactive multimedia performance based in Homer's Odyssey [2]. Afasia is a one-man digital theater play in which a lone performer fitted with a sensor-suit conducts, like Homer, the whole show by himself, controlling 2D animations, DVD video and conducting the music mechanically performed by a robot quartet. After contextualizing the piece, all of its technical elements, starting with the hardware input and output components, are described. A special emphasis is given to the interactivity strategies and the subsequent software design. Since its first version premiered in Barcelona in 1998, Afasia has been performed in many European and American countries and has received several international awards. }
}

@inproceedings{Kapur2002,
  author = {Kapur, Ajay and Essl, Georg and Davidson, Philip L. and Cook, Perry R.},
  title = {The Electronic Tabla Controller},
  pages = {108--112},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176434},
  url = {http://www.nime.org/proceedings/2002/nime2002_108.pdf},
  keywords = {Electronic Tabla, Indian Drum Controller, Physical Models, Graphical Feedback},
  abstract = {This paper describes the design of an electronic Tabla controller. The E-Tabla controls both sound and graphics simultaneously. It allows for a variety of traditional Tabla strokes and new performance techniques. Graphical feedback allows for artistical display and pedagogical feedback. }
}

@inproceedings{Kessous2002,
  author = {Kessous, Lo\''{\i}c},
  title = {Bi-manual Mapping Experimentation, with Angular Fundamental Frequency Control and Sound Color Navigation},
  pages = {113--114},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176436},
  url = {http://www.nime.org/proceedings/2002/nime2002_113.pdf},
  keywords = {Bi-manual, off-the-shelf input devices, fundamental frequency control, sound color navigation, mapping.},
  abstract = {In this paper, we describe a computer-based solo musical instrument for live performance. We have adapted a Wacom graphic tablet equipped with a stylus transducer and a game joystick to use them as a solo expressive instrument. We have used a formant-synthesis model that can produce a vowel-like singing voice. This instrument allows multidimensional expressive fundamental frequency control and vowel articulation. The fundamental frequency angular control used here allows different mapping adjustments that correspond to different melodic styles. }
}

@inproceedings{Machover2002,
  author = {Machover, Tod},
  title = {Instruments, Interactivity, and Inevitability},
  pages = {115--115},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176438},
  url = {http://www.nime.org/proceedings/2002/nime2002_115.pdf},
  abstract = {It is astonishing to think that a mere twenty years ago, real-time music production and performance was not only in a fledgling state with only primitive (such as the IRCAM 4X machine) or limited (like the Synclavier) capabilities, but was also the subject of very heated debate. At IRCAM in the early 1980's, for instance, some (such as Luciano Berio) questioned whether any digital technology could ever be truly "instrumental", while others (such as Jean-Claude Risset) doubted whether real-time activity of any sort would ever acquire the richness and introspection of composition.}
}

@inproceedings{Mandelis2002,
  author = {Mandelis, James},
  title = {Adaptive Hyperinstruments: Applying Evolutionary Techniques to Sound Synthesis and Performance},
  pages = {116--117},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176440},
  url = {http://www.nime.org/proceedings/2002/nime2002_116.pdf},
  keywords = {adaptive interfaces, artificial life,expressivity, hyperinstruments, live performance, motion-to-sound mapping, selective breeding, sound meta-synthesis},
  abstract = {This paper describes the Genophone [2], a hyperinstrument developed for Sound-Performance-Design using the evolutionary paradigm of selective breeding as the driving process. Sound design, and control assignments (performance mappings), on most current systems rely heavily on an intimate knowledge of the Sound Synthesis Techniques (SSTs) employed by the sound generator (hardware or software based). This intimate knowledge can only be achieved by investing long periods of time playing around with sounds and experimenting with how parameters change the nature of the sounds produced. This experience is also needed when control mappings are defined for performance purposes, so external stimuli can effect changes in SST parameters. Often such experience can be gained after years of interaction with one particular SST. The system presented here attempts to aid the user in designing performance sounds and mappings without the necessity for deep knowledge of the SSTs involved. This is achieved by a selective breeding process on populations of individual sounds and their mapping. The initial populations are made up of individuals of existing hand-coded sounds and their mapping. Initial populations never have randomly derived individuals (this is not an issue as man's best friend was also not selectively bred from protozoa). The user previews the population then expresses how much individuals are liked by their relative repositioning on the screen (fitness). Some individuals are selected as parents to create a new population of offspring, through variable mutation and genetic recombination. These operators use the fitness as a bias for their function, and they were also successfully used in MutaSynth [1]. The offspring are then evaluated (as their parents were) and selected for breeding. This cycle continues until satisfactory sounds and their mapping are reached. Individuals can also be saved to disk for future "strain" development. The aim of the system is to encourage the creation of novel performance mappings and sounds with emphasis on exploration, rather than designs that satisfy specific a priori criteria.}
}

@inproceedings{Marshall2002,
  author = {Marshall, Mark T. and Rath, Matthias and Moynihan, Breege},
  title = {The Virtual Bodhran -- The Vodhran},
  pages = {118--119},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176442},
  url = {http://www.nime.org/proceedings/2002/nime2002_118.pdf},
  keywords = {Virtual instrument, sound modeling, gesture, user-centered design},
  abstract = {This paper introduces a subtle interface, which evolved from the design of an alternative gestural controller in the development of a performance interface. The conceptual idea used is based on that of the traditional Bodhran instrument, an Irish frame drum. The design process was user-centered and involved professional Bodhran players and through prototyping and user testing the resulting Vodhran emerged. }
}

@inproceedings{Mccaig2002,
  author = {Mccaig, Graeme and Fels, Sidney S.},
  title = {Playing on Heart-Strings: Experiences with the 2{H}earts System},
  pages = {120--125},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176444},
  url = {http://www.nime.org/proceedings/2002/nime2002_120.pdf},
  keywords = {Heart Rate, Biosensor, Interactive Music, Non-Verbal Communication, Affective Computing, Ambient Display},
  abstract = {Here we present 2Hearts, a music system controlled bythe heartbeats of two people. As the players speak and touch, 2Hearts extracts meaningful variables from their heartbeat signals. These variables are mapped to musical parameters, conveying the changing patterns of tension and relaxation in the players' relationship. We describe the motivation for creating 2Hearts, observations from the prototypes that have been built, and principles learnt in the ongoing development process.}
}

@inproceedings{McElligott2002,
  author = {McElligott, Lisa and Dixon, Edward and Dillon, Michelle},
  title = {`PegLegs in Music' Processing the Effort Generated by Levels of Expressive Gesturing in Music},
  pages = {126--130},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176446},
  url = {http://www.nime.org/proceedings/2002/nime2002_126.pdf},
  keywords = {Gesture, weight distribution, effort, expression, intent, movement, 3D sensing pressure, force, sensor, resolution, control device, sound, music, input.},
  abstract = {In this paper we discuss the possibility of augmenting existing musical performance by using a novel sensing device termed 'PegLeg'. This device interprets the movements and motions of a musician during play by allowing the musician to manipulate a sensor in three dimensions. A force sensitive surface allows us to detect, interpret and interface the subtle but integral element of physical "effort" in music playing. This device is designed to extend the musicians control over any given instrument, granting an additional means of 'playing' that would previously have been impossible - granting an additional limb to extend their playing potential - a PegLeg...}
}

@inproceedings{Ng2002,
  author = {Ng, Kia},
  title = {Interactive Gesture Music Performance Interface},
  pages = {131--132},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176448},
  url = {http://www.nime.org/proceedings/2002/nime2002_131.pdf},
  keywords = {Gesture, Motion, Interactive, Performance, Music.},
  abstract = {This paper briefly describes a number of performance interfaces under the broad theme of Interactive Gesture Music (IGM). With a short introduction, this paper discusses the main components of a Trans-Domain Mapping (TDM) framework, and presents various prototypes developed under this framework, to translate meaningful activities from one creative domain onto another, to provide real-time control of musical events with physical movements. }
}

@inproceedings{Nichols2002,
  author = {Nichols, Charles},
  title = {The vBow: Development of a Virtual Violin Bow Haptic Human-Computer Interface},
  pages = {133--136},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176450},
  url = {http://www.nime.org/proceedings/2002/nime2002_133.pdf},
  keywords = {bow, controller, haptic, hci, interface, violin},
  abstract = {This paper describes the development of a virtual violin bow haptic human-computer interface, which senses bow position with encoders, to drive bowed-string physical model synthesis, while engaging servomotors, to simulate the haptic feedback of a violin bow on a string. Construction of the hardware and programming of the software are discussed, as well as the motivation for building the instrument, and its planned uses.}
}

@inproceedings{Oboe2002,
  author = {Oboe, Roberto and De Poli, Giovanni},
  title = {Multi-instrument Virtual Keyboard -- The MIKEY Project},
  pages = {137--142},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176452},
  url = {http://www.nime.org/proceedings/2002/nime2002_137.pdf},
  keywords = {Virtual mechanisms, dynamic simulation},
  abstract = {The design of a virtual keyboard, capable of reproducing the tactile feedback of several musical instruments is reported. The key is driven by a direct drive motor, which allows friction free operations. The force to be generated by the motor is calculated in real time by a dynamic simulator, which contains the model of mechanisms' components and constraints. Each model is tuned on the basis of measurements performed on the real system. So far, grand piano action, harpsichord and Hammond organ have been implemented successfully on the system presented here. }
}

@inproceedings{Paine2002,
  author = {Paine, Garth},
  title = {GESTATION},
  pages = {143--144},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176454},
  url = {http://www.nime.org/proceedings/2002/nime2002_143.pdf},
  keywords = {are your choice.},
  abstract = {Interactivity has become a major consideration in the development of a contemporary art practice that engages with the proliferation of computer based technologies. Keywords }
}

@inproceedings{Pardue2002,
  author = {Pardue, Laurel S. and Paradiso, Joseph A.},
  title = {Musical Navigatrics: New Musical Interactions with Passive Magnetic Tags},
  pages = {145--147},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176456},
  url = {http://www.nime.org/proceedings/2002/nime2002_145.pdf},
  keywords = {passive tag, position tracking, music sequencer interface},
  abstract = {Passive RF Tagging can provide an attractive medium for development of free-gesture musical interfaces. This was initially explored in our Musical Trinkets installation, which used magnetically-coupled resonant LC circuits to identify and track the position of multiple objects in real-time. Manipulation of these objects in free space over a read coil triggered simple musical interactions. Musical Navigatrics builds upon this success with new more sensitive and stable sensing, multi-dimensional response, and vastly more intricate musical mappings that enable full musical exploration of free space through the dynamic use and control of arpeggiatiation and effects. The addition of basic sequencing abilities also allows for the building of complex, layered musical interactions in a uniquely easy and intuitive manner. }
}

@inproceedings{Patten2002,
  author = {Patten, James and Recht, Ben and Ishii, Hiroshi},
  title = {Audiopad: A Tag-based Interface for Musical Performance},
  pages = {148--153},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176458},
  url = {http://www.nime.org/proceedings/2002/nime2002_148.pdf},
  keywords = {RF tagging, MIDI, tangible interfaces, musical controllers, object tracking},
  abstract = {We present Audiopad, an interface for musical performance that aims to combine the modularity of knob based controllers with the expressive character of multidimensional tracking interfaces. The performer's manipulations of physical pucks on a tabletop control a real-time synthesis process. The pucks are embedded with LC tags that the system tracks in two dimensions with a series of specially shaped antennae. The system projects graphical information on and around the pucks to give the performer sophisticated control over the synthesis process.}
}

@inproceedings{Wynnychuk2002,
  author = {Wynnychuk, Jordan and Porcher, Richard and Brajovic, Lucas and Brajovic, Marko and Platas, Nacho},
  title = {sutoolz 1.0 alpha : {3D} Software Music Interface},
  pages = {154--155},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176478},
  url = {http://www.nime.org/proceedings/2002/nime2002_154.pdf},
  keywords = {3D music interface, 3D sound, analogue input controllers, audio localization, audio visualization, digital architecture, hybrid environments, video game navigation},
  abstract = {The demo sutoolz 1.0 alpha is a 3D software interface for music performance. By navigating through a 3D virtual architecture the musician uses a set of 3D tools to interact with the virtual environment: gameplay zones, speaker volumes, speaker volume membranes, speaker navigation volumes and 3D multi-band FFT visualization systems.}
}

@inproceedings{Schnell2002,
  author = {Schnell, Norbert and Battier, Marc},
  title = {Introducing Composed Instruments, Technical and Musicological Implications},
  pages = {156--160},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176460},
  url = {http://www.nime.org/proceedings/2002/nime2002_156.pdf},
  keywords = {Instruments, musicology, composed instrument, Theremin, Martenot, interaction, streams, MAX.},
  abstract = {In this paper, we develop the concept of "composed instruments". We will look at this idea from two perspectives: the design of computer systems in the context of live performed music and musicological considerations. A historical context is developed. Examples will be drawn from recent compositions. Finally basic concepts from computer science will be examined for their relation ship to this concept. }
}

@inproceedings{Smyth2002,
  author = {Smyth, Tamara and Smith, Julius O.},
  title = {Creating Sustained Tones with the Cicada's Rapid Sequential Buckling Mechanism},
  pages = {24--27},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176462},
  url = {http://www.nime.org/proceedings/2002/nime2002_161.pdf},
  keywords = {Bioacoustics, Physical Modeling, Controllers, Cicada, Buckling mechanism.},
  abstract = {The cicada uses a rapid sequence of buckling ribs to initiate and sustain vibrations in its tymbal plate (the primary mechanical resonator in the cicada's sound production system). The tymbalimba, a music controller based on this same mechanism, has a row of 4 convex aluminum ribs (ason the cicada's tymbal) arranged much like the keys on a calimba. Each rib is spring loaded and capable of snapping down into a V-shape (a motion referred to as buckling), under the downward force of the user's finger. This energy generated by the buckling motion is measured by an accelerometer located under each rib and used as the input to a physical model.}
}

@inproceedings{Stanza2002,
  author = {Stanza},
  title = {Amorphoscapes \& Soundtoys},
  pages = {165--166},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176386},
  url = {http://www.nime.org/proceedings/2002/nime2002_165.pdf},
  abstract = {Amorphoscapes by Stanza are interactive, generative, audio visual, digital paintings and drawings created specifically for the internet. This is interactive art on the Internet, incorporating generative sounds and 3D imaging.}
}

@inproceedings{Johannes2002,
  author = {Johannes, Taelman},
  title = {A Low-cost Sonar for Unobtrusive Man-machine Interfacing},
  pages = {167--170},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176430},
  url = {http://www.nime.org/proceedings/2002/nime2002_167.pdf},
  keywords = {sonar},
  abstract = {This paper describes the hardware and the software of a computer-based doppler-sonar system for movement detection. The design is focused on simplicity and lowcost do-it-yourself construction. }
}

@inproceedings{Tanaka2002,
  author = {Tanaka, Atau and Knapp, Benjamin},
  title = {Multimodal Interaction in Music Using the Electromyogram and Relative Position Sensing},
  pages = {171--176},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176464},
  url = {http://www.nime.org/proceedings/2002/nime2002_171.pdf},
  keywords = {Human Computer Interaction, Musical Controllers, Electromyogram, Position Sensing, Sensor Instruments},
  abstract = {This paper describes a technique of multimodal, multichannel control of electronic musical devices using two control methodologies, the Electromyogram (EMG) and relative position sensing. Requirements for the application of multimodal interaction theory in the musical domain are discussed. We introduce the concept of bidirectional complementarity to characterize the relationship between the component sensing technologies. Each control can be used independently, but together they are mutually complementary. This reveals a fundamental difference from orthogonal systems. The creation of a concert piece based on this system is given as example. }
}

@inproceedings{Verplank2002,
  author = {Verplank, Bill and Gurevich, Michael and Mathews, Max},
  title = {THE PLANK: Designing a Simple Haptic Controller.},
  pages = {177--180},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176466},
  url = {http://www.nime.org/proceedings/2002/nime2002_177.pdf},
  keywords = {Haptics, music controllers, scanned synthesis.},
  abstract = {Active force-feedback holds the potential for precise and rapid controls. A high performance device can be built from a surplus disk drive and controlled from an inexpensive microcontroller. Our new design,The Plank has only one axis of force-feedback with limited range of motion. It is being used to explore methods of feeling and directly manipulating sound waves and spectra suitable for live performance of computer music.}
}

@inproceedings{Vogt2002,
  author = {Vogt, Florian and Mccaig, Graeme and Ali, Mir A. and Fels, Sidney S.},
  title = {Tongue `n' Groove: An Ultrasound based Music Controller},
  pages = {181--185},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176468},
  url = {http://www.nime.org/proceedings/2002/nime2002_181.pdf},
  keywords = {Tongue model, ultrasound, real-time, music synthesis, speech interface},
  abstract = {Here we propose a novel musical controller which acquires imaging data of the tongue with a two-dimensional medical ultrasound scanner. A computer vision algorithm extracts from the image a discrete tongue shape to control, in realtime, a musical synthesizer and musical effects. We evaluate the mapping space between tongue shape and controller parameters and its expressive characteristics.}
}

@inproceedings{Weinberg2002,
  author = {Weinberg, Gil and Aimi, Roberto and Jennings, Kevin},
  title = {The Beatbug Network -A Rhythmic System for Interdependent Group Collaboration},
  pages = {186--191},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176470},
  url = {http://www.nime.org/proceedings/2002/nime2002_186.pdf},
  keywords = {Interdependent Musical Networks, group playing, percussive controllers.},
  abstract = {The Beatbugs are hand-held percussive instruments that allow the creation, manipulation, and sharing of rhythmic motifs through a simple interface. When multiple Beatbugs are connected in a network, players can form large-scale collaborative compositions by interdependently sharing and developing each other's motifs. Each Beatbug player can enter a motif that is then sent through a stochastic computerized "Nerve Center" to other players in the network. Receiving players can decide whether to develop the motif further (by continuously manipulating pitch, timbre, and rhythmic elements using two bend sensor antennae) or to keep it in their personal instrument (by entering and sending their own new motifs to the group.) The tension between the system's stochastic routing scheme and the players' improvised real-time decisions leads to an interdependent, dynamic, and constantly evolving musical experience. A musical composition entitled "Nerve" was written for the system by author Gil Weinberg. It was premiered on February 2002 as part of Tod Machover's Toy Symphony [1] in a concert with the Deutsches Symphonie Orchester Berlin, conducted by Kent Nagano. The paper concludes with a short evaluative discussion of the concert and the weeklong workshops that led to it. }
}

@inproceedings{Wessel2002,
  author = {Wessel, David and Wright, Matthew and Schott, John},
  title = {Intimate Musical Control of Computers with a Variety of Controllers and Gesture Mapping Metaphors},
  pages = {192--194},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176472},
  url = {http://www.nime.org/proceedings/2002/nime2002_192.pdf},
  keywords = {Expressive control, mapping gestures to acoustic results, metaphors for musical control, Tactex, Buchla Thunder, digitizing tablets.},
  abstract = {In this demonstration we will show a variety of computer-based musical instruments designed for live performance. Our design criteria include initial ease of use coupled with a long term potential for virtuosity, minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control (OSC), and a variety of metaphors for musical control. }
}

@inproceedings{Wilkerson2002,
  author = {Wilkerson, Carr and Serafin, Stefania and Ng, Carmen},
  title = {The Mutha Rubboard Controller},
  pages = {195--198},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176474},
  url = {http://www.nime.org/proceedings/2002/nime2002_195.pdf},
  keywords = {MIDI controllers, computer music, Zydeco music, interactive music, electronic musical instrument, human computer interface, Louisiana heritage, physical modeling, bowl resonators.},
  abstract = {The Mutha Rubboard is a musical controller based on the rubboard, washboard or frottoir metaphor commonly used in the Zydeco music genre of South Louisiana. It is not onlya metamorphosis of a traditional instrument, but a modern bridge of exploration into a rich musical heritage. It uses capacitive and piezo sensing technology to output MIDI and raw audio data.This new controller reads the key placement in two parallel planes by using radio capacitive sensing circuitry expanding greatly on the standard corrugated metal playing surface. The percussive output normally associated with the rubboard is captured through piezo contact sensors mounted directly on the keys (the playing implements). Additionally,mode functionality is controlled by discrete switching on the keys.This new instrument is meant to be easily played by both experienced players and those new to the rubboard. It lends itself to an expressive freedom by placing the control surface on the chest and allowing the hands to move uninhibited about it or by playing it in the usual way, preserving its musical heritage.}
}

@inproceedings{Winkler2002,
  author = {Winkler, Todd},
  title = {Fusing Movement, Sound, and Video in Falling Up, an Interactive Dance/Theatre Production},
  pages = {199--200},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176476},
  url = {http://www.nime.org/proceedings/2002/nime2002_199.pdf},
  keywords = {Dance, Video processing, Movement sensor, VNS, Very Nervous System},
  abstract = {Falling Up is an evening-length performance incorporating dance and theatre with movement-controlled audio/video playback and processing. The solo show is a collaboration between Cindy Cummings (performance) and Todd Winkler(sound, video), first performed at the Dublin Fringe Festival,2001. Each thematic section of the work shows a different typeof interactive relationship between movement, video and sound. This demonstration explains the various technical configurations and aesthetic thinking behind aspects of the work.}
}

@inproceedings{Young2002,
  author = {Young, Diana},
  title = {The Hyperbow Controller: Real-Time Dynamics Measurement of Violin Performance},
  pages = {201--206},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2002},
  date = {24-26 May, 2002},
  address = {Dublin, Ireland},
  issn = {2220-4806},
  doi = {10.5281/zenodo.1176480},
  url = {http://www.nime.org/proceedings/2002/nime2002_201.pdf},
  keywords = {Hyperbow, Hyperviolin, Hyperinstrument, violin, bow, position sensor, accelerometer, strain sensor},
  abstract = {In this paper, the design and construction of a new violin interface, the Hyperbow, is discussed. The motivation driving the research of this instrument was the desire to create a violin bow capable of measuring the most intricate aspects of violin techniquethe subtle elements of physical gesture that immediately and directly impact the sound of the instrument while playing. In order to provide this insight into the subtleties of bow articulation, a sensing system has been integrated into a commercial carbon fiber bow to measure changes in position, acceleration, and the downward and lateral strains of the bow stick. The sensors were fashioned using an electromagnetic field sensing technique, commercial MEMS accelerometers, and foil strain gauges. The measurement techniques used in this work were found to be quite sensitive and yielded sensors that were easily controllable by a player using traditional right hand bowing technique.}
}

