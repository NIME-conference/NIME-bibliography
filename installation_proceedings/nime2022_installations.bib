@inproceedings{nime20202_installations_1,
 abstract = {Interface Design is a flexible, site-specific installation that can be presented in more than one configuration. It plays with the idea of what we expect synthesizers to look like by obscuring the user interface. This installation consists of oscillator circuitry paired with different values of photoresistors hidden throughout a web of wires.},
 address = {Auckland, New Zealand},
 articleno = {1},
 track = {Installations},
 author = {Erin Demastes},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.af1e8a6e},
 issn = {2220-4806},
 month = {jun},
 title = {Interface Design},
 url = {https://doi.org/10.21428/92fbeb44.af1e8a6e},
 year = {2022}
}

@inproceedings{nime20202_installations_2,
 abstract = {A record of Mahasangha Vinaya translated in Taisho Triptaka (1425) reveals the intuition and early understanding of the concept and value of time — in multiple/ submultiple of 20, smallest unit, niàn (念) at 18 ms, shùnqǐng (瞬顷) at 360 ms, tánzhǐ (弹指) at 7200 ms, luóyù (罗豫) at 2 minutes 24 seconds, and xūyú (须臾) at 48 minutes. blink moment is an acoustic re-visioning of ancient time units mediated by mechatronic sound machines. This work utilizes ancient time units to formalize musical events and actuations timings of serraE, a novel mechatronic sound machine inspired by the Chinese yǔ (敔), an ancient scraper-class percussion used to indicate time in ancient Chinese court and ritual music . Through the re-visioning of ancient time units as musical time duration(s), blink moment demonstrates the relationship between elapsed time and sonic characteristics. The duration of the piece is 2’ 24” ( luóyù, 罗豫). niàn, shùnqǐng, and tánzhǐ were used as rhythmic time values for actuating the percussive hit as well as the radial rasping motion of serraE. This renders a stream of percussive and ratcheting tones, embellishing a constant tone of 55.5555 Hz sine wave (audification of niàn) generated by a loudspeaker. These acoustical renderings are juxtaposed against the ancient Chinese value of second at 144 ms (percussive tone by serraE), and the modern unit of second at 1000 ms (silent). The modern second is not acoustically manifested as the intuition of a modern second elapsing is assumed to be inherent. blink moment is part of a series of works for serraE to explore its creative affordances as a sound machine in different creative contexts.},
 address = {Auckland, New Zealand},
 articleno = {2},
 track = {Installations},
 author = {Jingyin He},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.7b6126a3},
 issn = {2220-4806},
 month = {jun},
 title = {Blink Moment},
 url = {https://doi.org/10.21428/92fbeb44.7b6126a3},
 year = {2022}
}

@inproceedings{nime20202_installations_3,
 abstract = {Based on my real-time line-based sonification engine developed in 2016, Colormatrics has been newly created as a set of three sonification-driven audiovisual works specially designed for Cylorama of the Cube at the Moss Arts Center, Virginia Tech in November 2021. Colormatrics converts generative visual patterns into sound and conversely visualizes the sonification process in real-time. First, Colormatrics_01 generates additive synthesis-based ambient- or pad-like sounds fitting in with the immersive atmosphere of the space. Second, Colormatrics_02 creates additive synthesis-based beat music following self-changing graphic patterns that become more complex. Those patterns have a total of 18 steps and will loop again when they reached the last. Lastly, Colormatrics_03 creates timbre by additive synthesis and spatializes sound where the vertical and horizontal positions of graphics are mapped into 128-speaker systems in the Cube. The number of sine waves for additive synthesis can be flexible depending on the image size, which also indicates the length of the scan line. For the color-sound mapping for each pixel, hue values are tuned for musical pitch, saturation values detune the original pitch up to -100 cents, and the brightness values determine amplitude levels. The visual scores generated in Processing are transmitted to Max/MSP via Syphon for sonification.},
 address = {Auckland, New Zealand},
 articleno = {3},
 track = {Installations},
 author = {Woohun Joo},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.e0105d02},
 issn = {2220-4806},
 month = {jun},
 title = {Sonifyd:Colormatrics},
 url = {https://doi.org/10.21428/92fbeb44.e0105d02},
 year = {2022}
}

@inproceedings{nime20202_installations_4,
 abstract = {Seis8s is a web-based computer language that allows real-time interaction with digital audio and localized musical knowledge. Seis8s revolves around keywords or commands that relate to Latin dance music –also known as urban Latin music or Latin popular music. This is a 20th-century derivation of music “based on Afro-Cuban and Afro-Caribbean rhythms, as developed and performed throughout the Hispanic Caribbean basis and its diaspora” and which is “designed for accompanying social dancing”. At the moment of writing, Seis8s revolves around Mexican cumbia and Salsa. Drawing from the digital-art practice of Live Coding , Seis8s is meant for the performer and the audience to experience not only the music but also the code that is displayed on the screen. The latter to help connect the users (i.e. performer and audience) with other cultural layers influencing computer-music languages, like natural language. Seis8s explores the following possibilities: 1) a computer-music language to be derived from Spanish; 2) to appeal to an imagined community in/from Latin America; and 3) to explore cultural, political, economic, and historical commonalities of that imagined community. Seis8s can be used online at the following interactive website: https://seis8s.org/. On this website, users are invited to experience Seis8s through examples and references both in Spanish and English.},
 address = {Auckland, New Zealand},
 articleno = {4},
 track = {Installations},
 author = {Luis N. Del Angel and David Ogborn},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.80a3fd71},
 issn = {2220-4806},
 month = {jun},
 title = {Seis8s: a web-based localized computer-music language},
 url = {https://doi.org/10.21428/92fbeb44.80a3fd71},
 year = {2022}
}

@inproceedings{nime20202_installations_5,
 abstract = {The proposed sound installation aims to investigate the relationship between humans and the environment through technology and music. Biodiversity loss is usually underlined as the result of climate change while mycorrhizae networks and phytoplankton are the main organisms responsible for carbon reduction (sequestration) and dependent on the protection of animals, land, and flora in their habitat. Similarly, these organisms have never attracted or common governmental sense attention as species for common good, not even as species under threat.  Our work on various colonies of micro individuals – i.e fungi (including mold) and algae,   as sourdough, mother of vinegar, food mold, and so on – underlines the external conditions that stress themselves and consequently our ecosystem. Every organism has a definite range of light, humidity, heat, and noise levels as ideal livable conditions. Beyond such levels, they respond with a stress reaction. In our work, the micro-level living organisms serve as a musical interface via a GSR (Galvanic Skin Response) sensor which is usually used to detect changes in human emotional states. With the GSR sensor, we can follow slight variations in electrical resistance in the environment that micro-organisms reside. An Arduino board collects the data from the sensor and transmits it to the computer with Python code. Remote OSC handles the sending of the data to the web-based sound installation platform. On the web application, the Csound-based digital instruments wait for the incoming data to perform sonification in real-time and in the browser without any audio streaming between the data source and audience. The audience goes to the URL of the web application and they will not need to install any software or make any changes to their computer/browser settings. The web app will also include the documentation of the project with images, video, and text.},
 address = {Auckland, New Zealand},
 articleno = {5},
 track = {Installations},
 author = {Serkan Sevilgen and Ipek Oskay},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.a6fa6498},
 issn = {2220-4806},
 month = {jun},
 title = {Sounding Microcosmos},
 url = {https://doi.org/10.21428/92fbeb44.a6fa6498},
 year = {2022}
}

@inproceedings{nime20202_installations_6,
 abstract = {Spectra is a mechatronic audiovisual work that explores the materiality of the audiovisual medium by investigating the intersections of sound and light. Spectra adds to an ongoing discourse around the emergent field of physical audiovisual works, contrasting the dominantly screen-based works that are often conceptualised and discussed as audiovisual. The work physically explores audiovisuality by investigating the commonalities of light and sound spectra, and how their respective spectra can be manipulated and controlled. The work features an array of modules, each with a fresnel lens, a mechatronic assemblage, a speaker, and a light source. In each module, pure white light is passed through the flexible fresnel lens which focuses light. A stepper motor attaches to one end of the lens, deforming it through rotation. As the lens is deformed and manipulated, it deconstructs the spectrum of white light, scattering it across space by creating chromatic aberrations. The nature of each aberration is driven by an audiovisual relationship, with each module using a sine tone to control the behaviour of its mechatronic assemblage. Together, the array creates a rich harmonic spectrum, with each of its partials made visible through its audiovisual representation. In doing so, the spectral qualities of sound are imposed onto light, allowing for a physical interplay of audiovisuality.},
 address = {Auckland, New Zealand},
 articleno = {6},
 track = {Installations},
 author = {Blake Johnston},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.caaa51ff},
 issn = {2220-4806},
 month = {jun},
 title = {Spectra},
 url = {https://doi.org/10.21428/92fbeb44.caaa51ff},
 year = {2022}
}

@inproceedings{nime20202_installations_7,
 abstract = {The proposed installation intends to display aurally the diversity of sounds of the Iguazu River located in the state of Paraná, south of Brasil. Through an interactive geolocalized soundmap hosted in: www.sonsdorioiguazu.art.br any participant can access and with the click of a mouse and hear a work composed out of the different audios recorded there. A text and an image will help contextualize each location for further understanding since there are some audio testimonies in Portuguese and Kaingang an indigenous language as well as other particular considerations such as level of water, meteorological conditions, organizations involved, among many others that are vital for the full understanding and enjoyment of the project.},
 address = {Auckland, New Zealand},
 articleno = {7},
 track = {Installations},
 author = {Jaime D. Rojas Vargas},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 editor = {Meg Schedel and Paul Dunham},
 doi = {10.21428/92fbeb44.5a9f62ad},
 issn = {2220-4806},
 month = {jun},
 title = {Soundmap of the Iguazu River},
 url = {https://doi.org/10.21428/92fbeb44.5a9f62ad},
 year = {2022}
}
