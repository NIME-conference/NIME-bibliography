@inproceedings{nime20-music-Tonagel,
  author = {Tonagel, Tina and Crumbach, Conny and Grundmann Gesine and Britta Fehrmann},
  title = {4 Women, 12 Legs. 120 DEN!},
  pages = {1-3},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350588},
  url = {http://www.nime.org/proceedings/2020/nime2020_music01.pdf},
  abstract = {The Cologne based ladies‘ quartet 120 DEN, founded in 2019, plays with modified mannequin legs, which become independent electronic instruments through guitar strings, contact microphones and built-in synthesizer elements. The resulting sounds range from subtle caresses to overflowing tapestries of sound, to knee-jerked death metal passages and conceptual electronic textures. The experimental leg sound is of course also supported orally.}
}

@inproceedings{nime20-music-Cadavid,
  author = {Cadavid, Laddy Patricia},
  title = {Knotting the memory//Encoding the khipu{\_}},
  pages = {4-7},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350594},
  url = {http://www.nime.org/proceedings/2020/nime2020_music02.pdf},
  abstract = {The khipu is an information processing and transmission device used mainly by the Inca empire and previous Andean societies. The word comes from the kichwa1 language [khipu] which means knot. This mnemotechnic interface, is one of the first textile computers known, consisting of a central wool or cotton cord to which other strings are attached with knots of different shapes, colors, and sizes encrypting different kinds of values and information. The system was widely used until the Spanish colonization that banned their use and destroyed a large number of these devices [1]. In the performance, the interface is reused as a NIME using new materials in an electronic khipu, paying homage to this device with the convert into an instrument for the interaction and generation of live experimental sound. Through the weaving of knots, the artist takes the position of a contemporary “khipukamayuq”(who was the person dedicated to knot the khipu) [3] seeking, from a decolonial perspective to encode with the touch, the gestures and the different kinds of knots, the interrupted legacy of this ancestral practice in a different experience of tangible live coding and computer music, as well as weave the past with the present of the indigenous and people resistance of the Andean territory with their sounds.}
}

@inproceedings{nime20-music-Shatin,
  author = {Shatin, Judith and Tfirn, Maxwell},
  title = {Zipper Music},
  pages = {8-9},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350604},
  url = {http://w ww.nime.org/proceedings/2020/nime2020_music03.pdf},
  abstract = {Zipper Music is scored for 2 amplified zipper players with interactive electronics performed by a MIDI controller operator. It forms part of my Quotidian Music series, embodying the musicality afforded by everyday sounds, and performable by ‘everyday’ people, without requiring traditional musical training. Each zipper has a distinctive timbre, depending on material and length, as well as the fabric to which it is sewn. The zipper players are amplified and the sound of each is sent to a laptop. Next, their sound is either transformed using a MIDI controller, or sent through untouched, to stereo speakers. Coomposer Max Tfirm developed the original Max patch in consultation with me, with some additional changes by Alex Christie. The piece can be thought of as a dialogue, where the actors may be in sync or not; may try to convince one another, interrupt one another, or even talk over one another. Ultimately, they agree. The premiere performance is linked below. This version is for 2 amplified zipper players and 2 MIDI controllers and was premiered by the University of Virginia New Music Ensemble with Danielle Zevitz and Tianyu Zhang as zipper players, and Alex Christie and Travis Thatcher on MIDI controllers. The duration is 8:00, a minute longer than your requested duration; the structure was built around this time frame.}
}

@inproceedings{nime20-music-Wang,
  author = {Wang, Chi},
  title = {Qin},
  pages = {10-11},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350619},
  url = {http://www.nime.org/proceedings/2020/nime2020_music04.pdf},
  abstract = {Qin is a real-time interactive composition of approximately eight minutes in duration for two custom-made performance control interfaces, custom software created in Max, and Kyma. Qin is a special symbol in Chinese culture and literature that is associated with delicacy, elegance, confidence, power, eloquence, and longing for communication. The symbol Qin appears in literature as early as the time that the Book of Songs was collected. Qin is also a Chinese instrument. Qin has been played since ancient times, and has traditionally been favored by scholars and appeared in literature as an instrument associated with the ancient Chinese philosopher Confucius. In my composition Qin, I took as inspiration the shape of the original Qin instrument and mapped some of the traditional functions on to my custom-made performance interface, replacing the traditional Qin performance techniques with newly developed techniques that draw the desired data from the controllers.}
}

@inproceedings{nime20-music-Hsu,
  author = {Hsu, Aurie},
  title = {String Song (2019) for amplified prepared kinetic sculpture and live electronics},
  pages = {12-13},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350624},
  url = {http://www.nime.org/proceedings/2020/nime2020_music05.pdf},
  abstract = {String Song is a guided improvisation for prepared kinetic sculpture and live electronics. The kinetic sculpture is a collaboration between the Aurie Hsu and sound artist, Kyle Hartzell. The sculpture integrates design elements of a violin, erhu (Chinese “spike fiddle”), and a hurdy gurdy in using motorized gears to draw a bowing mechanism across the strings. The instrument also features two sets of sympathetic strings to augment the registral range and resonance of the instrument. The various ways of playing the instrument - plucking, using a metal slide across the strings, actuating the sympathetic strings, mechanical bowing, and physically altering the bow pressure - serve as a sound source for live electronics that further expand the instrument. The duration of the piece is four and a half minutes.}
}

@inproceedings{nime20-music-Lucas,
  author = {Lucas, Alex and Leatham, Tim and Fitzpatrick, Eoin and McCord, Mary-Louise and Morgan, Daniel},
  title = {Split Point: The Piano Reimagined as an Inclusive Hyper-Instrument},
  pages = {14-15},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350634},
  url = {http://www.nime.org/proceedings/2020/nime2020_music06.pdf},
  abstract = {Split Point is a quiet ambient work which explores inclusion and constraint and the redistribution of musical processes in contemporary piano music. In a collaboration between inclusive music collective The Wired Ensemble and experimental pianist Alex Lucas, the piano is played collectively, over a network, through the use of reductionist, accessible interfaces. In this con guration, the piano is considered a hyper-instrument with parameters such as pitch, rhythm and timbre, split and redistributed amongst the group. We invite the audience to consider if it is musically interesting to split the piano in such a way and if an individual can communicate independent creative expression when using binary on-off controllers; a common goal in inclusive music.}
}

@inproceedings{nime20-music-Zhao,
  author = {Zhao, Yixuan},
  title = {Charon – For Guzheng, violin, samples, and live electronics},
  pages = {16},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350646},
  url = {http://www.nime.org/proceedings/2020/nime2020_music07.pdf},
  abstract = {Charon is a celestial body in the solar system. In a tide-locked state, it and Pluto gradually becoming synchronous rotation from different orbits and rotation rates due to the influence of tidal forces over a period of time. This work combines different sounds of Chinese instrument, Western instrument and Samples. Their process from struggle to integration is a metaphor that Charon is gradually affected by tidal forces. Technology in this work has created interaction among acoustic instruments, samples and sound effects. The connection among them develops the work. I believe that the tension and interaction are the fascination of the combination of sounds.}
}

@inproceedings{nime20-music-Robson,
  author = {Robson, Nicole and Ulfarsson Halldor},
  title = {Dual/Duel/Duet/for/with/halldorophone},
  pages = {17-20},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6350695},
  url = {http://www.nime.org/proceedings/2020/nime2020_music08.pdf},
  abstract = {The halldorophone is a cello-like, feedback instrument, developed over the past decade by Halldór Úlfarsson. The instrument is well-established in experimental music circles and gaining wider recognition thanks to it’s use by composer and cellist Hildur Guðnadóttir in film scores, including her Oscar nominated music for Joker (2019). The halldorophone utilises a simple system, whereby the vibration of each string is detected by a pickup, amplified and routed to a speaker embedded in the back of the instrument. By adding gain to individual strings in the feedback loop, the instrument’s response can become rapidly complex, potentially spinning out of control. While every musical performance of a piece is unique in some way and contingent on its particular moment and situation in time, the unstable nature of the halldorophone exacerbates this condition. Players describe the halldorophone as ‘unpredictable’, ‘very much alive’ and as [having] ‘its own ideas’, even tiny changes to their body position in performance might produce unexpected effects [5]. In this NIME premiere for the instrument, cellist Nicole Robson will perform a piece for a new digitally endowed halldorophone, and the title of the piece – Dual/Duel/Duet – acknowledges the active role of the instrument in shaping the composition and performance.}
}

@inproceedings{nime20-music-Pardue,
  author = {Pardue, Laurel and Armitage, Jack and Bhamra, Kuljit},
  title = {Petrified Wood - Untitled 59},
  pages = {21-23},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351037},
  url = {http://www.nime.org/proceedings/2020/nime2020_music09.pdf},
  abstract = {Petrified Wood brings together three exciting cutting-edge improvisers, from disparate musical realms to create new musical interactions utilizing novel new instruments and exploring the potential for live-coding in a musically interactive setting. The trio consists of the duo Jack Armitage (live-coding) and Laurel Pardue (svampolin) joined by the legendary composer, producer, musician, and pioneer of Bhangra, Kuljit Bhamra MBE (electronic tabla and percussion). The performance features two novel alternative instruments designed to play, present, feel like, and even sound like the acoustic instruments on which they are modelled, but can equally sound completely unlike the originals. The svampolin, a hybrid electro-acoustic violin is a functional decomposition and recomposition of the violin retaining the instrument’s acoustic sonic physicality while enabling audio signal modi cation. Meanwhile, the electronic tabla, developed as part of e orts to make tabla learning more accessible, can be used in more traditional roles either as a regular tabla or as an interface to control any array of expressive percussive instruments. Lastly, Jack Armitage brings his expertise and musicianship as a live-coder to not only provide music and texture, but to resample and reframe instrumental player’s ideas live or, through remote control of the svampolin, rede ne performer intimacy as the coder alters the svampolin’s performative results in real-time. Changing the instrument’s functionality during a piece, the player and coder are able to shift the role of the instrument from structure to behaviour, or to freely transition between lutherie and performance.}
}

@inproceedings{nime20-music-Melbye,
  author = {Melbye, Adam Pulz and Ulfarsson, Halldor},
  title = {The Feedback-Actuated Augmented Bass (FAAB)},
  pages = {24-25},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  iso = {10.5281/zenodo.6351045},
  url = {http://www.nime.org/proceedings/2020/nime2020_music10.pdf},
  abstract = {The FAAB (Feedback-Actuated Augmented Bass) is a modi ed double bass featuring electromagnetic pickups, an embedded speaker and onboard DSP through a Bela microprocessor. Through mechanically induced feedback and adaptive signal processing, the instrument expands the textural and spectral properties of traditional as well as extended playing techniques. The complex dynamics of the electro-acoustic couplings requires the performer to investigate human-instrument relationships from the perspective of negotiation and exploration rather than instrumental mastery. The improvised performance is a snapshot of the continuous co-evolution between, on the one hand, new techniques and performance practices and on the other, mechanical, acoustical and digital optimisation.}
}

@inproceedings{nime20-music-Moroz,
  author = {Moroz, Solomiya and Dejana Sekulic},
  title = {Artefacts of Presence},
  pages = {26-27},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351119},
  url = {http://www.nime.org/proceedings/2020/nime2020_music11.pdf},
  abstract = {artefacts of presence uses archival material from a folk music archive and was part of the larger project addressing composition with archival material. In this piece, I used transcriptions of archival material to adapt to violin writing and techniques. I also use an extended bow attachment which is comprised of a minibee accelerometer whose speed and direction of movement influences digital sound processes of the violinist. The performative presence of the violinist on stage is established through a musical dialogue with the protagonists of the archival footage.}
}

@inproceedings{nime20-music-Zappi,
  author = {Zappi, Victor and Ronen, Oren},
  title = {Black Space},
  pages = {28-29},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351195},
  url = {http://www.nime.org/proceedings/2020/nime2020_music12.pdf},
  address = {Black Space is a solo performance that presents highly correlated sonic and visual elements. The piece revolves around the manipulation of acoustic qualities of sound propagation and reverberation in a physical model, that is capable of both synthesizing and rendering sound waves. The performer gradually populates the black space that stretches across the surface of his instrument with sound sources, creating layered textures and percussive sounds that get trapped and resonate in di erent 2D shapes and materials. As the piece evolves, the performer explores the acoustic e ects arising as he alters the physical properties of these materials and the shapes these sounds exist in. Black Space was composed for a novel audio/visual digital musical instrument, whose name is anonymized for the submission.}
}

@inproceedings{nime20-music-Ilsar,
  author = {Ilsar, Alon and Hughes, Matthew},
  title = {The Air Sticks - An Audio Visual Gestural Instrument},
  pages = {30-31},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351217},
  url = {http://www.nime.org/proceedings/2020/nime2020_music13.pdf},
  abstract = {The AirSticks are an audio-visual gestural instrument designed to allow the composition, performance and impro- visation of live electronic music and graphics using movements captured by handheld motion controllers, utilising bespoke software to generate musical and visual content from the gestural controller’s real-time position and rotation information. Through this interface, the performer is offered multidimensional control over audio-visual parameters, whilst providing a clearly transparent relationship between gesture and audio-visual product. The graphics are projected onto a transparent screen—or scrim—to allow both the performer and audience to relate to them. Percussionist and instrument designer Alon Ilsar has been performing with the AirSticks around the world since 2013 with highlights including a live performance with Alan Cumming at the MET museum in NYC, a TEDx performance with live electronic trio the Sticks at Sydney’s Opera House and a solo performance of an hour long audio-visual collaboration with Matt Hughes at Sydney’s Recital Hall entitled Trigger Happy Visualised. The AirSticks were also presented at the 2019 Guthman Musical Instrument Competition in Georgia Tech in Atlanta, Georgia, where they took out the Audience Choice Awards for Best Instrument and Best Performance. A similar presentation was recently made at SIGGRAPH Asia’s 2019 Real-Time Live Competition, in which the AirSticks took out the judge’s award for Best Presentation. In this video, we present three excerpts from Trigger Happy Visualised, plus a short introduction from SIGGRAPH Asia 2019.}
}

@inproceedings{nime20-music-Han,
  author = {Han, Isak},
  title = {Playing the nUFO},
  pages = {32-33},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351319},
  url = {http://www.nime.org/proceedings/2020/nime2020_music14.pdf},
  address = {"Will new digital instruments become part of the current musico-industrial framework with composers, publishers, producers, sound engineers, performers, concert halls, media, critics, audience? Or do they belong to a new age of musical practice? What is a new digital instrument? How do we play it? Who composes for it? Where does it fit in our culture? And is it a sustainable thing?" Thor Magnusson poses these questions in "sonic writing" (2019), and they all directly apply to the nUFO I’ve been developing over the past 3 years. They inform the conceptual background of the piece, with my personal answers to them becoming the initial sound material. Oscillating between clear intelligibility and complex processing blended with layers of abstract synthesis, the piece offers multiple auditory perspectives on these questions.}
}

@inproceedings{nime20-music-Allison,
  author = {Allison, Jesse and Marasco, Anthony T},
  title = {Gravity | Density},
  pages = {34-35},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6351489},
  url = {http://www.nime.org/proceedings/2020/nime2020_music15.pdf},
  abstract = {Gravity | Density is a work for cyber-hacked devices and Web Audio applications with thematic material drawn from humankind’s fascination with the universe. In Gravity | Density, we begin by manipulating fixed-audio sources through the performance of hacked CD play- ers. The sonic results of this mangled audio is sampled and then distributed to the audience’s mobile devices in both passive and interactive manners. Passive distributions allow us to create intricately-spatialized rhythmic interplay between the glitching CD players and the blanket of overlapping samples dispersed throughout the networked audience. Active distributions allow the audience to join in our performance; by sampling small portions of the audio, processing and looping these sounds and sending them back to the performers, we string this audio together and feed it into a cyber-controlled distortion pedal before sending it back to the audience for more manipulation. This results in overlapping cycles of control and audio generation between performer, audience, network, and machine.}
}

@inproceedings{nime20-music-Nerness,
  author = {Nerness, Barbara},
  title = {Embody},
  pages = {36-37},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352727},
  url = {http://www.nime.org/proceedings/2020/nime2020_music16.pdf},
  abstract = {embody is a piece for live performers using stethophones (stethoscope microphones), which I have created from hacked stethoscopes, in order to amplify the heartbeat and voice in the chest or vocal tract. The motivation came from my exploration of the sounds trapped within my body, such as my heartbeat and the resonance of my voice in my vocal tract or chest. Is it possible to record our voice as we hear it in our head? On the surface, embody asks the questions: “What if the ocean had a heart? What if machines could speak?” In some sense, the ocean does have a pulse through tides and machines do make noise, we just do not understand them as human. In the piece, sounds of the natural and built environment are anthropomorphized using the sounds inside the performers’ bodies. On a technical level, the sounds were constructed using spectral convolution and envelope following, probing the spectral overlap of our bodies with sounds external to us. The piece includes sounds from two eld recording sessions; one at the beach in Pescadero and another on a tour through the Stanford Energy Facility. The piece is spatialized in 3rd order Ambisonics to resemble a sonic body.}
}

@inproceedings{nime20-music-Hein,
  author = {Hein, Nicola Leonard and Truniger, Lukas},
  title = {Membranes},
  pages = {38-39},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352748},
  url = {http://www.nime.org/proceedings/2020/nime2020_music17.pdf},
  abstract = {Exploring the boundaries where music and language overlap, they use hybrid instruments – constructed from drum- skins and electronic components – as devices to turn written texts into pulses of light and percussive sound. As each machine translation emerges, the network of instruments starts to share the texts, transforming written material into aesthetic, visual and sonic patterns, for the performers and spectators to further interact with. Extrapolating from the example of the African talking drum, Membranes builds up an altogether new kind of tone language, constantly shifting and adapting itself before the viewer and performers alike. The instruments form a reactive network of semantic and aesthetic actors: a play of forms, light and sound unfolds between them. Following historical archetypes musical communication instruments and seeking to create a speculative acoustic interaction space, this audio-visual installation and performance offers a new alternative communication environment.}
}

@inproceedings{nime20-music-Song,
  author = {Song, Weiming},
  title = {Yunzhong Jun},
  pages = {40},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352756},
  url = {http://www.nime.org/proceedings/2020/nime2020_music18.pdf},
  abstract = {Yunzhong Jun is a real-time interactive music for human voice and Max/MSP. It is inspired by The Lord within the Clouds in Nine Songs (Chinese name Jiu Ge), which is an ancient Chinese poem series written by Qu Yuan. Yunzhong Jun is also the name of the figure in the poem who controls cloud and rain in ancient Chinese mythology. The lyrics spoken by the performer is come from the poem depicting the scene of ritual in which people calling for rain. The gesture and movement of the performer over the ultrasonic sensors generate the data for controlling parameters in the Max/MSP patch and for manipulating the voice of the performer as well.}
}

@inproceedings{nime20-music-Ressi,
  author = {Ressi, Christof and Benes, Szilard},
  title = {Terrain Study},
  pages = {41-43},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352760},
  url = {http://www.nime.org/proceedings/2020/nime2020_music19.pdf},
  abstract = {terrain study is a piece for solo performer and virtual reality system, which seeks to work with the possibilities and limitations of VR outside the usual context of a realistic 3D environment. The player starts in a simplistic 3D world consisting of only three basic elements: a randomly generated, slightly undulating terrain; a texture mapped cube which creates the illusion of an endless horizon (a so- called sky box); and several metal-like spheres hovering above the ground which the player can interact with musically. By and by, the visual and acoustic representation of the game world is manipulated by the sounds produced on the instrument, leading to bizarre structures and surreal perspectives, eventually questioning the division of subject and world.}
}

@inproceedings{nime20-music-Brown,
  author = {Brown, Courtney D},
  title = {Machine Tango},
  pages = {44-45},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352767},
  url = {http://www.nime.org/proceedings/2020/nime2020_music20.pdf},
  abstract = {Argentine tango dancers generally react to musical recordings with improvised steps, each action arising from an unspoken conversation between leader and follower. In Machine Tango, this relation between dancers and music is turned upside down, enabling tango dancers to drive musical outcomes. Motion sensors are attached to dancer limbs, and their data is sent wirelessly to a computer, where algorithms turn the movement into sound. In doing so, the computer inserts itself in this on-going nonverbal conversation. Instead of traditional tango instruments such as the violin, dancers generate and transform the sounds of aluminum capsules, typewriters, and other found sounds. The musical response of the interactive system to dancer movement transforms during the dance, becoming more complex. The two dancers must traverse the resulting volatile sound landscape as one, responding with stylized tango movements. The effort involved in performing this task, such as how the performers are required to listen to one another’s movements with even more attention, and the contrast between the traditional with the experimental are essential to the performance aesthetic. The work is performed by myself and my tango partner, Brent Brimhall, who has contributed greatly to the structures of the dance.}
}

@inproceedings{nime20-music-Chuang,
  author = {Chuang, Se-Lien and Weixler, Andreas},
  title = {Sonic Cultures},
  pages = {46-48},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352771},
  url = {http://www.nime.org/proceedings/2020/nime2020_music21.pdf},
  abstract = {Sonic Cultures is an immersive realtime audiovisual compositional environment with interactive generative score (iScore) for multiple computer and open ensemble. An open acoustic instruments ensemble including electronic devices using digital interfaces (laptops etc.) serves as mutual media for score conducting, reading and interpreting. In concert it is performed within an combination of audiovisual realtime processing and improvisation conducted by interactive graphic scores on individual screens/computer driven by virtuoso random functions and intentional choices of a digital conductor/composer, which underline the visual and graphic components that are linked to and experienced by the musical sound environments. The conducted improvisation is completed by an audio realtime signal processing by fft controlled freeze reverb, classic ring modulation as well as spectral delay by a computer performer in mutual inducement with the instrumental player.}
}

@inproceedings{nime20-music-Wilson,
  author = {Vasilakos, Konstantinos and Wilson, Scott and Yeung, Tsun Winston and Margetson Emma and Nystrom, Erik},
  title = {Dark Matter (live coding)},
  pages = {49-51},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6352914},
  url = {http://www.nime.org/proceedings/2020/nime2020_music22.pdf},
  abstract = {This performance, created in collaboration with the art@CMS project at CERN in Switzerland, involves the real-time sonification of data streams from the Large Hadron Collider, the world’s largest and most complex particle accelerator. Experimental data containing clues towards possible ’new physics’ becomes the raw material for improvised music and visualisations programmed with an aim to creating a result that while beautiful, is both musically and scientifically meaningful.}
}

@inproceedings{nime20-music-Cybulski,
  author = {Cybulski, Krzysztof},
  title = {Modular Process Music},
  pages = {52-54},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6353004},
  url = {http://www.nime.org/proceedings/2020/nime2020_music23.pdf},
  abstract = {Modular Process Music is an improvised performance with a set of self-devised and built electronic instruments. The instruments communicate with each other through the sound - each instrument has a speaker and a microphone, so they can listen to each other or to any other external sounds. The instruments are designed to make their interactions clearly comprehensible to the audience via their visual appearance.}
}


@inproceedings{nime20-music-McLean,
  author = {McLean, Alex},
  title = {Feedforward},
  pages = {55},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6353969},
  url = {http://www.nime.org/proceedings/2020/nime2020_music24.pdf},
  abstract = {This is an improvised, from-scratch live coding performance. The NIME interface which this performance showcases is the new Feedfoward editor for the TidalCycles live coding environment. Feedforward is written in Haskell using the ncurses library for terminal-based user interfaces. It runs on low-powered hardware including the Raspberry Pi Zero, with formative testing of prototypes conducted with several groups of children between the ages of 8 and 14. Feedforward has a number of features designed to support improvised, multi-pattern live coding. Individual Tidal patterns are addressable with hotkeys for fast mute and unmuting. Each pattern has a stereo VU meter, to aid the quick matching of sound to pattern within a mix. In addition, TidalCycles has been extended to store context with each event, so that source code positions in its polyrhythmic sequence mini-notation are tracked. This allows steps to be highlighted in the source code when- ever they are active. This works even when Tidal combinators have been applied to manipulate the timeline. Formal evaluation has yet to take place, but this feature appears to support learning of how pattern manipulations work in Tidal. Feedforward and TidalCycles is free/open source software under a GPL licence version 3.0.}
}


@inproceedings{nime20-music-Green,
  author = {Green, Owen},
  title = {Race to the Bottom},
  pages = {56-58},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6353975},
  url = {http://www.nime.org/proceedings/2020/nime2020_music25.pdf},
  abstract = {Race to the Bottom is the most recent of a string of improvising machines involving bowed cardboard boxes, developed over the last decade. In all these systems, bowed cardboard is both the source of all sonic material and the ‘control’ interface to software that occupies a changeable and turbulent role in the territories between algorithmic co-player, instrument and processor. Boxes, it turns out, yield a much more varied sound world, and more room for practised technique than I had imagined when I started exploring them (somewhat facetiously). They also present a range of interesting challenges to machine listening algorithms, such are the instabilities and varied points of interest in their sound. All of these improvising machines have explored different approaches to dealing with this, and finding creative ways of enjoying the software’s frequent ‘misunderstandings’ of its input. Increasingly, these machines have also been a place for me to investigate ways of dealing with time in algorithmically mediated improvising, particularly when (as here) my hands are already busy, and I have to trust my software’s sense of time and musicality (or at least put up with it). In Race to the Bottom, these fronts are explored by abusing segmentation algorithms and beat trackers as (loose- ish) analogues for, respectively, oscillators and filters. A clutch of these run at different rates, latching on to different parts of different sounds, and interfering with each other, informing both the processing of sound and the unfolding of musical shape.}
}


@inproceedings{nime20-music-Bowers,
  author = {Bowers, John and Hagan, Kerry},
  title = {Touch, Strike, Slide, Twist, Shudder},
  pages = {59-60},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6353981},
  url = {http://www.nime.org/proceedings/2020/nime2020_music26.pdf},
  abstract = {This video catches Bowers and Hagan in the act of sticking their dirty hands into machineries best left alone as they struggle in the midst of unruly sonic behaviours and non-obvious interaction design. Using synthesis algorithms with extreme sensitivity to gesture, they steer rather than control a complex solfége of pulses, noises, crackles and drones, negotiating a link between chaotic dynamics and improvisation. All relationships are tricky, especially the love polyhedron between Bowers, Hagan, their interfaces, their algorithms and their many noises. But we hope for the best. }
}


@inproceedings{nime20-music-Mako,
  author = {M{\'a}k{\'o}, M{\'a}ri},
  title = {Schmitt},
  pages = {61-64},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6353997},
  url = {http://www.nime.org/proceedings/2020/nime2020_music27.pdf},
  abstract = {Schmitt is a quadrophonic live-electronic music performance. The piece meant to challenge and explore the relationships between motion, gesture and music in a multi-channel speaker setup. Along with that the narrative of the performance is about overcoming existential crisis, which is translated into a sonic journey. The main symbol is a self-made square wave Schmitt oscillator, which is the sound source throughout the whole piece. The development of the oscillator’s timbre is the transformation of the narrative. The piece is also questioning a certain issue behind using self-made instruments or controllers compared to the use of traditional instruments. It is strongly connected to a reference point (expectation) of how the players gestures on the instrument are coordinated with the sounding outcome.}
}

@inproceedings{nime20-music-Nystrom,
  author = {Nystr{\"o}m, Erik},
  title = {Intra-action},
  pages = {65-66},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Wright, Joe and Feng, Jian},
  year = {2020},
  month = july,
  publisher = {Royal Birmingham Conservatoire},
  address = {Birmingham, UK},
  doi = {10.5281/zenodo.6354005},
  url = {http://www.nime.org/proceedings/2020/nime2020_music28.pdf},
  abstract = {Intra-action is an experimental computer music system and improvised performance where human agency and perceiving generative processes create an ecology of unconventional synthetic sonorities. The work is inspired by philosopher Karen Barad [1], for whom phenomena or objects are not external to one another, and do not precede their encounters, as implied in ‘interaction’: instead they emerge from ‘intra-action’, an interior process of relationships. In this work, intra-action is both a process occurring inside the computer – where morphological processes are shaped in relation to one another through machine listening and agent-based organisation – and a posthuman relation where ‘human’ and ‘machine’ agency are co-dependent. Intra-action was commissioned by, and premiered at, NEXT Festival 2019 in Bratislava.}
}
