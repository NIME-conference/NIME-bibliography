@article{nime2024_music_1,
  author = {Ivica Bukvic and Thomas Tucker},
  title = {Two Crowdsourced Telematic EDM Work Performances Using L2Ork Tweeter: Territorio Prismático and 8-bit Petal by L2Ork and L2Ork Community Ensembles},
  pages = {1--5},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {1},
  track = {Music},
  doi = {10.5281/zenodo.15027953},
  url = {http://nime.org/proceedings/2024/nime2024_music_1.pdf},
  presentation-video = {https://youtu.be/6oVbAWTlp-E},
  abstract = {A live performance of two co-created telematic EDM works that were devised using L2Ork Tweeter platform. Both works were premiered in December 2023. In addition, performance can also include projection mapping element. The proposed performances may be particularly conducive to a club scene and other less conventional performance spaces. The two works are Territorio Prismático (https://www.youtube.com/watch?v=6oVbAWTlp-E), and the 8-bit Petal (https://www.youtube.com/watch?v=hDMiE2OkGNA). Every facet of both works is co-created by the ensemble members, including instrument design, part composition, and performance. The final iteration of both works is curated by the L2Ork Director Ivica Ico Bukvic. The conference performance will be live, and will feature L2Ork community ensemble members consisting of volunteer co-creators and performers from all over the world, with physical distances exceeding 11,000 miles. Community members partaking in this performance will be announceed at the performance. A visual projection counterpart to the performance led by the visual artist Thomas Tucker will take place synchronously on Virgina Tech campus.},
  numpages = {5}
}

@article{nime2024_music_2,
  author = {Jean-Philippe Jullin and Ariane Levasseur},
  title = {Spectra},
  pages = {6--8},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {2},
  track = {Music},
  doi = {10.5281/zenodo.15028142},
  url = {http://nime.org/proceedings/2024/nime2024_music_2.pdf},
  presentation-video = {},
  abstract = {Spectra is a transdisciplinary performance exploring latent sound spaces through dance and the perception of human gesture. By tracing the motions of a dancer and using these gestures to navigate through sound corpora, this piece evokes the intricate interplay between technology and human experience. Drawing inspiration from technological advancements and their influence on human development, particularly the gradual reshaping of cognitive frameworks, this audiovisual composition explores the dynamics between humans and algorithmic systems. It probes various relational paradigms within an environment where the distinction between artist and machine becomes increasingly blurred.},
  numpages = {3}
}

@article{nime2024_music_3,
  author = {Yunyu Ong and Emma Smith and Ryuji Hamada and Lee McIver and Maddie Duncan},
  title = {When The Rain God Sings Storm Lions Are Born },
  pages = {9--12},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {3},
  track = {Music},
  doi = {10.5281/zenodo.15027961},
  url = {http://nime.org/proceedings/2024/nime2024_music_3.pdf},
  presentation-video = {https://vimeo.com/942163293/b63853485c},
  abstract = {Curiosity does not always kill a cat, sometimes it makes a god. Welcome to the world of ‘When the Rain God Sings, Storm Lions Are Born’ (‘Rain Gods’) by multi-award winning composer Yunyu. This is a supernatural world of cats, thunder and new gods. The old god has gone fishing, you see, so she leaves her drums for the next unsuspecting human to play, for this is how new gods are made. This is the world where drums play tunes and cats must first be appeased and fed so they can grow up and make thunder for the new gods. It is all very hard work. Commissioned by Taikoz, Percussion Australia and brought to life by the masterful Ryuji Hamada, Yunyu re-purposes a linear DAW, Logic X with a goal of turning a single performer into a performer/conductor. This is a seamless exploration of musical composition and instrument making, where traditional playing techniques of Taiko drumming are considered and mapped onto their electronic counterparts [Roland’s Taiko-1], pushing the limits of what taiko playing can be. This is a cautionary tale for the accidental gods amongst us. In a further development by Vfx Artist/Director Emma Smith, the performance intertwines sound and light with reactive weather patterns and a responsive ecosystem primarily comprised of cats, all changing in response to the playful musical landscape. Keep an eye out for the installation that accompanies this this performance – ‘Be your own Rain God’ where audiences can make their own thunderstorm. This is a tale of negotiation between environmental forces and human will, where humankind are not always in control although we often think we are.},
  numpages = {4}
}

@article{nime2024_music_4,
  author = {Lina Bautista and Timo Hoogland and Rafaele Andrade},
  title = {Morph},
  pages = {13--15},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {4},
  track = {Music},
  doi = {10.5281/zenodo.15028143},
  url = {http://nime.org/proceedings/2024/nime2024_music_4.pdf},
  presentation-video = {https://youtu.be/SXl8asBUsng},
  abstract = {Morph is an audiovisual performance that explores live hybrid sound design, with the use of electric guitar, acoustic drums, electronics and live coding. This iteration of Morph is performed by Timo Hoogland (drums, code) and Lina Bautista (guitar, code). While playing they both code live using the Mercury language. During the piece they explore how their instruments can extend beyond their own sound by controlling each others sonic output. Morph is an ongoing research between Rafaele Andrade, Timo Hoogland and Lina Bautista.},
  numpages = {3}
}

@article{nime2024_music_5,
  author = {Youngjoo Jennifer Ryu},
  title = {Monster Voice: Split Tongue},
  pages = {16--22},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {5},
  track = {Music},
  doi = {10.5281/zenodo.15028150},
  url = {http://nime.org/proceedings/2024/nime2024_music_5.pdf},
  presentation-video = {},
  abstract = {Monster Voice: Split Tongue is a live recitation composition of a spoken language dedicated to female pain, one that may become a new method of communication for women who hurt. A new sound language based on phonetic symbols, designed using SuperCollider, is read aloud on the custom-built body-worn Arduino instruments. The pain of a hurting woman is difficult to convey to others. Instead of language, the content of pain has been vocalized through whimpers, cries, screams, or silence. Following in the footsteps of generations of women who have attempted to verbalize their pain, the language dismantles the existing [consonant+vowel] language system. Instead, it incorporates the structure of [sound+vowel] to interpret the writings of women who came before us. At the same time, the language is an attempt to vocally communicate the chronic pain of the composer/performer herself, who suffers from fibromyalgia. The process of physically translating the new language, Monster Voice, through the custom-built body-worn instruments revive and give voice to the pain of the composer/performer and the women of previous generations.},
  numpages = {7}
}

@article{nime2024_music_6,
  author = {Jessica Rodríguez},
  title = {encarnadas (f.) embodiments},
  pages = {23--25},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {6},
  track = {Music},
  doi = {10.5281/zenodo.15028161},
  url = {http://nime.org/proceedings/2024/nime2024_music_6.pdf},
  presentation-video = {},
  abstract = {encarnadas => (f.) embodiments is an audio-visual project in the form of a performance piece and a dance-video piece. This is an 8-minute performance mixing a dancer, live video coding, and ASMR sonic experiences. This piece is an experimental homage to feminine human bodies, present both visually (through the image of the dancer physically and virtually) and sonically (through a sound composition built of repeating breathings, whispers, and other mouth sounds). Through the eyes of technology, the audience will experience a coming and going of folding and unfolding audio-visual images of the feminine bodies involved, moving through the multiple spaces and times of the project.},
  numpages = {3}
}

@article{nime2024_music_7,
  author = {Koray Tahiroğlu},
  title = {Communal},
  pages = {26--28},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {7},
  track = {Music},
  doi = {10.5281/zenodo.15027977},
  url = {http://nime.org/proceedings/2024/nime2024_music_7.pdf},
  presentation-video = {https://vimeo.com/913266625},
  abstract = {The composition Communal is one of a set of performances where the performer and the musical instrument work together to direct, suggest and form a transitional musical narrative. For this performance, the piece takes the form of a collective that allows us to recognise the deeper transformations in the use of AI technologies towards co-determining how music can be present for and perceived by human musicians and audience. The piece was composed using the tools we develop as part of AI-terity and GANSpaceSynth projects. In the context of new interfaces for musical expression, AI technologies serve an integral role today, offering new perspectives to experiment on the ways in which a musical instrument manifests itself in human-technology relation, finding ways to embody itself into the otherness.},
  numpages = {3}
}

@article{nime2024_music_8,
  author = {Francesco Corvi and Daniel Gorelick},
  title = {Distributed Listening},
  pages = {29--33},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {8},
  track = {Music},
  doi = {10.5281/zenodo.15027981},
  url = {http://nime.org/proceedings/2024/nime2024_music_8.pdf},
  presentation-video = {https://youtu.be/9CwJnnz18a8},
  abstract = {‘Distributed Listening’ is a music performance dealing with the concepts of distributed agency, machine listening, and adaptive sound processing. The focus of the project is the exploration of a miscellaneous technological apparatus, where digital and electroacoustic instruments are situated in the same environment, sharing data in the form of audio signals and descriptors. Particular relevance is given to how this shapes the functioning of each instrument: as a mediator between performers, as a semi-autonomous agent able to exhibit adaptive behaviors and react to the incoming data, and on its ability to influence the rest of the system.},
  numpages = {5}
}

@article{nime2024_music_9,
  author = {Kieran McAuliffe},
  title = {A History Told in Grains},
  pages = {34--36},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {9},
  track = {Music},
  doi = {10.5281/zenodo.15027985},
  url = {http://nime.org/proceedings/2024/nime2024_music_9.pdf},
  presentation-video = {},
  abstract = {The Powder Toy is a free, open source sandbox game.  It features some of the most extensive systems out of all ‘falling sand’ games, a genre in which players freely tinker with powder substances and observe their chaotic interactions.  These games notably lack sound.  As an enthusiast of the genre, I took it upon myself to add audio to The Powder Toy.  The result is not an objective or realistic solution to how these quirky games should sound, but rather an artistic exploration.  Using this system, I present a history of the known universe told through grains of sand and grains of sound by three laptop performers.},
  numpages = {3}
}

@article{nime2024_music_10,
  author = {Mei-ling Lee},
  title = {Summoner},
  pages = {37--37},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {10},
  track = {Music},
  doi = {10.5281/zenodo.15027988},
  url = {http://nime.org/proceedings/2024/nime2024_music_10.pdf},
  presentation-video = {https://youtu.be/YtsuM_a6pq4},
  abstract = {Summoner, a music composition performance, is created using Kyma by Symbolic Sound Corporation, Max software by Cycling '74, and the Leap Motion Controller by Ultraleap. All performative movements are based on turning an intangible sound into an imaginary physical object.},
  numpages = {1}
}

@article{nime2024_music_11,
  author = {Anders Lind},
  title = {Voyage One - Audience Mobile Phone Orchestra Performance},
  pages = {38--41},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {11},
  track = {Music},
  doi = {10.5281/zenodo.15027993},
  url = {http://nime.org/proceedings/2024/nime2024_music_11.pdf},
  presentation-video = {https://youtu.be/8zEm0X3xPOM},
  abstract = {Voyage One is a 6-minute composition for a participatory Mobile Phone Orchestra (MPO) concept developed by the author. The MPO concept is designed to embrace people regardless their musical backgrounds as performers, but still with an aim to generate expressive and meaningful artistic expressions for concert hall performances. In a performance the MPO consist of 20-40 people, divided in 6 individual parts. They perform using their phones, and the dedicated MPO Web-API, as instrument interfaces. Animated notation is showing performance instructions for the 6 individual parts and conducting the performance. Voyage One was composed in 2017, during the early stages of development of the MPO platform. The work is a single movement composition, where 6 individual voices are introduced one after another to slowly build up an orchestral harmonic texture towards a concluding climax. The composition is characterized by extremely tight constraints, where only four pitches are used in each voice, based on the previous conditions of the mobile phone orchestra's instrument interface. The challenge lay in creating musical coherence within this limitation of four pitches per voice by organizing the interaction among the six voices. Voyage One was composed as an initial journey into the unknown where the MPO becomes a metaphor for the collective and the importance of interaction in creating meaning.},
  numpages = {4}
}

@article{nime2024_music_12,
  author = {Paul Stapleton and Michael Speers},
  title = {Membracinae},
  pages = {42--46},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {12},
  track = {Music},
  doi = {10.5281/zenodo.15027997},
  url = {http://nime.org/proceedings/2024/nime2024_music_12.pdf},
  presentation-video = {https://vimeo.com/912578933},
  abstract = {This improvised performance deploys metastable networks of vibrotactile and audible feedback to intertwine Stapleton's custom-made electroacoustic instrument Volatile Assemblage (aka VOLA) with Speers's acoustic drums driven by air pumps and transducers. The music that emerges through such intra-actions tends towards unforeseen behaviours and contingent structures, akin to the steering of a small ship on tempestuous waters, or the communication of insects through the rapid bouncing of abdomens against a shared substrate, thereby creating a kind of ‘aesthetic interfacing’ between performers, instruments, audience, environment and their collective movements through time and space.},
  numpages = {5}
}

@article{nime2024_music_13,
  author = {Robert Ek},
  title = {One Grain of Sound},
  pages = {47--48},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {13},
  track = {Music},
  doi = {10.5281/zenodo.15028001},
  url = {http://nime.org/proceedings/2024/nime2024_music_13.pdf},
  presentation-video = {https://youtu.be/5OBZSFhxZAE},
  abstract = {This system was initially created in 2022 and focuses on non-pitched sound material from the clarinet, like tongue rams, key clicks, and different types of air sounds. The audio input from the clarinet is fed into a modular synthesizer where it is processed. The module mainly used in this patch is the Mutable Instruments Beads, a texture synthesizer working with granulation. The sensor data from the physical gestures are converted to control voltage (CV) to manipulate parameters in the modular setup. Creating this system was informed by my use of the MiM sensor bell for more than seven years. Given the extensive time I have spent working with the sensor component of the system, my awareness of how certain bodily movement creates particular gestural input is rather detailed. This understanding, combined with the knowledge gained through analyzing performance videos through an embodied perspective, helps me to make informed decisions in the process of designing the mapping that controls the intermedial translation.},
  numpages = {2}
}

@article{nime2024_music_14,
  author = {Bernt Isak Wærstad and Tejaswinee Kelkar},
  title = {Three is a crowd? A prompt driven human-bot performance},
  pages = {49--51},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {14},
  track = {Music},
  doi = {10.5281/zenodo.15028005},
  url = {http://nime.org/proceedings/2024/nime2024_music_14.pdf},
  presentation-video = {},
  abstract = {This performance is an improvisational collaboration between a vocalist, an electronic musician, and a musical agent based on self organizing maps from curated music corpora. The back-and-forth in this musical conversation is based around the concept of a very simple control algorithm that controls the conversation through generated prompts. Each element of this performance controls and is controlled by the tightly regimented constraints around making musical meaning together. ‘Three is a crowd?’ is a continuation of Co-Creative Spaces presented at NIME 2023 and builds on both the experiences and software (CCCP) from that project. The agents in Co-Creative Spaces generate sound by picking from a corpus of recorded material from the human musicians. How these collections were curated and put together was an important artistic decision for the co-creation process. This gave the musicians a closeness to the material that was seen as positive, but at the same time there was a recurring wish that the agents could have their own voice to a greater extent. “Three is a crowd?” is the first step in exploring other ways of giving the non-human agents more explicit agency in a performance by introducing a simple control algorithm that will guide the musical performance through text-based prompts.},
  numpages = {3}
}

@article{nime2024_music_15,
  author = {Rudolf Arnold},
  title = {Cassiopeia's Secret},
  pages = {52--56},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {15},
  track = {Music},
  doi = {10.5281/zenodo.15028009},
  url = {http://nime.org/proceedings/2024/nime2024_music_15.pdf},
  presentation-video = {https://vimeo.com/942964945},
  abstract = {The performance ‘Cassiopeia’s Secret’ is a first approach to an artistic, emotional, and scientific examination of the relations between music, sexology, gender identity, and astrophysics. It utilizes medical sensors and the technique of sonification to make sexual arousal audible. Moreover, there are tactile stimulators controlled by music and data generated by cosmic phenomena. The sensors and vibrators are hidden beneath a futuristic attire called a Pleasure Space Suit designed for sexual relaxation during long space travels. The story is about an experiment performed by Cassiopeia, a genderfluid Space Girl wearing the Pleasure Suit, and her friend and scientist, Dr. Aurélie. It is a simulated mission to an exomoon where the audience perceives the sonification of Cassiopeia’s sexual arousal, the sound of celestial signals, and Aurélie’s stimulating music as a futuristic symphony of pleasure.},
  numpages = {5}
}

@article{nime2024_music_16,
  author = {Nicola Leonard Hein and Viola Yip},
  title = {Transsonic | Sonic Fluidity},
  pages = {57--61},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {16},
  track = {Music},
  doi = {10.5281/zenodo.15028017},
  url = {http://nime.org/proceedings/2024/nime2024_music_16.pdf},
  presentation-video = {https://youtu.be/t16oltv-Fmk},
  abstract = {Transsonic (Viola Yip/Nicola Hein) is an experimental transmedia duo that creates immersive, site-specific performances and installations that bridge the vibrations of light and sound. They develop a transmedial aesthetic language using Yip's self-built light bulb instrument Bulbble, which generates both light and sound and the electronic sounds of Hein, working with Buchla synthesizers and electric guitar. In addition, they use a third autonomous A.I. musical agent (NicolAI) as an additional voice, which is trained live on the musical material of the performance and plays together with them. Transsonic develops complex cybernetic systems as a space for transmedial musical performance. Sonic Fluidity further develops the work of Transsonic: Yip and Hein develop instruments that use solar panels as microphones for light signals and can further process these incoming audio signals, as well as spatialize them on a multichannel-loudspeaker system; The feedback feeds into physical modeling and RAVE (Realtime Audio Variational autoEncoder) algorithms, furthermore into a chain of electronic effects in order to generate the sound of the piece; The piece uses an autonomous A.I. musical agent (NicolAI) as an additional voice, which is trained live on their musical material and plays together with them; Transsonic works with a laser projection based on the bulb instrument Bulbble by Yip. For the first time, Transsonic uses lasers as a light source and uses them to fill the performance space. The lasers are controlled by sound signals. These sound signals originate from the solar panel instruments developed for the project (which generate their sound by light falling on the solar panels); The project develops a highly dynamic audiovisual cybernetic system that Yip and Hein perform with.},
  numpages = {5}
}

@article{nime2024_music_17,
  author = {Vladimir Vlaev},
  title = {Pervade the Space},
  pages = {62--63},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {17},
  track = {Music},
  doi = {10.5281/zenodo.15028166},
  url = {http://nime.org/proceedings/2024/nime2024_music_17.pdf},
  presentation-video = {https://youtu.be/mSSHa74S6B8},
  abstract = {Pervade the Space is a multichannel sound performance which creates an original relationship between the input of the physical gesture of the performer, the derived artistic output and its spatial distribution. It is an exploration of the capabilities of a prototype of musical instrument — the HexApp — a digital processing engine developed to transform the sound of multichannel acoustic input in real-time. This instrumental & live-electronics performance is a solo set in which the performer interacts in a balanced relationship with the computer in the process of decision making providing memorable spatial sonic experience for the listener. It explores unconventional instrumental approaches as well as compositional strategies applied in real-time improvisatory domain. Furthermore, the performance delves into the magnetic properties of the hexaphonic pickup used as a sound source — multichannel input of the real-time processing system. The sound transformations occupy a broad spectrum of musical expressivity ranging from immersive slowly unfolding and evolving textures to emerging sharply articulated grainy sonic entities. HexApp is an instrument which could be described as a hybrid, acoustic - digital, naturally - artificial, traditionally - innovative hybrid of six independently depending on each other, unpredictably predictable constituents of a dynamically - motionless soundscape. The HexApp uses the Max/MSP/Jitter environment for processing the multichannel input. The project implements custom built modules based on processes such as ring modulation, delay, transposition, flanging, granulation, feedback and any combination between them. The control over processes is both manual through a MIDI controller and automated through a limited randomness provided through the digital environment itself. },
  numpages = {2}
}

@article{nime2024_music_18,
  author = {Gaël Moriceau},
  title = {Study for T-Stick and Granulation},
  pages = {64--67},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {18},
  track = {Music},
  doi = {10.5281/zenodo.15028025},
  url = {http://nime.org/proceedings/2024/nime2024_music_18.pdf},
  presentation-video = {https://vimeo.com/902033741},
  abstract = {This performance offers an exploration of sound synthesis and instrumental gestures using the T-Stick, a well-established gestural controller. Mapped to a granulation-based sound engine developed in the SuperCollider environment, the T-Stick transforms into a digital musical instrument (DMI), enabling the performer to shape sounds in real-time. The choice to employ granulation stems from its capability to effortlessly generate complex sounds by creating dense clusters of short "grains" extracted from sound files. This study marks the initial phase of a research project aimed at expanding the T-Stick repertoire and developing new playing techniques for DMIs.},
  numpages = {4}
}

@article{nime2024_music_19,
  author = {Michael Mulshine},
  title = {All Of It},
  pages = {68--69},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {19},
  track = {Music},
  doi = {10.5281/zenodo.15028029},
  url = {http://nime.org/proceedings/2024/nime2024_music_19.pdf},
  presentation-video = {https://youtu.be/BGyzlBk_B18},
  abstract = {‘All Of It’ tries (and necessarily fails) to embrace everything all at once. Mediated through live theatrical performance, dance/movement, and ambisonics tape, ‘All Of It’ reflects a period of hyper-mobility, departure from routine, and dynamic understandings of home. The piece features collaborative making of a DMI/interactive sound object mid-performance and asks the audience to consider the beauty found in the process of creation, opposing understandings of measurements of value resting solely in the artifacts/outcomes of production.},
  numpages = {2}
}

@article{nime2024_music_20,
  author = {Se-Lien Chuang and Andreas Weixler},
  title = {Die Schönheit der Vergänglichkeit},
  pages = {70--73},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {20},
  track = {Music},
  doi = {10.5281/zenodo.15028035},
  url = {http://nime.org/proceedings/2024/nime2024_music_20.pdf},
  presentation-video = {https://youtu.be/cdHGZsppDrI},
  abstract = {The illustrated structure and the organization of lines and strokes are the essence of the Chinese calligraphy. In an artistic analogy to musical expression, the rhythmic dynamics of the hand, the time-shifting method, the articulation of breath, the wet pen/dry nib and the speed of pen movement during the writing-process-momentum combine the characteristics of time and space in a distinctively individual and an immediately compositional way. Here is the occasion to pick up the brush again for the desire of linking the beauty of the cultural treasure with the globally interconnected understanding of contemporary music.},
  numpages = {4}
}

@article{nime2024_music_21,
  author = {Oliver Kwapis},
  title = {Lucky},
  pages = {74--75},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {21},
  track = {Music},
  doi = {10.5281/zenodo.15028039},
  url = {http://nime.org/proceedings/2024/nime2024_music_21.pdf},
  presentation-video = {https://vimeo.com/916572186},
  abstract = {My grandmother, Nana, passed away in New York in the winter of 2020. With the coronavirus still raging, none of my extended family was able to fly east to pack up her apartment. The task, instead, fell to my girlfriend, Amanda, who was living in the city at the time. Near the end of the process, I received a voice memo from Amanda. Sitting at my grandmother’s piano, she recorded one of the last scores that hadn’t been boxed away: Edward MacDowell’s “To a Wild Rose.” For such a gentle and unassuming piece, the music carried startling gravitas. It seemed to me that the music served as the parting statement of an apartment where my grandparents had spent so much of their lives, the last expression of a place that was central to my notion of family. Amanda’s recording allowed me to play and replay its “voice” as often as I needed. "Lucky" explores the ways in which ‘To a Wild Rose’ has helped me process Nana’s death–how it has served as an expression of my grief and a gateway to my memories, as well as a shaper of both. ‘Lucky’ is dedicated to Nana.},
  numpages = {2}
}

@article{nime2024_music_22,
  author = {Yichen Wang and Sandy Ma},
  title = {Unspoken},
  pages = {76--77},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {22},
  track = {Music},
  doi = {10.5281/zenodo.15028043},
  url = {http://nime.org/proceedings/2024/nime2024_music_22.pdf},
  presentation-video = {https://youtu.be/H5AdOE8QnKk},
  abstract = {Unspoken is a mixed reality duet performance that explores the aesthetic possibilities of augmented reality technology as a medium for collaborative musical expression. Two performers with their tangible musical systems are communicated of each other's gestural and spatial musical intention through a collaborative augmented reality interface.},
  numpages = {2}
}

@article{nime2024_music_23,
  author = {Teerath Majumder and James Ilgenfritz},
  title = {In and Out of Phase},
  pages = {78--83},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {23},
  track = {Music},
  doi = {10.5281/zenodo.15028167},
  url = {http://nime.org/proceedings/2024/nime2024_music_23.pdf},
  presentation-video = {https://youtu.be/bDjcRRQ-oAo},
  abstract = {In this performance, a double bass player and a computer-transducer (CT) player improvise using a double bass, two transducers, and a computer. These entities influence and mediate each other's contributions to the sonic outcome. At the technological level, a complex feedback loop is established: (i) a microphone picks up sounds from the bass, (ii) a computer program analyzes this sound, ‘smears’ it, and generates new partials in response, and (iii) the transducers play the ‘smeared’ signal and the generated tones through the body of the bass. While the bass player plays natural harmonics with various articulations adapting to and intervening in the natural flow of information among the entities, the CT player regulates the output of the computer and plays the bass by moving one of the transducers. This interface offers new possibilities of performance that incorporate the tactility of the physical entities, digital transformation of mechanically produced sounds, and a distributed network of human and nonhuman agents.},
  numpages = {6}
}

@article{nime2024_music_24,
  author = {Shawn Greenlee},
  title = {Sluicer},
  pages = {84--88},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {24},
  track = {Music},
  doi = {10.5281/zenodo.15028049},
  url = {http://nime.org/proceedings/2024/nime2024_music_24.pdf},
  presentation-video = {https://youtu.be/6hXwXbzgp9Q},
  abstract = {Sluicer is a performance system for spatial audio improvisation, adaptable to various output channel configurations from stereo to high density loudspeaker arrays. In this work, two 20-voice, erratic synthesizers operate as a roving ‘chorus’ under the player’s direction. Both synths have a series of multichannel effects designed to work specifically with high order ambisonic signals, allowing the player to create and alter spatial dimensions. As audio flows, the guiding action is like closing/opening gates in a lock on a waterway. The results are timbral and spatial churns, swells, floods and drains, motion in repetition, expansion, and contraction. Sluicer is programmed in Max with tactile interfaces being high resolution, multi-touch control surfaces and a DJ-style MIDI controller.},
  numpages = {5}
}

@article{nime2024_music_25,
  author = {Yao Hsiao},
  title = {Consort Yu},
  pages = {89--91},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {25},
  track = {Music},
  doi = {10.5281/zenodo.15028053},
  url = {http://nime.org/proceedings/2024/nime2024_music_25.pdf},
  presentation-video = {https://youtu.be/I5cIZv_ySUQ},
  abstract = {In the piece ‘Consort Yu’ (with Max/MSP), I was inspired by the traditional Chinese Peking Opera ‘The Hegemon-King Bids His Lady Farewell’, which is about the fight between two kings, Xiang Yu and Liu Bang. In the opera, Xiang Yu is surrounded by Liu Bang's forces and on the verge of total defeat. Realizing the dire situation that has befallen them, Xiang Yu’s wife, Consort Yu, begs to die alongside her husband, but he strongly refuses her wish. Afterwards, as he is distracted, Yu commits suicide with Xiang Yu's own sword. I tried to create connections between traditional Peking opera and contemporary electronic music. First, I used timbres and rhythms similar to those used by ‘The Hegemon-King Bids His Lady Farewell’. Also, the musical use of unstable pulses, such as tempo rubato and voice glissando in Peking opera, can relate to the color of contemporary music. Second, I used traditional Peking opera singing style throughout the vocal part. I also used some similar lines from the Peking opera but changed some notes to add different harmonic colors. In the electronics, I sometimes imitated the rhythms the Peking opera, and at other times made different granulated layers of various singing styles in Peking opera. Moreover, I used Leap Motion to better control the gestures of Peking opera in a live performance setting.},
  numpages = {3}
}

@article{nime2024_music_26,
  author = {Julie Zhu and Joseph Gascho and Zachary Kerhoulas and Joshua Cheng and Hogene Kim and Sophia Brueckner and Chandan Bhambhani and James Ashton-Miller and Peng Li},
  title = {Fulgura Frango: Breath-Extended Harpsichord},
  pages = {92--94},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {26},
  track = {Music},
  doi = {10.5281/zenodo.15028172},
  url = {http://nime.org/proceedings/2024/nime2024_music_26.pdf},
  presentation-video = {},
  abstract = {Fulgura Frango is a composition for extended harpsichord and electronics. It is conceptually inspired by Élisabeth Jacquet de La Guerre's opera Céphale et Procris, and many of its techniques refer to Cephale’s bow and arrow that mistakenly pierced Procris’s unwavering heart. Procris is represented by a steady passacaglia reminiscent of de la Guerre’s baroque harmonies, and it is interrupted by multiple interventions: bowing of an amplified horsehair tied to a harpsichord string, goose quill glissandos on the upper tuning pins, and e-bow placements on a small psaltery. In this tragic love story, the cycle of bowing and being stricken represents a perpetual shooting and dying and loving and shooting and dying and loving. In addition, the performer controls frequency shifting parameters through a max patch that takes in his breath data as measured through a hexoskin.  Thoracic inhale pitch-shifts up, whereas abdominal inhale pitch-shifts down, so a taking in a breath increases resulting frequency output.  Though harpsichord is not a wind instrument, the musician’s breath is an interesting and often unnoticed part of the performance.  The performer can also intentionally manipulate the live electronics with their breath, adding another dimension to the composition.},
  numpages = {3}
}

@article{nime2024_music_27,
  author = {Chi Wang},
  title = {AEON},
  pages = {95--96},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {27},
  track = {Music},
  doi = {10.5281/zenodo.15028178},
  url = {http://nime.org/proceedings/2024/nime2024_music_27.pdf},
  presentation-video = {https://youtu.be/LWuolr1jKZ8},
  abstract = {The symbolic abstraction of origin, motion of circle, and the reflection of evolution can be implemented in numerous forms and timespans and can inspire provocative insights into everyday life. Four custom-made controllers – Yuan are used for the performance. Each controller can be performed individually or together with the other three, creating an immersive musical experience.},
  numpages = {2}
}

@article{nime2024_music_28,
  author = {Daniel Fredriksson and Paul Evans and Tanja Jörgensen},
  title = {Vertical Resonance},
  pages = {97--98},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {28},
  track = {Music},
  doi = {10.5281/zenodo.15028065},
  url = {http://nime.org/proceedings/2024/nime2024_music_28.pdf},
  presentation-video = {},
  abstract = {In this performance, the NIME-instrument called Evangistrum is utilized together with a Church Organ (or equivalent) to explore the concept of ‘vertical resonance’: the existential axis of Hartmut Rosas theory of resonance. The Evangistrum is an audiovisual instrument for two performers, designed to promote collaboration, have strong audiovisual congruence and to be intuitive to use while still allowing for more complex levels of expression. The design was built using Unreal Engine, controlled with commercially available midi controllers, and requires two users to operate. The performance was conceived to further explore the Evangistrums possibilities for collaboration and resonance. It was developed as a composition in three parts, with semi-improvised melodic and rhythmic content. The premiere performance in a local church, and the rehearsals leading up to them, including the composition process, were designed as a micro-study, exploring how to learn to play and create on a newly developed instrument, and for the organist how to learn to play with a newly developed instrument. The Evangistrum was further developed during and between these sessions, relating both to the experience of playing and learning the instrument, as well as to composing the music.},
  numpages = {2}
}

@article{nime2024_music_29,
  author = {Dylan Beatttie},
  title = {Tattoo Parlour},
  pages = {99--101},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {29},
  track = {Music},
  doi = {10.5281/zenodo.15028069},
  url = {http://nime.org/proceedings/2024/nime2024_music_29.pdf},
  presentation-video = {https://youtu.be/Gl9q4S5U2w8},
  abstract = {Tattoo Parlour is an improvised performance centred around developing instrument, The Performance Record Lathe. Using a blank disc and a handheld transducer (a ‘cutterhead’), sound is ‘tattooed’ on to the record surface, while multiple tonearms track the evolving grooves. Unlike in traditional ‘record cutting’, which generally lacks agency, the performer can modify anywhere on the disc as well as adjust angle and pressure during inscription. As a result, it is possible to create commercial record-like grooves or undertake more experimental practice such as cross-groove inscription, or overcutting, eliciting sonic characteristic and/or tonearm behaviour change. The cutterhead is fed by audio from looped sections of Maholy-Nagy’s 1933 optical sound film Tönendes ABC and the signals from the pickups are subjected to further processing and effects during performance. As in turntablism and sound art practices, the limitations of phonographic disc as recording medium are celebrated: the repetition of locked grooves are employed to build performance and clicks, pops and other artefacts of process are incorporated into the overall aesthetic. By using a handheld inscription approach, human ‘inaccuracy’ in a medium dependant on microvariation manifests as medium liveness and thereby enables the record and interface to act as performance partner.},
  numpages = {3}
}

@article{nime2024_music_30,
  author = {Simon Blackmore},
  title = {L'UPIC Ludique},
  pages = {102--103},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {30},
  track = {Music},
  doi = {10.5281/zenodo.15028075},
  url = {http://nime.org/proceedings/2024/nime2024_music_30.pdf},
  presentation-video = {https://youtu.be/NSbDbgL3gOE},
  abstract = {L’UPIC Ludique reimagines Xenakis' UPIC (Unité Polyagogique Informatique CEMAMu) instrument as a children’s toy. With its stripped-back, simple, minimal wooden interface, raw audio waveforms can be drawn and manipulated. Different coloured pencils can control various layers of the composition, from drawing audio waveforms to manipulating other parameters and employing compositional techniques such as granular synthesis.},
  numpages = {2}
}

@article{nime2024_music_31,
  author = {Krzysztof Cybulski},
  title = {GranuSpinu},
  pages = {104--108},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {31},
  track = {Music},
  doi = {10.5281/zenodo.15028079},
  url = {http://nime.org/proceedings/2024/nime2024_music_31.pdf},
  presentation-video = {https://vimeo.com/943704694},
  abstract = {GranuSpinu is a custom granular looper used for an improvised performance - a device which takes advantage of digital sound-transforming techniques, while retaining physical form of a small, tangible box.A mechanical spinning disc, representing and controlling the audio loop, makes it possible for both performer and the audience to follow the internal logic of the digital sound transformations, loop playback and manipulations, making GranuSpinu an expressive performance instrument.},
  numpages = {5}
}

@article{nime2024_music_32,
  author = {Vincenzo Madaghiele and Arife Dila Demir},
  title = {Pain Creature},
  pages = {109--113},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {32},
  track = {Music},
  doi = {10.5281/zenodo.15028083},
  url = {http://nime.org/proceedings/2024/nime2024_music_32.pdf},
  presentation-video = {https://zenodo.org/records/11047691},
  abstract = {Pain Creature is an interactive wearable instrument for improvisational movement and sound-making. The instrument materializes the distinct qualities of the performer's chronic pain through visual-tactile-auditory aspects. In this semi-improvised dance performance, Pain Creature embodies the dancer's pain as an unwanted presence, a parasite living on her skin that responds to touch with abstract sonic utterances. The piece unfolds as the dancer explores her relationship with the creature, accompanied by a texture of evolving electronic sounds generated by a live electronic musician. As the piece progresses, the performer explores the choreographic and sonic possibilities of the instrument in a dialogue with the electronic sonic background.},
  numpages = {5}
}

@article{nime2024_music_33,
  author = {Alexandros Kontogeorgakopoulos},
  title = {Talandon},
  pages = {114--116},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {33},
  track = {Music},
  doi = {10.5281/zenodo.15028085},
  url = {http://nime.org/proceedings/2024/nime2024_music_33.pdf},
  presentation-video = {},
  abstract = {Talandon, is a live composition created in 2015 for a custom designed electroacoustic musical instrument, the semantron and light. The music is developed around a basic rhythmic pattern radiated directly from the body of the instrument and from a set of physical models simulating various vibrating structures. The interplay between the rhythmic gestures [form] of the performer and the resonance of the physical and virtual bodies [colour] is enriched, transformed and amplified by the presence of the light component of the composition. Musical sounds and sculpted light create a pure and transcendent soundscape and landscape; silence and shadows express the inner fine values of the work. The composition seeks spirituality and interprets Kandinsky's language of form and colour.},
  numpages = {3}
}

@article{nime2024_music_34,
  author = {Giacomo Lepri and Nicola Privato},
  title = {Magnetologues},
  pages = {117--121},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {34},
  track = {Music},
  doi = {10.5281/zenodo.15028087},
  url = {http://nime.org/proceedings/2024/nime2024_music_34.pdf},
  presentation-video = {https://youtu.be/4qbK3cw3E5M},
  abstract = {Stacco is a new NIME, embedding magnetic attractors that detect variations in the surrounding magnetic fields. It attracts and repels magnetic spheres displaced by the performer, allowing both fine musical control and the emergence of unpredictable interactions out of its interlaced magnetic forces. Stacco has been designed to perform with neural synthesis models, where multidimensional sonic spaces can be navigated through the exploration of tangled control parameters. It comes with two graphical scores that function as guides for the exploration of the neural synthesis model. By drawing on the surface of the interface, it is also possible to create new scores and layer them on top of each other. We propose a performance titled ‘Magnetologues’, with two Staccos, one operating as a neural audio engine and the other controlling in real-time the sound in space via Ambisonics.},
  numpages = {5}
}

@article{nime2024_music_35,
  author = {Filiippo Angeloni and Domenico Stefani and Matteo Tomasetti},
  title = {Performance with Esteso: Interactive AI Music Duet Based on Player-Idiosyncratic Extended Double Bass Techniques},
  pages = {122--125},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {35},
  track = {Music},
  doi = {10.5281/zenodo.15028089},
  url = {http://nime.org/proceedings/2024/nime2024_music_35.pdf},
  presentation-video = {https://youtu.be/oncw3G4sLuM},
  abstract = {Esteso is an interactive improvisational system for double-bass based on player-idiosyncratic extended techniques. It was created in collaboration with the contemporary double-bass player and composer Filippo Angeloni and tailored for his personal vocabulary of extended techniques. In Esteso, the musician and an AI counterpart take turns in an improvisational duet. The system's response consists of a manipulation of the real double-bass, achieved live through a timbre-transfer neural network, granular synthesis, and reverberation. The timbre-transfer network was trained on generic double-bass recordings, resulting in a peculiar ‘hybrid’ double-bass sound. We Machine listening is integrated in the form of a real-time classifier of extended techniques played on the double-bass, whose output controls the sound manipulation process to affect various techniques differently. The personal extended techniques chosen for Esteso are: ‘Brushed’ Jeté, Sfregato con legno, and Percussive. Here, we propose a 10/15 minutes improvised duet performance where the double bass player interacts with Esteso, creating an action-reaction interplay between acoustic and virtual.},
  numpages = {4}
}

@article{nime2024_music_36,
  author = {Cléo Palacio-Quintin},
  title = {ALÉAS: La connaissance ruisselée des solides / Streamed knowledge of solids, for hyper-bass-flute, live electronics, interactive video and recited poetry},
  pages = {126--129},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {36},
  track = {Music},
  doi = {10.5281/zenodo.15028091},
  url = {http://nime.org/proceedings/2024/nime2024_music_36.pdf},
  presentation-video = {https://youtu.be/tFteIMbsSeA},
  abstract = {ALÉAS is a cycle of 12 transdisciplinary creations, which combines music (acoustic and electroacoustic) and visual creations (drawings, collages, objects, photographs and videos) with original poetry. Stemming from cosmological reflections, these works question the conception that we have of the universe that surrounds us, through poetic journeys exploring nature and matter (including the five fundamental elements: water, air, earth, fire, cosmos). This creative work is inspired by the concept of diagonal sciences of Roger Caillois, a form of interdisciplinarity of knowledge, in which the invisible, the underground relations must be exhumed in order to allow the emergence of a new and more complex image of the universe. Thus, in these compositions, the intertwining of sounds, images and poetry triggers multiple perceptions in synesthesia, blurring the boundaries between reality, illusion and imagination. This first composition of the cycle, ‘Streamed knowledge of solids’ is inspired by the materials that form the earth. Although they seem at first sight to be inert substances, rocks carry within them their whole history. A multitude of elements from the past are inscribed in their geological constitution, shaped over millennia by melting, sedimentation and water runoff. The structure and shape of each stone tells us where it came from and how it came to end up in that particular and unique shape. Matter can thus reveal profound knowledge. The work is performed on the Hyper-Bass-Flute, an instrument on which multiple sensors captures the subtle tactility and movements of the performer. They interact with live electronic processing of the flute’s acoustic sound, as well as with the photo and video images that are mixed in real time and vary constantly. All electroacoustic sounds of the piece are generated in real time from the sounds of the live performed bass flute. Only the voice of the poet was recorded to be added to this performance.},
  numpages = {4}
}

@article{nime2024_music_37,
  author = {Victor Shepardson and Sophie Skach},
  title = {Learning Machine Knit Minput Intertextiles},
  pages = {130--134},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {37},
  track = {Music},
  doi = {10.5281/zenodo.15028093},
  url = {http://nime.org/proceedings/2024/nime2024_music_37.pdf},
  presentation-video = {https://youtu.be/VT8Ht0lf_F4},
  abstract = {What lies among these loops of copper, wool and steel? Skin, yarn and wire form a circuit, machine precision meets somatic sense, and tactility elaborates algorithmic entanglements. In this performance, e-textile pieces are patched into a no-input mixer, while player uses interactive machine learning tools to embroider sonic layers onto a repeated gesture. Analog audio signals from a no-input mixing board are routed through a piezoresistive mat which has been knitted from wool and steel yarns. The performer first develops a patch on the no-input mixing board to sound a two-handed pressing gesture on the mat. Then, the they alternate between performing the gesture and refining mappings between a machine listing algorithm and additional layers of sound using the anguilla interactive machine learning package.},
  numpages = {5}
}

@article{nime2024_music_38,
  author = {Mark Hanslip},
  title = {PlayTrainPlay},
  pages = {135--137},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {38},
  track = {Music},
  doi = {10.5281/zenodo.15028095},
  url = {http://nime.org/proceedings/2024/nime2024_music_38.pdf},
  presentation-video = {},
  abstract = {‘PlayTrainPlay’ is a structured solo human-computer improvisation in two parts. It combines instrumental improvisation with granular synthesis, machine listening and neural networks. Through its structure, PlayTrainPlay describes the process of collecting data, training a neural network and interacting with the resulting model through musical performance; its structure can also be said to represent the transition from a physical effects interface to a data-based one. These concepts are additionally communicated through the projection of live visuals consisting of code outputs, performance footage and abstract audio-reactive images. Section 1 employs a real-time granular effect whose parameters are manipulated via a foot controller. Over the course of this section, analysis of the saxophone's timbre and corresponding effect parameters are logged before the performer triggers training of the neural network. In Section 2, the neural network controls the effect, which is deployed in a loop that the performer interacts with. This work motivates further use of data model-based interfaces for instrumental effects by instrumentalists themselves. It proposes the use of data collection and modelling during performance as a means to create unique situation-based interactions. Lastly, it promotes the use of neural networks as a way of simplifying musicians' workflows.},
  numpages = {3}
}

@article{nime2024_music_39,
  author = {Andrew Watts},
  title = {What it means to be post-human},
  pages = {138--141},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {39},
  track = {Music},
  doi = {10.5281/zenodo.15028181},
  url = {http://nime.org/proceedings/2024/nime2024_music_39.pdf},
  presentation-video = {},
  abstract = {‘What it means to be post-human’, explores the intersection of technology and human performance. Drawing inspiration from ‘A Dialogue, In Absentia’, this work advances the concept of integrating human performers with digital sound processing in a futuristic, collective context. The composition utilizes purpose built, original Bluetooth speakers and headset devices to direct processed sounds into performers' mouths, enabling them to modulate audio output through physical movements. This innovative approach transforms performers into live acoustical filters, adding human texture to digital sounds, and challenges traditional distinctions between musicians and instruments. The compositional framework employs a hocket technique to create a cohesive auditory experience from individual inputs, embodying the NIME 2024 theme ‘Tactility in a hybrid world‘. This piece exemplifies the fusion of tactile human interaction and digital technology in music, highlighting sustainability and adaptability in post-pandemic performance contexts. ‘What it means to be post-human‘ contributes to the discourse on new musical interfaces by redefining the role of the human body in musical expression and demonstrating the enhanced possibilities when merging human and technological elements. The composition invites reevaluation of musical performance boundaries and exemplifies the potential of technology in expanding the capabilities of human artistic expression. This work not only adds to the field of musical technology but also provokes thought about the future of human and digital collaboration in art.},
  numpages = {4}
}

@article{nime2024_music_40,
  author = {Ka Hei  Cheng and Irina Kruchinina and Matin Esmaeili},
  title = {Phantom of Utopia},
  pages = {142--145},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {40},
  track = {Music},
  doi = {10.5281/zenodo.15028099},
  url = {http://nime.org/proceedings/2024/nime2024_music_40.pdf},
  presentation-video = {https://youtu.be/NeAsumJOG2U},
  abstract = {Chinese Calligraphic Dance (CCD) is introduced in this paper as an innovative artistic discipline synthesizing traditional calligraphy, dance, and interactive technology. The elements utilized in the performance derive exclusively from traditional Chinese characters, grounded in the clerical script that originated during the Han Dynasty around 200 BCE. In the historical context of Chinese calligraphic strokes (elements of Chinese words), our interdisciplinary approach transcribes these strokes into gestures, translating them into generative music and visual media through motion tracking. The present interdisciplinary exploration, influenced by somaesthetic principles, aims to deepen our awareness of bodily perception as well as provide an immersive engagement with Chinese calligraphy culture.},
  numpages = {4}
}

@article{nime2024_music_41,
  author = {Alex Lucas and Barry Cullen and Saul Rayson},
  title = {Vapour Waves: Synths Powered by Discarded E-cigarettes },
  pages = {146--148},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {41},
  track = {Music},
  doi = {10.5281/zenodo.15028101},
  url = {http://nime.org/proceedings/2024/nime2024_music_41.pdf},
  presentation-video = {https://youtu.be/DGdjzq3qgSs},
  abstract = {Over the past two years, an abundance of e-waste has grown on the streets of Belfast City. Keeping company with the plastic packaging and drinks containers one has grown to expect are so-called disposable vapes or e-cigarettes. This e-waste has a new identity; it exists outside landfill sites and WEEE collection points. This is e-waste as litter! For the digital instrument makers and composer-designers who author this group, this situation illustrates the disconnect many of us hold between what we consume and its means of production. The composite nature of most products renders them and their associated supply chains highly complex. Furthermore, manufacturers must be more forthcoming in highlighting ethical issues in their supply chains. This performance is a small act of resistance. The instruments used are powered by disposable vape batteries, highlighting the value of this rechargeable resource, which we're told to throw away. Doing so opens a space for conversations around the human rights issues at the bottom of the lithium battery supply chain. In the spirit of inclusive musicking, the group invites attendees from the companion NIME 2024 Vapour Waves workshop to perform alongside their bespoke creations as part of a locally-populated, crowdsourced group of performers. The piece is composed with ample space for improvisation. Four short movements showcase the instrument's potential, focusing on harmonic drones, rhythmic interplay, timbral variation and the ability to create tension between control and chaos. The limitations of the technology are productive constraints to be explored. Incorporating the NIME 2024 theme, these Vapour Wave instruments are inherently tactile; they invite touch and physical manipulation. Our ‘hybrid world’ manifests in the instrument's use of bought and found components.},
  numpages = {3}
}

@article{nime2024_music_42,
  author = {Christian Faubel},
  title = {Songs from my analogue utopia},
  pages = {149--150},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {42},
  track = {Music},
  doi = {10.5281/zenodo.15028105},
  url = {http://nime.org/proceedings/2024/nime2024_music_42.pdf},
  presentation-video = {https://vimeo.com/367880723},
  abstract = {In Songs from my analogue utopia, I explore the self-organizing coordination dynamics of analog oscillators and the Utopian potentials of analogue communication. In analogue communication, synchronization results from the mutual interaction of two or more processes, not a single process is dominating the other. It is in the mutuality where I see the Utopian potential of analogue communication. I undertake this exploration on the screen of an overhead projector, where I place little motors driven by analogue oscillators. The motors hit on rubber bands or other objects which are equipped with piezo-pickups, rendering the rhythmical hitting of the motors into sound and into a shadow play.},
  numpages = {2}
}

@article{nime2024_music_43,
  author = {Chiara Percivati and Claudio Panariello},
  title = {WYPYM - Were you a part of your mother?},
  pages = {151--155},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {43},
  track = {Music},
  doi = {10.5281/zenodo.15028109},
  url = {http://nime.org/proceedings/2024/nime2024_music_43.pdf},
  presentation-video = {},
  abstract = {This performance presents, through artistic means, the current state of development of the feedback-augmented bass clarinet—a NIME instrument previously created by the two authors. The performance aims to showcase improvements made to the instrument, both in terms of hardware and software. Regarding hardware and instrument design, after experimenting with different neck extensions realized through CAD and 3D printing—enabling the insertion of our first microphone into the instrument body and a more refined tuning of the instrument—we decided to focus on the use of an intra-mic to capture the bass clarinet sound. This not only ultimately addressed previous issues with tuning, but also enhanced the playability of the feedback-augmented bass clarinet, aligning it more closely with traditional performance practices. Consequently, this augmented instrument is potentially approachable by a larger number of performers. Improvements in the software, such as in-depth control of the audio routing and a feedback calibration routine, have addressed issues related to the freedom and playability of the system that the authors experienced while working on the previous model. The performance features a new version of the piece ‘WYPYM - Were you a part of your mother?’, for bass clarinet and feedback system. The work explores the relationship between the performer on the augmented bass clarinet and the feedback system, and is based on active listening, constant adaptation, and precarious balance.},
  numpages = {5}
}

@article{nime2024_music_44,
  author = {Daniel Jones},
  title = {La durée (working title)},
  pages = {156--157},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {44},
  track = {Music},
  doi = {10.5281/zenodo.15028113},
  url = {http://nime.org/proceedings/2024/nime2024_music_44.pdf},
  presentation-video = {},
  abstract = {La durée explores different notions and spans of time, from the instantaneous to the eternal. Using high-resolution real-time spectral analysis and a control interface comprised of an array of high-resolution rotary encoders, a vast palette of acoustic material is frozen in time, dilated, blurred and sliced.},
  numpages = {2}
}

@article{nime2024_music_45,
  author = {Patrick Hartono},
  title = {Ciung Wanara},
  pages = {158--160},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {45},
  track = {Music},
  doi = {10.5281/zenodo.15028115},
  url = {http://nime.org/proceedings/2024/nime2024_music_45.pdf},
  presentation-video = {https://youtu.be/UFeEJXJj0gw},
  abstract = {This piece explores audiovisual composition using hand gestures as the primary means of interaction. It adapts the Sabetan technique of Indonesia's Wayang Kulit shadow puppetry, aiming to demonstrate embodied audio-visual interaction. Sabetan involves expressive gestures by the puppeteer, conforming to the scene's characterization. The embodied interaction is performative, creating audio and visual elements simultaneously. It draws on Michael Chion's ‘added-value’ concept. A choreographed hand movement, incorporating Sabetan, facilitates real-time interaction with a depth camera and machine learning. This concept is implemented in Ciung Wanara, an interactive music system integrating Wayang Kulit and supervised machine learning. The system also employs the Polymorphism Sound synthesis method. ""Ciung Wanara"" is an interactive audiovisual composition inspired by Indonesian shadow puppet battles. It features rooster avatars responding to the performer's gestures, recreating the tale of Ciung Wanara, a wise king defeating an evil sorcerer. The Sabetan technique and FluComa machine learning enable simultaneous control of sound synthesis, spatialization, and visuals. Two avatars with a narrative driven by hand gestures create a unique immersive experience, uncommon in traditional audiovisual composition, engaging both performer and audience.},
  numpages = {3}
}

@article{nime2024_music_46,
  author = {Iurii Kuzmin and Zhengyang Ma and Raul Masu},
  title = { 竹脑 - zhu nao },
  pages = {161--163},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {46},
  track = {Music},
  doi = {10.5281/zenodo.15028184},
  url = {http://nime.org/proceedings/2024/nime2024_music_46.pdf},
  presentation-video = {},
  abstract = {This performance presents 竹脑 (zhu nao) a new instrument based on bamboo craftsmanship as both an archetypal technical practice in South East Asia and the articulation of symbolic and technical dimensions of the material. This instrument was devised to explore the concept of environment improvisation – an approach to free improvisation grounded in aesthetics and philosophy of shanshui – traditional Chinese landscape painting and the associated way of forming affective relations with environment and locality (Wang 2021). This allows us to frame these reference points: bamboo craftsmanship and environment improvisation as cosmotechnical activities, following Yuk Hui's proposition to abandon the one-sided narrative of Western technological modernity in favor of pluralist notion of technodiversity.},
  numpages = {3}
}

@article{nime2024_music_47,
  author = {Jonas Braasch},
  title = {Microcosm for Sonic Mediation Table and Wave Field Synthesis},
  pages = {164--165},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {47},
  track = {Music},
  doi = {10.5281/zenodo.15028189},
  url = {http://nime.org/proceedings/2024/nime2024_music_47.pdf},
  presentation-video = {https://vimeo.com/913265461},
  abstract = {The sonic meditation table is part of the artists extended saxophone practice. It is an inverted soprano saxophone with clamped keys and different mouthpieces attached to the saxophone through a hose for low frequency drone tones. The instrument was inspired by Pauline Oliveros’ Deep Listening Practice and Mazen Kerbaj’s improvisational trumpet work. For this conference presentation, the sonic mediation table is augmented by a wave field synthesis installation with live electronics (VCV rack with Max/MSP) also using a spatialization technique called virtual microphone control that was developed by the performer.},
  numpages = {2}
}

@article{nime2024_music_48,
  author = {Nolan Hildebrand and Timothy Roth},
  title = {Generative open graphic score #1},
  pages = {166--171},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {48},
  track = {Music},
  doi = {10.5281/zenodo.15028121},
  url = {http://nime.org/proceedings/2024/nime2024_music_48.pdf},
  presentation-video = {https://youtu.be/gayAyjdJRzY},
  abstract = {Generative open graphic score #1 is a work that uses the software program Touchdesigner to design and build generative processes that create an open graphic score/notation. In performance the digital score produces a plethora of graphic symbols—from simple ink blot-esque dots and abstract globular shapes to complex webs of broken grid patterns interacting with sharp and angular geometric shapes. The electroacoustic aspects of this work utilize mixer feedback. Mixer feedback is created when the inputs of the mixer are routed back into its outputs to create a (feedback) loop. Manipulating the mixer’s, faders, dials, and buttons creates unpredictable electronic sounds ranging from simple and harmonious to chaotic and noisy. The setup for generative open graphic score #1 consists of an instrumentalist patched into a mixer with feedback loops being played by another performer. In this novel electroacoustic setup, the sounds, and timbres of the two instruments can clash and contrast or synthesize and melt together. In performance, the instrument patched into the mixer transmutes into a noise-laden super-instrument that in turn can mutate the behavior of the electronic sounds together with the mixer performer. I have dubbed this live electroacoustic system/process as ‘Instrumentalist and Mixer Feedback Transmutation’ (IMFT).},
  numpages = {6}
}

@article{nime2024_music_49,
  author = {Nicholas Shaheed},
  title = {degr d t  n},
  pages = {172--173},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {49},
  track = {Music},
  doi = {10.5281/zenodo.15028196},
  url = {http://nime.org/proceedings/2024/nime2024_music_49.pdf},
  presentation-video = {https://vimeo.com/943876017},
  abstract = {Slow, repetitive, contemplative, and noisy. Repeatedly-applied neural reconstructions fail slowly and imperceptibly as feature space is explored. This performance uses the ‘I Am Sitting in a (Latent) Room’ improvisation system. Inspired by Alvin Lucier's ‘I Am Sitting in a Room’ and the general process of degrading sound by repeatedly passing it through an acoustic medium, it is a system that allows the improvisers to interact with the process of degradation in real time. Using a bespoke variational autoencoder (VAE) model, a 25-second audio clip is repeatedly encoded and decoded through two parallel instances of the model. On top of this process, the performers take on the role of improviser. By manipulating the model's latent embeddings of the audio in real-time, they explore the latent space (or ""room"") of the model over the course of the performance.},
  numpages = {2}
}

@article{nime2024_music_50,
  author = {John Ferguson and Nicole Carroll},
  title = {Modular Mechanical Systems},
  pages = {174--176},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {50},
  track = {Music},
  doi = {10.5281/zenodo.15028198},
  url = {http://nime.org/proceedings/2024/nime2024_music_50.pdf},
  presentation-video = {},
  abstract = {Modular Mechanical Systems (MMS) is a study of DIY handmade electronic music systems utilising light sensors and kinetic movement as audio and control sources. It explores tactile feedback systems where performance gestures and light control and reception enable cyclical sonic motifs. Rotating frames are mounted on bearings/motors that support panels of coloured acrylic that function as light filters. Below this, embedded into the surface, are photocells routed to bespoke circuitry based on the 40106 CMOS IC and 6N138 optocoupler. Thus, the initial soundworld is generated via standalone synthesisers that are tangible (performed via rotation by hand and motor) and highly responsive/performable via light. A range of complimentary MIDI controllers with computer-controlled LEDs and accelerometers are used to process and augment the other boxes. The modular design allows an infinite array of potential performance outcomes. MMS considers how each element–hardware and software, tangible and virtual–of the system can both enact and respond to generative processes through gestural control and light manipulation. The authors explore the role and affordances of each element and how it contributes towards the temporal sonic and visual space. This question arises during both the design and interactive performance. During performance, the authors explore shifting timbres, rhythms, and recurring sonic motifs by manipulating the boxes' configuration and their relationship to one another as well as light positions and filters. The interplay of emerging textures with the performers' responsiveness and interaction highlights the affordances of handmade bespoke systems toward musical structures in non-linear systems. While improvisation and experimentation are at the heart of the composition process, the system allows for curated and repeatable performance outcomes.},
  numpages = {3}
}

@article{nime2024_music_51,
  author = {Rebecca Abraham and Albert Zhang},
  title = {A Thousand Mornings},
  pages = {177--179},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {51},
  track = {Music},
  doi = {10.5281/zenodo.15028202},
  url = {http://nime.org/proceedings/2024/nime2024_music_51.pdf},
  presentation-video = {},
  abstract = {This work introduces a performance piece for two dancers co-creating movement and music with the Magical Musical Mat (MMM), an interactive instrument that amplifies touch with sound. Through a series of structured improvisations and choreographed sequences, performers explore the expressive potential of the MMM's tactile interface, creating rich sonic textures with an evocative movement vocabulary that explores the nuances of human touch. In addition to its artistic objectives, the performance serves as a platform for exploring the technical capabilities of the MMM and pushing the boundaries of interactive music systems. By showcasing the MMM in a live performance context, we aim to demonstrate its potential as a versatile and expressive tool for artistic expression, while also inviting critical reflection on the role of technology in shaping our relationship with sound and movement.},
  numpages = {3}
}

@article{nime2024_music_52,
  author = {Robin Foster and John Bowers},
  title = {Stuff In A Box},
  pages = {180--182},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {52},
  track = {Music},
  doi = {10.5281/zenodo.15028203},
  url = {http://nime.org/proceedings/2024/nime2024_music_52.pdf},
  presentation-video = {},
  abstract = {This performance derives from our ongoing research into ‘hybrid-rummaging’; exploring how the physical performance practice of rummaging can be hybridised through digital technology. Rummaging is a practice centred around using the hands and a box of found objects to make noise. Our hybrid-rummaging expands this practice, seeking to explore how rummaging as a paradigm might be applied at every level of our performance ecology. We work with a range of technologies, from RFID, Bluetooth and video-tracking to tilt switches, electromagnetism and raw voltages, investigating how rummaging might be interfaced with these technologies, and the ways in which the technologies themselves might be appropriated, plundered and rummaged. We believe our practice enables us to speak to fundamental issues in NIME and explore them in performance, matters such as the relationships between gesture and sound, different forms of materiality, and the sense we can give to concepts such as ‘interface’, ‘instrument’ and ‘expression’. Our approach to hybridism differs from many approaches that can be found in NIME. We do not translate one form of materiality into another. We do not get different materials or actions on them to relate via abstraction or representation. Rather, we treat all objects at the same level, a truly flat ontology in which things, our hands included, collide. Our work is, in some respects, a boundary condition for NIME research and performance that we hope will provoke reflection on these and other affairs: it’s all stuff in a box.},
  numpages = {3}
}

@article{nime2024_music_53,
  author = {Matthew Rogerson},
  title = {Dromos/Autos: The Autistic Ontology as Performance},
  pages = {183--184},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Laurel Smith Pardue and Palle Dahlstedt},
  year = {2024},
  month = {September},
  address = {Utrecht, Netherlands},
  issn = {2220-4806},
  articleno = {53},
  track = {Music},
  doi = {10.5281/zenodo.15028213},
  url = {http://nime.org/proceedings/2024/nime2024_music_53.pdf},
  presentation-video = {},
  abstract = {The essence of this research performance-project is comprised of a transgressive implementation of ‘neurofeedback’; a process in which one attunes and self-regulates their own cognitive and emotional functioning via the utilisation of EEG (electroencephalography) to harness their brainwaves and generate external audio and/or visual stimuli, which in turn consecutively modulate their brainwave patterns to desired, often placative results; a feedback loop. The transgressive nature of this performance derives from the conceptualisation of neurofeedback as a process that induces negative cognitive consequences, by means of a ‘provocative’ audio-visual performance ecology the performer is both a passive mediator and subject to; engendered via cascading digital ‘provocative' systems established within Max/MSP. The performance leverages, and assigns primacy towards, the artist/performers autistic cognition; a particularly idiosyncratic and revealing interface for performance and musical expression which can serve to auto-ethnographically evoke and deconstruct the systemically debilitating socio-economic constructs and metanarratives of the social model of disability, represented by the provocative performance ecology, that disempower members of the autistic and wider disability community.},
  numpages = {2}
}
