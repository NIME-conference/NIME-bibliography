@article{nime23-music-12,
  author = {Christos Michalakos},
  title = {SPLT/SCRN: A Game-Piece for Dueling Improvisers},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_1.pdf},
  note = {Live Concert 1, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {12},
  abstract = {SPLT/SCRN is a game-piece where two improvisers play against each-other using their instruments as game controllers. The piece consists of multiple randomized mini-challenges where the performers need to improvise in order to understand what musical gestures are required from them through positive feedback from the screen. The mini-games cover a range of musical affordances, giving the advantage to both instrumentalists at different times. The instrument signal is analysed in real-time using machine learning techniques through Max/MSP, and used as control data for both the progress within the game, as well as the control of the live electronics. These parameters are then sent through OSC to the game engine Unity and control the game. In addition, the hybrid system makes use of DMX-controlled lights, which are also mapped to control data and game levels. On-screen events are accentuated through lights within the physical space, merging the physical and the digital.}
}

@article{nime23-music-13,
  author = {Anderson Maq},
  title = {(ex)tension by Fabrizio di Salvo in collaboration with reConvert},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {13},
  abstract = {Our idea starts from the necessity to investigate space, explore its features, find the potential in acoustic properties, and use them as a starting point for our research. How is it possible to create a three-dimensional and analog sound system? How are we able to work with instruments that can move sound in space? Taking advantage of the use of customized industrial items, we will have the possibility to create three-dimensional audio images controlled and designed in real-time by the performers. The concept that interests us is the single percussive impulse as a music creator. We can change the surface, and speed of the execution but the impulse is at the core of every percussive action. Solenoids are our artistic medium and the interesting aspect is the relationship between us as human performers and the possibilities that arise through our interaction with a complex mechanical instrument. Thus we see in this instrument an extension of our percussive possibilities.}
}

@article{nime23-music-19,
  author = {Rob Hamilton},
  title = {Elegy (Ready, Set, Rapture)},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {19},
  abstract = {Elegy (Ready, Set, Rapture) is the second work composed for Coretet, a virtual reality musical instrument modeled after traditional bowed stringed instruments including the violin, viola, cello and double bass. Elegy (Ready, Set, Rapture) is a solo multi-channel performance for the Coretet double bass that combines a pre-composed musical chord structure displayed on the neck of the instrument in real-time with improvisation. Coretet is built using the Unreal Engine and is performed using the Oculus Rift or Quest 2 head-mounted displays and Oculus Touch controllers. All audio in Coretet is procedurally generated, using physical models of a bowed string from the Synthesis Toolkit (STK) and a waveguide plucked string, all running within Pure Data.}
}

@article{nime23-music-26,
  author = {Boris Wilmot},
  title = {ALEA(s)},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {26},
  abstract = {Born from the will to offer a unique live experience, ALEA(s) delivers boiling, improvised performances mixing live drawing, video animation and electronic music.  Surrounded by their audience, the three members are busy creating their show, without any safety net. While the complex, loaded electronic music fills the room, the illustrator’s physical implication in his drawings and the hypnotic animations projected onto the big screen unite to finish this well-rounded show.  ALEA(s) performances are often described as immersive, intense and crafted.}
}

@article{nime23-music-28,
  author = {Sunhuimei Xia},
  title = {The Center of the Universe},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {28},
  abstract = {The Center of the Universe was inspired by my impression of New York City after several trips to this world center. When I stood at the top of the Empire State Building, I felt that it absorbed the energy of the entire universe. People with different backgrounds travel to New York from all over the world, creating a colorful and spectacular city. The primary material in this work is the text “The Center of the Universe.” This text is stated and manipulated in various languages, including English, Spanish, French, German, Italian, Russian, Chinese, Japanese, Korean, and Thai. All the human voices come from the sampled AI voices of the MacOS system. Two Bluetooth Nintendo Wiimote Controllers provide the capability to stand untethered at center stage and play this composition.}
}

@article{nime23-music-29,
  author = {Seth A Davis},
  title = {“Chomsky Hash” for improvisation, electric guitar, and live electronics},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {29},
  abstract = {“Chomsky Hash” is a piece for improvisation, electric guitar, and live electronics. The piece utilizes traditional guitar effects processing with a variety of unconventional effects for the instrument, along with a surround panner setup for quadraphonic sound. The laptop and electronic elements also act as improvising agent, with a variety of chance operations that allow the computer to make decisions for itself in performance. The title is a reference to the famous debate between Noam Chomsky and Michel Foucault. Famously, Foucault asked to be paid in a large amount of hash for his participation in the debate. Friends would say that on special occasions Foucault would break out “that Chomsky Hash”. The relevance of this debate to the piece is the elements I’m working with and transforming. The electric guitar itself has a long history in American popular music and has a lot of specific cultural connotations that could seem traditional even though at times it’s been a counter cultural symbol. With the use of DAW’s such as Ableton Live or Max/MSP, the electric guitar can be further altered and expanded upon. Noam Chomsky is considered a radical and countercultural figure in American politics, but within the debate with Michel Foucault comes off as traditional and conservative compared to Foucault’s Dionysian and hedonistic character traits. The debate itself is an interesting synthesis of the two thinkers' ideas. The main driving factors of the piece are improvisation, timbral transformation, live electronics processing, and spatialization. Since 2019, I’ve been working on bringing together my instrumental background as a guitarist and improviser with my interest in electronic music. This piece is a part of a series of pieces for electric guitar \& live electronics.}
}

@article{nime23-music-36,
  author = {Qiujiang Lu},
  title = {Galactic Madness},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {36},
  abstract = {Galactic Madness is a structured improvisational network piece inspired by a set of pictures of the galaxy taken by NASA's James Webb Space Telescope(released in June 2022). After closely observing the pictures for hours, I wanted to create a mesmerizing system that resembles the infinite and enigmatic nature of the galaxy.}
}

@article{nime23-music-52,
  author = {Matthew Goodheart},
  title = {Refraction Interlude: piano},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {52},
  abstract = {“Refraction Interlude” features a solo performer surrounded by a battery of gongs and cymbals that are activated by surfaces transducers. The metal percussion responds to the performer’s improvisation, seeming to sound autonomously. The work can be performed by any instrument. Each new performer records a set of samples, short improvisations centered around a specified set of techniques. These recordings are then analyzed and used to as a foundation for forms of mixed synthesis, generating sounds that are tailored to the specific acoustical properties of the metal percussion. This iteration of the work is a new realization for piano.}
}

@article{nime23-music-66,
  author = {Paul Stapleton and Ricki O'Rawe},
  title = {Where is that Batallón de San Patricio Groove?},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_4.pdf},
  note = {Live Concert 4, Thursday June 1, Centro de Cultura Digital},
  articleno = {66},
  abstract = {Our duo -ence improvises live remixes of augmented 7” vinyl records combined with performance on, and sequenced sampling of, custom-made elecroacoustic instruments. Our collaboration draws on Anon2’s experience in art installation contexts and with electronic dance music group Anon, and Anon1’s work as an instrument inventor, sound designer and improviser in groups such as Anon and Anon. Our performance for NIME 2023 begins by asking, what kind of strange rhythmic futures will continue to be built at the intersection of Mexican and Irish cultures? To aid this endeavour, we invoke the mythology of Batallón de San Patricio, a group of disenfranchised European (largely Irish) immigrants and African slaves who defected from the United States Army to fight on the side of the Mexican Army during the Mexican–American War of 1846–48. The battalion has been memorialised by a broad range of musicians, novelists and filmmakers. These accounts provide stories of cultural resonances in the lives of diverse peoples, unlikely collectives who formed allegiances through their shared oppression at the hands of dominant imperialist powers. Our storytelling here is similar, but also different. While we are interested in resonances, allegiances, and points of connection that form moments of tense but productive co-existences between different communities, we are likewise drawn towards the precarious, noisy and uncertain material processes enacted in such meetings. Thus, we seek a kind of dissensual groove, an oscillation between distance and relation, remixing fragments from Irish and Mexican music traditions into fragile and ever-collapsing rhythmic architectures, creating spaces in which to move.}
}

@article{nime23-music-73,
  author = {Takumi Ikeda and Hanako Atake and Iannis Zannos},
  title = {Unboxing: Public-Space Performance With Wearable-Sensors And SuperCollider},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {73},
  abstract = {This piece is an mobile outdoor performance where a dancer wearing mobile wireless IMU sensors controls sound generated by a laptop through their movements. The performance is mobile, and can take place in any available public space. The dancer's movements acquired by the sensors drive sound generation algorithms running on SuperCollider and output from a mobile speaker. Since all the hardware is commercially available and relatively inexpensive, this system is easy to build. Through this work, we are showing that a performance that is not bound by location is possible through a relatively inexpensive and easy-to-construct performance system. The title "Unboxing" refers to escaping from the economic, social, political, and artistic constraints of conventional performances. It also alludes to “unboxing” as an internet meme in online videos where one does not know what is contained in the box before it is opened - as the performance data and the resulting sound structures cannot be evaluated beforehand. This project aims to open up computer music creativity to a wider audience through frugal technology and escape Western-centric concepts of music and dances. As alternative, we propose the term “electronic sound performance”.}
}

@article{nime23-music-1099,
  author = {Yichen Wang and Charles Patrick Martin},
  title = {Music(re)ality: A Collaborative Improvisation between Virtual and Real World},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1099},
  abstract = {Music(re)ality is a collaborative musical performance between the virtual and real world. Two musicians will present a musical improvisation, with one performing with an iPad instrument and the others using a freehand augmented reality musical instrument. While musicians are physically located in the space, the music jamming will happen across a virtual and real environment. How will the collaboration happen and what is a mixed reality musical performance? Through sonic feedback or performers' musical gestures? It will all be demonstrated in this performance.}
}

@article{nime23-music-1101,
  author = {D Stewart},
  title = {Sculpture DAXR},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_4.pdf},
  note = {Live Concert 4, Thursday June 1, Centro de Cultura Digital},
  articleno = {1101},
  abstract = {The performance of Sculpture DAXR is an offshoot of the Oscuterium project, created by the group, RedSpills, a collaborative trio of new musical instrument technologists, artists and performers: Michał Seta (Montreal, Quebec, Canada), Dirk Stromberg (Republic of Singapore), and D. Andrew Stewart (Lethbridge, Alberta, Canada). While Sculpture DAXR can be experienced as a live, in-person, multi-media show involving the karlax digital musical instrument, live coding, video and sound projection, this work is best experienced in its original form: a hybrid performance and experience in which the participants (performer and audience) inhabit both a live venue in real life (IRL) and a 3D virtual reality (VR) meeting point in Mozilla's real-time communications platform, Hubs. The innovative nature of this work arises from the production of sound directly within the Hubs environment using the Faust (Functional Audio Stream) programming language (i.e., browser-based software synthesis engine). Both sound creation and 3D objects are transformed by real-time data transmitted from a DMI over the internet.}
}

@article{nime23-music-1110,
  author = {Ivica Ico Bukvic},
  title = {Transcontinental Grapevine},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_3.pdf},
  note = {Live Concert 3, Thursday June 1, Centro de Cultura Digital},
  articleno = {1110},
  abstract = {Transcontinental Grapevine is a new crowdsourced telematic work by the Virginia Tech Linux Laptop Orchestra (L2Ork) that was co-created and performed with collaborators from UNTREF, Buenos Aires, Argentina. The work is inspired by the introductory loop of the "Grapevine" song by Lane 8 and Elderbrook and utilizes L2Ork Tweeter online collaborative musicking platform that allows for perfect sync among performers regardless the distance (in this case two groups of performers, 11 in total, were over 5,000 miles apart). The work’s EDM aesthetics intentionally seeks to test the limits of the newfound platform’s ability to sync players, as well as to expand the telematic musical vocabulary.  The work was co-created by the participants, each offering their own monophonic contributions. It starts with Lane 8's "Grapevine" intro, and then crossfades into a crowdsourced theme and variations.}
}

@article{nime23-music-1113,
  author = {Dimitris Papageorgiou},
  title = {T/ensor/~ 0.3},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_2.pdf},
  note = {Live Concert 2, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1113},
  abstract = {T/ensor/~ (version 0.3) is a prototype of a dynamic performance system developed in MAX that involves adaptive digital signal processing modules and generative processes towards exploring the field and performance practice of human-machine improvisation. The system is the result of a pilot, artistic research study entitled ‘Improvisation Technologies and Creative Machines: The Performer-Instrument Relational Milieu’. Our proposal for the NIME 2023 conference involves a c.10–12 minutes improvised performance with the system (drum-kit performer and T/ensor/~ 0.3).}
}

@article{nime23-music-1115,
  author = {Ryan R Smith and Shawn Lawson},
  title = {DEF FUNCTION(DYSTOPIAKIRA)},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1115},
  abstract = {Neo Tokyo, ca. 2019, 31 years after World War III, Akira awakens. This homage is an audiovisual, live-coded performance, remixing and re-envisioning the 1988 classic film created in the year of its setting, 2019 and reimagined now in 2022/2023 as the audiovisual work DEF FUNCTION(DYSTOPIAKIRA).  The authors use the code editor Jensaarai to collaboratively and simultaneously live-code TidalCycles and Python, each supported by SuperCollider and Touch Designer on the backend respectively. The authors often collaborate remotely due to their respective locations which is facilitated by Jensaarai. This enables the client-side rendering of both audio and visuals in order to retain high-quality representations of both elements.}
}

@article{nime23-music-1137,
  author = {Sebastien Beaumont and Ivann Cruz and Arthur Paté and Florent Berthaut},
  title = {VS : Improvisation with Automated Interactive Instruments},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1137},
  abstract = {In this performance, two guitar players improvise using electro-acoustic guitars equipped with actuators that can hit each of the strings. By moving through virtual shapes placed around them with their guitars and bodies, they can control the actuators. By using minimal modifications of the instrument and subtly extending existing playing techniques, the setup aims at preserving the technical and cultural heritage of the acoustic instrument. During the performance, the two musicians combine elements of traditional playing with rhythmical interventions that complements the interaction with the shapes. In particular, the shapes allow them to generate stable rhythmical overlapped sequences. The improvisation then develops according to the musicians' inspiration with the shapes integrated in their playing.}
}

@article{nime23-music-1141,
  author = {Francesco Dal Rì and Francesca Zanghellini},
  title = {Codex Saqqara},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1141},
  abstract = {Codex Saqqara is a cycle of five semi-improvised musical pieces for live coding and electric violin. Here, for duration reasons, we present a short excerpt. The interaction between the two performers takes place through a system that allows the violinist to record and overdub up to five samples in real-time, which are then processed and organized into structures by the live coder. In this way, the two musicians interact with each other’s musical space, taking on different musical roles during the performance, such as soloists, orchestrators or accompanists. Given its extemporaneous nature, the piece is composed from-scratch, following a series of macro-structures determined beforehand. This submission accompanies a paper regarding the system used, along with some reflections that emerged during the rehearsals for this performance.}
}

@article{nime23-music-1148,
  author = {iran sanadzadeh and Chloë Sobek},
  title = {Flightless Path},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1148},
  abstract = {This is a proposal for the premier of Flightless Path, a new work for The Terpsichora Pressure-Sensitive Floors and Renaissance Violone. The Terpsichora Pressure-Sensitive Floors (The Floors) are a new digital musical instrument which uses whole-body motion to control electronic music. The instrument continues the development of early models for pioneering dancer Philippa Cullen (1950-1975), expanding its use as an expressive and versatile instrument for musicians to play. The Floors use a large interactive surface for fine control of many sonic parameters with a small number of sensors. The violone is the Renaissance precursor to the double bass. It is a large instrument that has six gut strings, gut frets and is played with a viol style underhand bow. This instrument also requires the whole body to play and physically support the instrument in performance. This new work brings these two instruments together and is an interplay between the definitions of instruments and controller as they relate to contemporary practices based on gesture. Working with the specific limitations of the body in relation to large objects, the Floors and the violone both function as controllers for affecting sound and as instruments for creating sound.}
}

@article{nime23-music-1158,
  author = {Chloë L A Sobek},
  title = {The Moirai Mask},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1158},
  abstract = {PROGRAM NOTES The Moirai Mask is an ornate mask that operates as a NIME. The mask has an integrated MIDI controller that allows the performer to play music by touching the brass and bamboo panels. In performance, the artist uses audio-montage to collage sounds of the Australian wilderness with electronics and sampled fragments of an acoustic string instrument. The mask is handmade from predominantly recycled materials; hand cut brass panels and hand painted bamboo elements adorn the front of the mask, which are sewn into the cotton paneling that covers the hand soldered electrical components. The Moirai Mask is a sonic play on the Covid-19 PPE mask. The PPE mask, like an exo-skeleton, provides an extra, augmented layer of protection from our bodies, the ‘outside world’, the virus, the Other. The Covid-19 pandemic forced us to accept our bodily limitations and embrace this prosaic form of human augmentation, the PPE mask. Furthermore, as the Covid-19 virus enters our bodies and is transmitted through our breath, we must acknowledge that we are not separate from the non-human world that we inhabit but are in fact bodily constituted through it [1]. As Deborah Lupton et al. point out ‘the COVID crisis [has] heightened awareness of our collective vulnerability to each other’s more-than-human bodies’ [ibid.]. Drawing on the concept of a NIME, here the PPE mask is appropriated as a symbolic and subversive art object, paying sonic homage to the non-human world while the artist’s voice is subtly silenced.}
}

@article{nime23-music-1166,
  author = {Sofya Yuditskaya and Jess Rowland and Margaret Schedel},
  title = {Carbon Based EM Fields},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_4.pdf},
  note = {Live Concert 4, Thursday June 1, Centro de Cultura Digital},
  articleno = {1166},
  abstract = {BANDNAME is composed of three womxn NAME, NAME, and NAME and guests who use the physical properties of the electromagnetic spectrum to create installations, performances and recordings. Using electronic feedback, audio speakers, various kinds of microphones/pickups, and resonant objects of all shapes and kinds, we summon the feminine spirit of electromagnetism, aka the Goddess of the Electronic Medium aka the ElecroMagnetic Goddess. We have a flexible membership inclusive to all peoples who are willing to open themselves up to this spirit. In terms of current trends in audio technology, we invoke a feminist response to the masculinization of the music industry, audio engineering, and to the artistic spaces of sound arts in general.  Our latest project includes playing with painted score-objects Bareëmins. They are painted with conductive carbon paint, and non-conductive paint. When the area that is conductive is activated it produces sound, the non-conductive area does not. Thereby, by alternating painted and not painted areas in an aesthetic way, a score can be embedded into the very instrument itself. The paint can be applied to paintings as well as the inside of paper and plastic sculptures the results are many fold.  There are folded paper crystal Bareëmins that look like crystals suitable for an electromagnetic altar. You can use them to invoke the Electromagnetic Goddess at home.   The project is particularly aligned with this year's theme of Frugal Music Innovation as it uses all natural materials + paste glue to create the painted score/instrument. The carbon paint is made by recycling charcoal from a cooking fire, the colored paint is everyday school supplies and paint made out of found earth pigment. The binder is paste glue. The brains are an Arduino running simple theremin code with only 2 resistors and an 8ohm speaker as peripherals.   video here   https://youtu.be/YAD-F68Ntl4}
}

@article{nime23-music-1168,
  author = {Cayn Borthwick},
  title = {Sonic Swells - Riding Swells},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1168},
  abstract = {Sonic Swells is a multimedia music composition for fixed audio, filmed footage of a surfer and live saxophone. This iterative sound art project explores the use of sonification of ocean weather data, sonification of movement data from a surfer riding waves, and live performance as tools for music composition. Weather data is collected through a free API and converted to sound in Max/MSP, driving the parameters of a very large additive and subtractive synthesizer that uses pink noise as its fundamental sound source. The sonification includes swell direction and wind speed that dictate the positions of audio in the stereo or surround speaker field, and wave height and swell period driving an undulating filter effect. The severity of the conditions dictates the complexity of the soundscape. Sampled audio is blended into the sonification. The surfer's movement data is collected with a DIY kit including an iPhone for telemetry, an android or esp32 watch for data logging, and a small Wi-Fi router with battery and a GoPro. This information influences elements of the ocean weather sonification and affects the saxophone live performance. The performer plays a combination of scored and improvised material. The piece explores the relationship between sonification, motion and music.}
}

@article{nime23-music-1174,
  author = {Jack Armitage and Celeste Betancur},
  title = {Pandora's Mycophony},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1174},
  abstract = {Pandora hears her own dreams, they talk to her in mysterious voices, unknown languages. You find yourself standing alone, in the middle of her darkness. You don’t know how you got there. Are you one of Pandora’s dreams? Talk to her, maybe she will answer you. In this audiovisual dreamscape lies a re-imagining of Pandora’s story, where the contents of her jar are bioluminescent swarming spores that seek to fill the world with hope instead of evil, and life instead of death. The spores want to get out, their evolutionary powers are hidden, and the whole universe is waiting to be explored. Meanwhile, Pandora is dreaming, condemned to keep the box closed. Life waits to be released.}
}

@article{nime23-music-1212,
  author = {Teodoro Dannemann},
  title = {Sabotaging Piano Concert},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 1, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1212},
  abstract = {The Sabotaging Piano is an electronic prepared piano that challenges performers through the remapping of keys to unexpected pitches. For every new performance, a new remapping pattern is given, so performers face a continuously surprising new element. The performer is provided with an expression pedal (a ``sabotaging pedal'') to modulate the amount of keys that will we remapped, going from none to all of them.}
}

@article{nime23-music-1214,
  author = {Solomiya Moroz and Zubin Kanga},
  title = {Returns \& Simulacra},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1214},
  abstract = {Returns and Simulacra combines sound and projections of video onto a screen with the performer’s body on stage. It uses mini bee accelerometers and touch-sensor attachments as an instrument called Piano Hands. Through this instrument, the pianist controls a max/MSP patch interface and some elements in the projected video of the piece. The piece addresses the performer’s multiple identities on stage, playing the line between the real and virtual performance while incorporating different footage from filmed videos of the pianist and archived cabaret performances of the British queer performers of the past. The digital score relies on the pianist's embodied gestural behaviour and his reaction to audio and video material.}
}

@article{nime23-music-1245,
  author = {Diemo Schwarz},
  title = {Absence},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1245},
  abstract = {Absence is a performance for audio–visual concatenative synthesis elaborated during Diemo Schwarz’s art–science residency at the IMéRA Institute for Advanced Study in 2022. It explores several notions of absence: of light, of love, of humanity, where societies and all human artefacts will be destructured to gradually disappear within the materials and textures of the natural world. Audio–visual concatenative synthesis extends the principle of corpus-based sound synthesis to the visual domain, where, in addition to the sound corpus (i.e. a collection of segments of recorded sound with a perceptual description of their sound character), the artist uses a corpus of still images with perceptual description (colour, texture, brightness, entropy, and other content-based image descriptors). The artist then creates an audio–visual musical performance by navigating through one of these descriptor spaces, e.g. through the collection of sound grains in a space of perceptual audio descriptors, and at the same time through the other descriptor space, i.e. select images from the visual corpus for rendering, and thus navigate in parallel through both corpora interactively with gestural control via movement sensors. This will evoke an aesthetic of acoustic and visual collage or cut-up, generating an audio–visual sequence of similar sounds/images from the two corpora when navigation is local, and opposing contrasting sounds/images when the navigation jumps to different parts of the linked sound/image descriptor space. The artistic–technological question that is explored here is how to control at the same time the navigation through the audio and the image descriptor spaces with gesture sensors, i.e. how to link the gesture sensing to both the image descriptors and the sound descriptors in order to create a multi-modal audio–visual performance.}
}

@article{nime23-music-1249,
  author = {Daniel Jones},
  title = {Dream Structures},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_3.pdf},
  note = {Live Concert 3, Thursday June 1, Centro de Cultura Digital},
  articleno = {1249},
  abstract = {Dream Structures is a live coding performance that uses computational audio analysis and machine learning to navigate and resample a half-terabyte archive of 90s/00s trance music, creating a live musical collage that organises fragments of audio from thousands of tracks by traversing a multidimensional feature space.}
}

@article{nime23-music-1262,
  author = {Gerard Roma},
  title = {Stir bugs},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1262},
  abstract = {Stir bugs is an exploration of live algorithmic control in corpus-based performance. A community of computational agents confined to a two-dimensional square prison cell is live-coded into collective madness. Agents are controlled by simple code functions that define navigation in a terrain made of a collection of electronic noise samples. Each agent is also associated with a sound playback/synthesis function. The performance embraces the complexity emerging from quickly coding a multiplicity of behaviours in a shared sonic space.}
}

@article{nime23-music-1272,
  author = {Daniel Manesh and Douglas A Bowman Jr and Sang Won Lee},
  title = {Branch},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_4.pdf},
  note = {Live Concert 4, Thursday June 1, Centro de Cultura Digital},
  articleno = {1272},
  abstract = {Branch is a live coding étude centered around speech and form. The piece uses the TidalCycles language alongside a tool we developed called SHARP, which provides an interactive, tree-like structure embedded in the text editor to track how blocks of code evolve over time. SHARP opens up new musical affordances centered around quickly switching between previous program states. In addition, SHARP’s version trees act as a kind of post-hoc score, leaving a visual trace of the piece’s structure as it unfolds. With Branch, we attempt to go beyond a simple demonstration of SHARP as a tool and instead create a piece which highlights the interplay between musical form, its visual representation in SHARP, and the sonic material itself. To that end, Branch makes use of machine-generated speech based mostly on snippets from the text of Robert Frost’s poem “The Road Not Taken”. The text is largely decontextualized, and its treatment is somewhat tongue-in-cheek: while the poem’s premise centers around not being able to take both paths, we can easily explore as many code paths as we wish. In addition to speech, Branch uses audio samples from Freesound, including the sounds of twigs snapping, knocking on wood, and a person stepping on leaves.}
}

@article{nime23-music-1284,
  author = {Adriano Claro Monteiro},
  title = {Displacements},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_4.pdf},
  note = {Live Concert 4, Thursday June 1, Centro de Cultura Digital},
  articleno = {1284},
  abstract = {Displacements is a music and video performance that thematizes the recording of walks in public spaces (a relatively recent and popular genre of videos on streaming platforms). In a place built to organize human displacements, a moving observer registers passing bodies: their directions, flows and speeds superimposed on the shades and forms of the environment are the visual information that feed an algorithmic composition based on shifts of space, time and color. The music, likewise algorithmic and mainly synthetic (but also including transformations of the sound captured during the footage), modulates its visual counterpart by providing an ethereal atmosphere uncorrelated with the expected soundscape. The work alludes to principles of the live coding practice as its performance happens in an improvised way through editing and running a pre-prepared computer code that controls the processes for music and video generation. The code is displayed as the top layer of the video, making available to the audience the performer’s decisions, as well as the algorithmic structure of the work, and having an aesthetic role as part of the visual composition of the work.}
}

@article{nime23-music-1285,
  author = {Anastasia Clarke},
  title = {Shard Speakers: Beyond Hexagons},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_3.pdf},
  note = {Live Concert 3, Thursday June 1, Centro de Cultura Digital},
  articleno = {1285},
  abstract = {If crystal bowls could speak, what would they say? Beyond Hexagons is a performance using the shard-speakers, a musical instrument and playback system created from the shards of broken crystal singing bowls with affixed transducers and resonators. Tracing their lifespans from quartz mines to factories and from scientific laboratories and sound studios, the bowls transmit their origin stories of purpose, function, and pleasure through a unique and alien sonic language that makes heavy use of improvisation, whimsy, and custom software instruments. The result is a sonic exploration of the paradoxes contained in these materials — strength and fragility, acuity and intuition, secrecy and frankness.}
}

@article{nime23-music-1287,
  author = {Costa K Colachis Glass},
  title = {Fluid Flows, Transit, and Symbols},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_2.pdf},
  note = {Live Concert 2, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1287},
  abstract = {Fluid Flows, Transit, and Symbols is a coded composition and re-imagined sonic poem. The primary influence for the design of the piece was pipe flow and fluid mechanics; specifically the transition from laminar (smooth) flow to turbulent flow within a pipe. The sounds and sequences are all designed in SuperCollider and the organization of the composition is composed live and sounds different with every performance. The reading of the poem is processed through granular synthesis, creating new sentences amongst the soundscape at an unpredictable rate. The performance and piece can be adapted to any space and only requires a microphone, a laptop, and a soundsystem.}
}

@article{nime23-music-1305,
  author = {Eugene Markin},
  title = {Survival Kit},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_1.pdf},
  note = {Live Concert 1, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1305},
  abstract = {Survival Kit is a live electroacoustic piece that explores the connection between textual and musical meanings. It is a revised take on choral music in the  digital era. The author experiments with ways to interpret natural language in computer music and suggests a novel approach to performing text/sound compositions. The foundation of the piece is a poetic text that lists all the things that may come to mind amidst a futile preparation for a global disaster.  The piece is performed by a single performer in the live coding manner. The author enters the text in his original computer music software, which triggers sections of pre-recorded music and corresponding processing algorithms. All vocals were performed by a collaborator vocalist (tenor) using a recording score for individual lines, and then edited and programmed into the software by the author.}
}

@article{nime23-music-1315,
  author = {Marianne Teixido and Emilio Ocelotl},
  title = {deep structures},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_5.pdf},
  note = {Live Concert 5, Friday June 2, Centro de Cultura Digital},
  articleno = {1315},
  abstract = {Sound composition on the fly that consists of a descent into the training of a deep learning audio neural network, which will explore with voice the implications of artificial intelligence from a transhackfeminist ethical perspective in order to critically look at these tools from the same and thus intervene them from within. That is, as an algorithmic essay, the piece will explore with voice, the implications of these technologies taking as text feminist and transfeminist research that theorize on the subject. The voice will be synthesized and reconstructed as a means to hack the same networks and the way we understand them.}
}

@article{nime23-music-1316,
  author = {Chi Wang},
  title = {Transparent Affordance},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1316},
  abstract = {Affordance describes the relationship between the environment and the individual from the action provider’s perspective. Affordance can be false, can be hidden, or can be perceptible. Within our complex environment, real or virtual, material or intellectual, the affordances can be functional or delusional, can be ephemeral or permanent, can be present or delayed – a choice for you to observe, adapt, participate, and evolve.}
}

@article{nime23-music-1340,
  author = {Danny Hynds and Aoi Uyama and George Chernyshov and DingDing Zheng and Kozue Matsumoto and Michael Pogorzhelskiy and Tatsuya Saito and Kai Kunze and Kouta Minamizawa},
  title = {Innermost Echoes},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1340},
  abstract = {Innermost Echoes is a performance work which utilizes performer physiological data as a novel input mechanism to introduce a new form of hybrid improvisation alongside a robotic koto which will sonify this data in a communicative feedback loop and a Eurorack system which will serve as a bridge between the passive physiological data and the active performance. By introducing this form of input, our improvisational performance will challenge the traditional approach to live performance by creating a closed loop between our emotions and the performance itself. In a sense, we will be improvising with our own presence. We believe this new kind of performative dialogue can challenge existing hierarchies within live music performances. This novel performance paradigm seeks to examine new performative dialogues and ideas on what it means to perform live. Current performance practices are often based predominantly on the direct communication of the performers through their respective instruments. When we introduce the performer’s physiology as a gestural language, we hope to define a new methodology of presence-based improvisation. The performers wear custom built sensing wristbands and elastic breathing bands around their chest to gather physiological data consisting of EDA (electrodermal activity), HRV (heart rate variability), and respiration rate. This data is then sent via OSC to a laptop running Max/MSP which applies this live data to the robotic koto and the Eurorack system. These data streams and occurrences of synchrony between the performers’ data are then sonified and used as a structural indicator of the current state of the performers, thereby forming a new unspoken dialogue between the two.}
}

@article{nime23-music-1389,
  author = {Miguel Ortiz and Barry Cullen and Paul Stapleton},
  title = {Pandemonium Quintet play Drone \& Drama Versions},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_3.pdf},
  note = {Live Concert 3, Thursday June 1, Centro de Cultura Digital},
  articleno = {1389},
  abstract = {Our performance research quintet has been set up to explore multiple instantiations of DIY electronic musical instruments (EMI) through improvisation. Our group consists of five highly experienced music improvisers, visual artists and instrument makers with a shared connection to the Sonic Arts Research Centre (SARC) at Queen’s University Belfast.   Performer-makers in this group have multiple decades of experience producing work in academic and professional contexts in Europe, the Americas and the Middle East [websites anonymised, but available upon request].  We are particularly interested in exploiting irregularities in the qualities of circuit components (e.g. imprecise tolerances/values), and how this allows for the development of stylistic differences across multiple instrument-performer configurations. We are also interested in how skill, style and performance techniques are developed in different ways on similar devices over extended periods of time, and how our existing musical practices are reconfigured through such collaborative exchanges.   For this musical performance each performer will use DIY EMI featuring function generators and wide band noise. The instruments are ‘bent by design’ (Hordijk 2009) and use ‘withered technologies’(Ott 2020) at their core. These musical instruments have been selected to promote productive instability whilst building a timbral playground.   The DIY instrument ethos includes the publication of the designs and ‘how to’ instructions to assist other makers in the creation of their own EMI, especially those who have to adopt a frugal approach to resources.  The aesthetic of our performance is informed by noise and free improvised musics, and is offered as continuation of ‘thinkering’ (Huhtamo 2011) practice as part of the history of electronic music experimentation.}
}

@article{nime23-music-1392,
  author = {Derek Holzer and Luka Aron},
  title = {Laser Phase Synthesis [XXI VII III I]},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_2.pdf},
  note = {Live Concert 2, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1392},
  abstract = {Laser Phase Synthesis [XXI VII III I] is an audiovisual performance informed by the historical Audio/Video/Laser system developed by Lowell Cross and Carson Jeffries for use by David Tudor and Experiments in Arts and Technology (E.A.T.) at the 1970 Japan World Exposition in Osaka, Japan. The current work employs digital audio synthesis, modern laser display technology, and close collaboration between sound and image composition to illustrate the harmonic progression of a musical work.}
}

@article{nime23-music-1393,
  author = {Omar C Hamido},
  title = {4 Disklavier Preludes},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime2023.org/program/online-in-person-concerts},
  note = {Online Presentation},
  articleno = {1393},
  abstract = {4 Disklavier Preludes is one of the main works in The Gedanken Room (2021). This is a work that explores the implications of Quantum Computing for Music composition, both conceptually and practically. Its 4 parts explore the use of the Disklavier both as an input and output interface for building Quantum Circuits and retrieving its measurements, in a live interactive multimedia environment with which live performers interact. The cinematographic narrative addresses utopian/dystopian issues in human-machine interaction.}
}

@article{nime23-music-1394,
  author = {Palle Dahlstedt},
  title = {Finger Breath – Material and control through intimate sounds},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Rob Hamilton},
  year = {2023},
  month = {May},
  url = {https://www.nime.org/proceedings/2023/nime23_concert_2.pdf},
  note = {Live Concert 2, Wednesday May 31, Biblioteca Vasconcelos},
  articleno = {1394},
  abstract = {Finger Breath, for performer, live electronics, and zither, was originally commissioned by the the Frontside International Chamber Music Festival, funded by a grant from the Swedish Arts Council, and premiered in January 2023 as a headphone performance in the belly of a small passenger ferry. The main concepts behind the work are three: First, the intimate sounds from the musicians breathing, and from his fingers on the strings of an ancient zither. Second, the idea that the live breathing and the musician’s sounds played by finger movements are the only sources of gestural control and expression in the piece. Breathing and finger movements form the basis of many musical expressions throughout the world, as they are our most intimate physiological and gestural bodily mechanisms. Third, the combination of the first two into a situation of  “entangled musicianship”, where each action has triple consequences: as a sound source to be heard live, as a sound source being fed to various buffers for later manipulation and playback, but also as a source of gestural control, affecting a variety of playback mechanisms for the buffered sounds. It is thus impossible to play something without also altering the conditions for future playing. Hence the entanglement.}
}

