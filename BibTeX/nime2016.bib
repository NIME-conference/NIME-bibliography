@InProceedings{Arango2016,
  Title                    = {The Smartphone Ensemble. Exploring mobile computer mediation in collaborative musical performance},
  Author                   = {Julian Jaramillo Arango and Daniel Mel\`{a}n Giraldo},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {61--64},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper reports the goals, procedures and recent activities of
 the Smartphone Ensemble, an academic group of musicians and designers exploring
 mobile phones social mediation in musical contexts. The SE was created in the
 Design and Creation program at the Caldas University in Manizales, Colombia and
 includes six regular members. The group intends to enhance links among musicians,
 and between the musicians and their audience, by leveraging the network
 capabilities and mobility of smart phones, and exploring the expressivity of
 urban space. Through the creation of pieces and interventions that are related to
 urban experiences, the Smartphone Ensemble envisions alternatives to the standard
 musical performance space. In this regard, the performances intend to be urban
 interventions, not traditional concerts, they progress according to previously
 defined tours around the city that the group embarks while playing},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0013.pdf}
}

@InProceedings{Balandra2016,
  Title                    = {Haptic Music Player---Synthetic audio-tactile stimuli generation based on the notes' pitch and instruments' envelope mapping},
  Author                   = {Alfonso Balandra and Hironori Mitake and Shoichi Hasegawa},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {90--95},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {An entertainment environment to enrich music listening experience
 is purposed. This environment is composed of 3 modules: a MIDI player, a music
 animation and a haptic module that translates the notes played by one instrument
 into a resemblant vibration. To create the haptic vibration, the notes' relative
 pitch in the song are calculated, then these positions are mapped into the haptic
 signals' amplitude and frequency. Also, the envelope of the haptic signal is
 modified, by using an ADSR filter, to have the same envelope as the audio signal.
 To evaluate the perceived cross-modal similarity between users, two experiments
 were performed. In both, the users used the complete entertainment environment to
 rank the similarity between 3 different haptic signals, with triangular, square
 and analogue envelopes and 4 different instruments in a classical song. The first
 experiment was performed with the purposed amplitude and frequency technique,
 while the second experiment was performed with constant frequency and amplitude. 
 Results, show different envelope user preferences. The square and triangular
 envelopes were preferred in the first experiment, while only analogue envelopes
 were preferred in the second. This suggests that the users' envelope perception
 was masked by the changes in amplitude and frequency.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0019.pdf}
}

@InProceedings{Baldwin2016,
  Title                    = {Tromba Moderna: A Digitally Augmented Medieval Instrument},
  Author                   = {Alex Baldwin and Troels Hammer and Edvinas Pechiulis and Peter Williams and Dan Overholt and Stefania Serafin},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {14--19},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {An interactive museum exhibit of a digitally augmented medieval
 musical instrument, the tromba marina, is presented. The tromba marina is a
 curious single stringed instrument with a rattling bridge, from which a
 trumpet-like timbre is produced. The physical instrument was constructed as a
 replica of one found in Musikmuseet in Frederiksberg. The replicated instrument
 was augmented with a pickup, speakers and digital signal processing to create a
 more reliable, approachable and appropriate instrument for interactive display in
 the museum. We report on the evaluation of the instrument performed at the Danish
 museum of musical instruments.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0004.pdf}
}

@InProceedings{Banas2016,
  Title                    = {Design and evaluation of a gesture driven wave field synthesis auditory game},
  Author                   = {Jan Banas and Razvan Paisa and Iakovos Vogiatzoglou and Francesco Grani and Stefania Serafin},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {188--193},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {An auditory game has been developed as a part of research in
 Wavefield Synthesis. In order to design and implement this game, a number of
 technologies have been incorporated in the development process. By pairing motion
 capture with a WiiMote new dimension of movement input was achieved.
 We present an evaluation study where the game was assessed.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0039.pdf}
}

@InProceedings{Barrett2016,
  Title                    = {The `Virtualmonium': an instrument for classical sound diffusion over a virtual loudspeaker orchestra},
  Author                   = {Natasha Barrett and Alexander Refsum Jensenius},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {55--60},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Despite increasingly accessible and user-friendly multi-channel
 compositional tools, many composers still choose stereo formats for their work,
 where the compositional process is allied to diffusion performance over a
 `classical' loudspeaker orchestra. Although such orchestras remain
 common within UK institutions as well as in France, they are in decline in the
 rest of the world. In contrast, permanent, high-density loudspeaker arrays are on
 the rise, as is the practical application of 3-D audio technologies. Looking to
 the future, we need to reconcile the performance of historical and new stereo
 works, side-by-side native 3-D compositions. In anticipation of this growing
 need, we have designed and tested a prototype `Virtualmonium'. The
 Virtualmonium is an instrument for classical diffusion performance over an
 acousmonium emulated in higher-order Ambisonics. It allows composers to
 custom-design loudspeaker orchestra emulations for the performance of their
 works, rehearse and refine performances off-site, and perform classical
 repertoire alongside native 3-D formats in the same concert. This paper describes
 the technical design of the Virtualmonium, assesses the success of the prototype
 in some preliminary listening tests and concerts, and speculates how the
 instrument can further composition and performance practice.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0012.pdf}
}

@InProceedings{Baytas2016,
  Title                    = {The Perception of Live-sequenced Electronic Music via Hearing and Sight},
  Author                   = {Mehmet Ayd{\i}n Bayta\c{s} and Tilbe G\"{o}ksun and O\u{g}uzhan \"{O}zcan},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {194--199},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In this paper, we investigate how watching a live-sequenced
 electronic music performance, compared to merely hearing the music, contributes
 to spectators' experiences of tension. We also explore the role of the
 performers' effective and ancillary gestures in conveying tension, when they can
 be seen. To this end, we conducted an experiment where 30 participants heard,
 saw, or both heard and saw a live-sequenced techno music performance recording
 while they produced continuous judgments on their experience of tension. Eye
 tracking data was also recorded from participants who saw the visuals, to reveal
 aspects of the performance that influenced their tension judgments. We analysed
 the data to explore how auditory and visual components and the performer's
 movements contribute to spectators' experience of tension. Our results show that
 their perception of emotional intensity is consistent across hearing and sight,
 suggesting that gestures in live-sequencing can be a medium
 for expressive performance.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0040.pdf}
}

@InProceedings{Becking2016,
  Title                    = {Drum-Dance-Music-Machine: Construction of a Technical Toolset for Low-Threshold Access to Collaborative Musical Performance},
  Author                   = {Dominic Becking and Christine Steinmeier and Philipp Kroos},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {112--117},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Most instruments traditionally used to teach music in early
 education, like xylophones or flutes, encumber children with the additional
 difficulty of an unfamiliar and unnatural interface. The most simple expressive
 interaction, that even the smallest children use in order to make music, is
 pounding at surfaces. Through the design of an instrument with a simple
 interface, like a drum, but which produces a melodic sound, children can be
 provided with an easy and intuitive means to produce consonance. This should then
 be further complemented with information from analysis and interpretation of
 childlike gestures and dance moves, reflecting their natural understanding
 of musical structure and motion. Based on these assumptions we propose a modular
 and reactive system for dynamic composition with accessible interfaces, divided
 into distinct plugins usable in a standard digital audio workstation. This paper
 describes our concept and how it can facilitate access to collaborative music
 making for small children. A first prototypical implementation has been
 designed and developed during the ongoing research project
 Drum-Dance-Music-Machine (DDMM), a cooperation with the local social welfare
 association AWO Hagen and the chair of musical education at the University of
 Applied Sciences Bielefeld.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0023.pdf}
}

@InProceedings{Benson2016,
  Title                    = {SoundMorpheus: A Myoelectric-Sensor Based Interface for Sound Spatialization and Shaping},
  Author                   = {Christopher Benson and Bill Manaris and Seth Stoudenmier and Timothy Ward},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {332--337},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We present an innovative sound spatialization and shaping
 interface, called SoundMorpheus, which allows the placement of sounds in space,
 as well as the altering of sound characteristics, via arm movements that resemble
 those of a conductor. The interface displays sounds (or their attributes) to the
 user, who reaches for them with one or both hands, grabs them, and gently or
 forcefully sends them around in space, in a 360$^{\circ}$ circle. The system
 combines MIDI and traditional instruments with one or more myoelectric sensors. 
 These components may be physically collocated or distributed in various locales
 connected via the Internet. This system also supports the performance of
 acousmatic and electronic music, enabling performances where the traditionally
 central mixing board, need not be touched at all (or minimally touched for
 calibration). Finally, the system may facilitate the recording of a visual score
 of a performance, which can be stored for later playback and additional
 manipulation. We present three projects that utilize SoundMorpheus and
 demonstrate its capabilities and potential.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0065.pdf}
}

@InProceedings{Berdahl2016,
  Title                    = {Wireless Vibrotactile Tokens for Audio-Haptic Interaction with Touchscreen Interfaces},
  Author                   = {Edgar Berdahl and Danny Holmes and Eric Sheffield},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {5--6},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {New interfaces for vibrotactile interaction with touchscreens are
 realized. An electromagnetic design for wireless actuation of 3D-printed
 conductive tokens is analyzed. Example music interactions are implemented using
 physical modeling paradigms, each investigated within the context of a particular
 token that suggests a different interaction metaphor.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper00032.pdf}
}

@InProceedings{Berdahl2016a,
  Title                    = {Very Slack Strings: A Physical Model and Its Use in the Composition Quartet for Strings},
  Author                   = {Edgar Berdahl and Andrew Pfalz and Stephen David Beck},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {9--10},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Virtual ``slack'' strings are designed for and employed by the
 Laptop Orchestra of Louisiana. These virtual strings are ``slack'' in the sense
 that they can be very easily displaced, bent, tugged upon, etc. This enables
 force-feedback control of widely ranging pitch glides, by as much as an octave or
 more, simply by bending the virtual string. To realize a slack string design, a
 virtual spring with a specific nonlinear characteristic curve is designed. 
 Violin, viola, and cello-scale models are tuned and employed by the Laptop
 Orchestra of Louisiana in \emph{Quartet for Strings}.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper00052.pdf}
}

@InProceedings{Berg2016,
  Title                    = {Tango: Software for Computer-Human Improvisation},
  Author                   = {Henning Berg},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {7--8},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This demonstration describes Tango, software for
 Computer-Human Improvisation developed for more than 25 years by Henning Berg.
 Tango listens to an improvising musician, analyses what it hears
 and plays musical responses which relate directly to the musical input.
 If the improviser in turn reacts to these answers, a musical loop between the
 human and the machine can emerge. The way input and reaction correlate and the
 predictability of Tango's responses can be defined by the user via a setup
 of improvising environments, called Rooms. 
 Real-time sampling with knowledge of the musical content behind the samples and
 Midi-handling are unified via Tango's own monophonic audio-to-Midi, time
 stretching and pitch shifting algorithms. Both audio and Midi can be used by
 Tango's modules (e.g. Listeners, Players, Modifiers, Metronomes or Harmony)
 for input and output. 
 A flexible real time control system allows for internal and external remote
 control and scaling of most parameters. 
 The free software for Windows7 with all necessary folders, English and German
 manuals, many example-Rooms and a few videos can be downloaded at
 www.henning-berg.de.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper00042.pdf}
}

@InProceedings{Bhumber2016,
  Title                    = {Pendula: An Interactive Swing Installation and Performance Environment},
  Author                   = {Kirandeep Bhumber and Nancy Lee and Brian Topp},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {277--285},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes the processes involved in developing Pendula,
 a performance environment and interactive installation using swings, interactive
 video, and audio. A presentation of the project is described using three swings.
 Gyroscopic and accelerometer data were used in each of the setups to control
 audio and visual parameters.The installation was presented as both an interactive
 environment and as a performance instrument, with multiple public performances.
 Construction of the physical devices used, circuits built, and software created
 is covered in this paper, along with a discussion of problems and their solutions
 encountered during the development of Pendula.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0054.pdf}
}

@InProceedings{Bin2016,
  Title                    = {Skip the Pre-Concert Demo: How Technical Familiarity and Musical Style Affect Audience Response},
  Author                   = {S. Astrid Bin and Nick Bryan-Kinns and Andrew P. McPherson},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {200--205},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper explores the roles of technical and musical familiarity
 in shaping audience response to digital musical instrument (DMI) performances. In
 an audience study conducted during an evening concert, we examined two primary
 questions: first, whether a deeper understanding of how a DMI works increases an
 audience's enjoyment and interest in the performance; and second, given the same
 DMI and same performer, whether playing in a conventional (vernacular) versus an
 experimental musical style affects an audience's response. We held a concert in
 which two DMI creator-performers each played two pieces in differing styles.
 Before the concert, each half the 64-person audience was given a technical
 explanation of one of the instruments. Results showed that receiving an
 explanation increased the reported understanding of that instrument, but had no
 effect on either the reported level of interest or enjoyment. On the other hand,
 performances in experimental versus conventional style on the same instrument
 received widely divergent audience responses. We discuss implications of these
 findings for DMI design.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0041.pdf}
}

@InProceedings{Bowers2016,
  Title                    = {One Knob To Rule Them All: Reductionist Interfaces for Expansionist Research},
  Author                   = {John Bowers and John Richards and Tim Shaw and Jim Frieze and Ben Freeth and Sam Topley and Neal Spowage and Steve Jones and Amit Patel and Li Rui},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {433--438},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes an instance of what we call `curated
 research', a concerted thinking, making and performance activity between
 two research teams with a dedicated interest in the creation of experimental
 musical instruments and the development of new performance practices. Our work
 builds theoretically upon critical work in philosophy, anthropology and
 aesthetics, and practically upon previous explorations of strategies for
 facilitating rapid, collaborative, publicly-oriented making in artistic settings.
 We explored an orientation to making which promoted the creation of a family of
 instruments and performance environments that were responses to the
 self-consciously provocative theme of `One Knob To Rule Them All'. A
 variety of design issues were explored including: mapping, physicality, the
 question of control in interface design, reductionist aesthetics and design
 strategies, and questions of gender and power in musical culture. We discuss not
 only the technologies which were made but also reflect on the value of such
 concerted, provocatively thematised, collective making activities for addressing
 foundational design issues. As such, our work is intended not just as a technical
 and practical contribution to NIME but also a reflective provocation into how we
 conduct research itself in a curated critical manner.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0085.pdf}
}

@InProceedings{Bown2016,
  Title                    = {A Musical Game of Bowls Using the DIADs},
  Author                   = {Oliver Bown and Sam Ferguson},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {371--372},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We describe a project in which a game of lawn bowls was recreated
 using Distributed Interactive Audio Devices (DIADs), to create an interactive
 musical experience in the form of a game. This paper details the design of the
 underlying digital music system, some of the compositional and design
 considerations, and the technical challenges involved. We discuss future
 directions for our system and compositional method.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0072.pdf}
}

@InProceedings{Brown2016,
  Title                    = {Leimu: Gloveless Music Interaction Using a Wrist Mounted Leap Motion},
  Author                   = {Dom Brown and Nathan Renney and Adam Stark and Chris Nash and Tom Mitchell},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {300--304},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Camera-based motion tracking has become a popular enabling
 technology for gestural human-computer interaction. However, the approach suffers
 from several limitations which have been shown to be particularly problematic
 when employed within musical contexts. This paper presents Leimu, a wrist mount
 that couples a Leap Motion optical sensor with an inertial measurement unit to
 combine the benefits of wearable and camera-based motion tracking. Leimu is
 designed, developed and then evaluated using discourse and statistical analysis
 methods. The results indicate that the Leimu is an effective interface for
 gestural music interaction and offers improved tracking precision over Leap
 Motion positioned on a table top. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0059.pdf}
}

@InProceedings{Cakmak2016,
  Title                    = {Networked Virtual Environments as Collaborative Music Spaces},
  Author                   = {Cem Cakmak and Anil Camci and Angus Forbes},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {106--111},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In this paper, we describe a novel multimedia system for networked
 musical collaboration. Our system, called Monad, offers a 3D virtual environment
 that can be shared by multiple participants to collaborate remotely on a musical
 performance. With Monad, we explore how various features of this environment in
 relation to game mechanics, network architecture, and audiovisual aesthetics can
 be used to mitigate problems inherent to networked musical performance, such as
 time delays, data loss, and reduced agency of users. Finally, we describe the
 results of a series of qualitative user studies that illustrate the effectiveness
 of some of our design decisions with two separate versions of Monad.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0022.pdf}
}

@InProceedings{Carey2016a,
  Title                    = {SpectraScore VR: Networkable virtual reality software tools for real-time composition and performance},
  Author                   = {Benedict Carey},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {3--4},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes a package of modular tools developed for use
 with virtual reality peripherals to allow for music composition, performance and
 viewing in `real-time' across networks within a spectralist paradigm.
 The central tool is SpectraScore, a Max/MSP abstraction for analysing audio
 signals and ranking the resultant partials according to their harmonic pitch
 class profiles. This data triggers the generation of objects in a virtual world
 based on the `topography' of the source sound, which is experienced
 by network clients via Google Cardboard headsets. They use their movements to
 trigger audio in various microtonal tunings and incidentally generate scores.
 These scores are transmitted to performers who improvise music from this notation
 using Leap Motion Theremins, also in VR space. Finally, the performance is
 broadcast via a web audio stream, which can be heard by the composer-audience in
 the initial virtual world. The `real-time composers' and performers
 are not required to have any prior knowledge of complex computer systems and
 interact either using head position tracking, or with a Oculus Rift DK2 and a
 Leap Motion Camera. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper00022.pdf}
}

@InProceedings{Carey2016,
  Title                    = {Reflection On Action in NIME Research: Two Complementary Perspectives},
  Author                   = {Benjamin Carey and Andrew Johnston},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {377--382},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper discusses practice-based research in the context of
 live performance with interactive systems. We focus on two approaches, both of
 which are concerned with documenting, examining and reflecting on the real-world
 behaviours and experiences of people and artefacts involved in the creation of
 new works. The first approach is primarily based on reflections by an individual
 performer/developer (auto-ethnography) and the second on interviews and
 observations. The rationales for both approaches are presented along with
 findings from research which applied them in order to illustrate and explore the
 characteristics of both. Challenges, including the difficulty of balancing
 rigour and relevance and the risks of negatively impacting on creative practices
 are articulated, as are the potential benefits.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0075.pdf}
}

@InProceedings{CarvalhoJunior2016,
  Title                    = {Understanding Cloud Support for the Audience Participation Concert Performance of Crowd in C[loud]},
  Author                   = {Antonio Deusany de Carvalho Junior and Sang Won Lee and Georg Essl},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {176--181},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Cloud services allow musicians and developers to build audience
 participation software with minimal network configuration for audience and no
 need for server-side development. In this paper we discuss how a cloud service
 supported the audience participation music performance, Crowd in C[loud], which
 enables audience participation on a large scale using the audience audience's
 smartphones. 
 We present the detail of the cloud service technology and an analysis of the
 network transaction data regarding the performance. 
 This helps us to understand the nature of cloud-based audience participation
 pieces based on the characteristics of a performance reality and provides cues
 about the technology's scalability.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0037.pdf}
}

@InProceedings{Chang2016,
  Title                    = {Electromagnetically Actuated Acoustic Amplitude Modulation Synthesis},
  Author                   = {Herbert H.C. Chang and Spencer Topel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {8--13},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper discusses a new approach to acoustic amplitude
 modulation. Building on prior work with electromagnetic augmentation of acoustic
 instruments, we begin with a theory of operation model to describe the mechanical
 forces necessary to produce acoustic amplitude modulation synthesis. We then
 propose an implementation of our model as an instrumental prototype. The results
 illustrate that our acoustic amplitude modulation system produces controllable
 sideband components, and that synthesis generated from our corresponding
 numerical dynamic system model closely approximates the acoustic result of the
 physical system.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0003.pdf}
}

@InProceedings{Cherston2016,
  Title                    = {Musician and Mega-Machine: Compositions Driven by Real-Time Particle Collision Data from the ATLAS Detector},
  Author                   = {Juliana Cherston and Ewan Hill and Steven Goldfarb and Joseph Paradiso},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {78--83},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We present a sonification platform for generating audio driven by
 real-time particle collision data from the ATLAS experiment at CERN. This paper
 provides a description of the data-to-audio mapping interfaces supported by the
 project's composition tool as well as a preliminary evaluation of the platform's
 evolution to meet the aesthetic needs of vastly distinct musical styles and
 presentation venues. Our work has been conducted in collaboration with the ATLAS
 Outreach team and is part of a broad vision to better harness real-time sensor
 data as a canvas for artistic expression. Data-driven streaming audio can be
 treated as a reimagined form of live radio for which composers craft the
 instruments but real-time particle collisions pluck the strings.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0017.pdf}
}

@InProceedings{Dabin2016,
  Title                    = {{3D} Modelling and Printing of Microtonal Flutes},
  Author                   = {Matthew Dabin and Terumi Narushima and Stephen Beirne and Christian Ritz and Kraig Grady},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {286--290},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This project explores the potential for 3D modelling and printing
 to create customised flutes that can play music in a variety of microtonal
 scales. One of the challenges in the field of microtonality is that conventional
 musical instruments are inadequate for realising the abundance of theoretical
 tunings that musicians wish to investigate. This paper focuses on the development
 of two types of flutes, the recorder and transverse flute, with interchangeable
 mouthpieces. These flutes are designed to play subharmonic microtonal scales. The
 discussion provides an overview of the design and implementation process,
 including calculation methods for acoustic modelling and 3D printing
 technologies, as well as an evaluation of some of the difficulties encountered.
 Results from our 3D printed flutes suggest that whilst further refinements are
 necessary in our designs, 3D modelling and printing techniques offer new and
 valuable methods for the design and production of customised musical instruments.
 The long term goal of this project is to create a system in which users can
 specify the tuning of their instrument to generate a 3D model and have it printed
 on demand. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0056.pdf}
}

@InProceedings{Eyes2016,
  Title                    = {How to Stop Sound: Creating a light instrument and `Interruption' a piece for the Mimerlaven, Norberg Festival 2015.},
  Author                   = {Benjamin James Eyes and Laurits Esben Jongejan},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {373--374},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {During an electronic music performance it is common to see light
 and sound interacting electronically in many different ways. From sound and light
 shows, whereby light reacts to sound, or generated visuals are projected onto a
 screen behind the performer. However we asked the question what if we could
 convert sound to light and back again and control sound with light? Inspired by
 the huge acoustic of the Mimerlaven at Norberg festival we built a `light
 instrument' that allowed us to interrupt and disrupt sound using light
 forming the basis of our piece `Interruption'.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0073.pdf}
}

@InProceedings{Gnicode243mez2016,
  Title                    = {Designing a Flexible Workflow for Complex Real-Time Interactive Performances},
  Author                   = {Esteban G\'{o}mez and Javier Jaimovich},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {305--309},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents the design of a Max/MSP flexible workflow
 framework built for complex real-time interactive performances. This system was
 developed for Emovere, an interdisciplinary piece for dance, biosignals, sound
 and visuals, yet it was conceived to accommodate interactive performances of
 different nature and of heterogeneous technical requirements, which we believe to
 represent a common underlying structure among these. 
 The work presented in this document proposes a framework that takes care of the
 signal input/output stages, as well as storing and recalling presets and scenes,
 thus allowing the user to focus on the programming of interaction models and
 sound synthesis or sound processing. Results are presented with Emovere as an
 example case, discussing the advantages and further challenges that this
 framework offers for other performance scenarios.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0060.pdf}
}

@InProceedings{Gimenes2016,
  Title                    = {Frontiers: Expanding Musical Imagination With Audience Participation},
  Author                   = {Marcelo Gimenes and Pierre-Emmanuel Largeron and Eduardo Miranda},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {350--354},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper introduces Performance Without Borders and Embodied
 iSound, two sound installations performed at the 2016 Peninsula Arts Contemporary
 Music Festival at Plymouth University. Sharing in common the use of smartphones
 to afford real-time audience participation, two bespoke distributed computer
 systems (Sherwell and Levinsky Music, respectively). Whilst the first one
 implements a cloud-based voting system, the second implements movement tracking
 and iBeacon-based indoor-positioning to control the choice of soundtracks, audio
 synthesis, and surround sound positioning, among other parameters. The general
 concepts of the installations, in particular design and interactive possibilities
 afforded by the computer systems are presented.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0068.pdf}
}

@InProceedings{Greenhill2016,
  Title                    = {Focal : An Eye-Tracking Musical Expression Controller},
  Author                   = {Stewart Greenhill and Cathie Travers},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {230--235},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We present Focal, an eye-tracking musical expression controller
 which allows
 hands-free control over audio effects and synthesis parameters during
 peformance. A see-through head-mounted display projects virtual dials and
 switches into the visual field. The performer controls these with a single
 expression pedal, switching context by glancing at the object they wish to
 control. This simple interface allows for minimal physical disturbance to the
 instrumental musician, whilst enabling the control of many parameters otherwise
 only achievable with multiple foot pedalboards. We describe the development of
 the system, including the construction of the eye-tracking display, and the
 design of the musical interface. We also present a comparison of a performance
 between Focal and conventional controllers. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0046.pdf}
}

@InProceedings{Hnicode233on-Morissette2016,
  Title                    = {Transdisciplinary Methodology: from Theory to the Stage, Creation for the {SIC}MAP},
  Author                   = {Barah H\'{e}on-Morissette},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {253--258},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The author's artistic practice as a composer and performer is
 transdisciplinary. The body as a vector associated with sound, gesture, video,
 physical space, and technological space, constitute the six founding elements.
 They give rise to works between music and dance, between musical theater and
 multimedia works leading to a new hybrid performative practice. These works are
 realized using a motion capture system by computer vision, SICMAP (Syst\'{e}me
 Interactif de Captation du Mouvement en Art Performatif --- Interactive
 Motion Capture System For The Performative Arts). In this paper, the author
 situates her artistic practice founded by the three pillars of transdisciplinary
 research methodology. The path taken by the performer-creator, leading to the
 conception of the SICMAP, is then explained through a reflection on the
 `dream instrument'. Followed by a technical description, the SICMAP
 is contextualized using theoretical models: the instrumental continuum and energy
 continuum, the `dream instrument' and the typology of the
 instrumental gesture. Initiated by the SICMAP, these are then applied to a new
 paradigm the gesture-sound space and subsequently put into practice through the
 creation of the work From Infinity To Within.

 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0050.pdf}
}

@InProceedings{Hindle2016,
  Title                    = {Hacking NIMEs},
  Author                   = {Abram Hindle},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {359--364},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = { NIMEs typically focus on novelty but the cost of novelty is
 often to
 ignore other non-functional requirements and concerns such as
 usability or security. Digital security has probably not been a
 concern for performers due to the duration of their performances and
 lack of disrespectful hackers, known as crackers, in attendance
 carrying the appropriate equipment and software necessary to hack a
 performance. Yet many modern NIMEs could be hacked from smart-phones
 in the audience. The lack of security hardening makes NIMEs an easy
 target --- but a question arises: if hacking can interrupt or modify
 a performance couldn't hacking itself also be performance? Thus
 would music hacking, live-hacking, be similar to live-coding? In
 this paper we discuss how NIMEs are in danger of being hacked, and
 yet how hacking can be an act of performance too.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0070.pdf}
}

@InProceedings{Hofmann2016,
  Title                    = {Development of Fibre Polymer Sensor {Reed}s for Saxophone and Clarinet},
  Author                   = {Alex Hofmann and Vasileios Chatziioannou and Alexander Mayer and Harry Hartmann},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {65--68},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Electronic pickup systems for acoustic instruments are often used
 in popular and contemporary music performances because they allow amplification
 and modification of a clean and direct signal. Strain gauge sensors on saxophone
 and clarinet reeds have been shown to be a useful tool to gain insight into
 tongue articulation during performance but also capture the reed vibrations. In
 our previous design, we used a procedure with epoxy adhesive to glue the strain
 gauge sensors to the flat side of the synthetic single reeds. The new design
 integrates the sensor inside a synthetic reed, respectively between layers of
 fibre polymer and wood. This allows an industrial production of sensor reeds.
 Sensor reeds open up new possibilities to pick up woodwind instruments and to
 analyse, to modify, and to amplify the signal. A signal-to-noise analysis of the
 signals from both designs showed that a sensor, glued to the outside of the reed,
 produced a cleaner signal.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0014.pdf}
}

@InProceedings{Hofmann2016a,
  Title                    = {Csound Instruments On Stage},
  Author                   = {Alex Hofmann and Bernt Waerstad and Kristoffer Koch},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {291--294},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Low cost, credit card size computers like the Raspberry Pi allow
 musicians to experiment with building software-based standalone musical
 instruments. The COSMO Project aims to provide an easy-to-use hardware and
 software framework to build Csound based instruments as hardware devices. Inside
 the instrument, the Csound software is running on a Raspberry Pi computer,
 connected to a custom designed interface board (COSMO-HAT) that allows to connect
 potentiometers, switches, LED's, and sensors. A classic stomp box design is used
 to demonstrate how Csound can be brought on stage as a stand-alone hardware
 effect instrument.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0057.pdf}
}

@InProceedings{Hope2016,
  Title                    = {Headline grabs for music: The development of the iPad score generator for `Loaded (NSFW)'},
  Author                   = {Cat Hope and Stuart James and Aaron Wyatt},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {375--376},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper-demonstration provides an overview of an generative
 music score adapted for the iPad by the Decibel new music ensemble. The original
 score `Loaded (NSFW)' (2015) is by Western Australian composer Laura
 Jane Lowther, and is scored for ensemble and electronics, commissioned for a
 performance in April 2015 at the Perth Institute of Contemporary Arts. It engages
 and develops the Decibel Score Player application, a score reader and generator
 for the iPad as a tool for displaying an interactive score that requires
 performers to react to news headlines through musical means. The paper will
 introduce the concept for the player, how it was developed, and how it was used
 in the premiere performance. The associated demonstration shows how the score
 appears on the iPads. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0074.pdf}
}

@InProceedings{Huberth2016,
  Title                    = {Notation for {3D} Motion Tracking Controllers: A Gametrak Case Study},
  Author                   = {Madeline Huberth and Chryssie Nanou},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {96--105},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Notation systems are used in almost all fields, especially for the
 communication and expression of ideas. This paper proposes and discusses a
 notation system for Gametrak-based computer music instruments. The notation
 system's design is informed both by Western music notation and dance
 notation, as well as common mappings used in laptop orchestras. It is designed to
 be sound- agnostic, primarily instructing the performer in their motions. While
 the discussion of such a notation system may be particularly timely due to the
 growing commercially-available 3D motion tracking controllers, the notation
 system may prove especially useful in the context of Gametrak and laptop
 orchestra, for which score-based representation can help clarify performer
 interaction and serve as a teaching tool in documenting prior work.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0020.pdf}
}

@InProceedings{Jaimovich2016,
  Title                    = {Emovere: Designing Sound Interactions for Biosignals and Dancers},
  Author                   = {Javier Jaimovich},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {316--320},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents the work developed for Emovere: an interactive
 real-time interdisciplinary performance that measures physiological signals from
 dancers to drive a piece that explores and reflects around the biology of
 emotion. This document focuses on the design of a series of interaction modes and
 materials that were developed for this performance, and are believed to be a
 contribution for the creation of artistic projects that work with dancers and
 physiological signals. The paper introduces the motivation and theoretical
 framework behind this project, to then deliver a detailed description and
 analysis of four different interaction modes built to drive this performance
 using electromyography and electrocardiography. Readers will find a discussion of
 the results obtained with these designs, as well as comments on future work.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0062.pdf}
}

@InProceedings{Jakobsen2016,
  Title                    = {Hitmachine: Collective Musical Expressivity for Novices},
  Author                   = {Kasper buhl Jakobsen and Marianne Graves Petersen and Majken Kirkegaard Rasmussen and Jens Emil Groenbaek and jakob winge and jeppe stougaard},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {241--246},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents a novel platform for expressive music making
 called Hitmachine. Hitmachine lets you build and play your own musical
 instruments from Legos and sensors and is aimed towards empowering everyone to
 engage in rich music making despite of prior musical experience. The paper
 presents findings from a 4-day workshop where more that 150 children from ages
 3-13 built and played their own musical instruments. The children used different
 sensors for playing and performed with their instruments on stage. The findings
 show how age influenced the children's musical understanding and
 expressivity, and gives insight into important aspects to consider when designing
 for expressive music for novices.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0048.pdf}
}

@InProceedings{James2016,
  Title                    = {A Multi-Point {2D} Interface: Audio-Rate Signals for Controlling Complex Multi-Parametric Sound Synthesis},
  Author                   = {Stuart James},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {401--406},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper documents a method of controlling complex sound
 synthesis processes such as granular synthesis, additive synthesis, timbre
 morphology, swarm-based spatialisation, spectral spatialisation, and timbre
 spatialisation via a multi-parametric 2D interface. This paper evaluates the use
 of audio-rate control signals for sound synthesis, and discussing approaches to
 de-interleaving, synchronization, and mapping. The paper also outlines a number
 of ways of extending the expressivity of such a control interface by coupling
 this with another 2D multi-parametric nodes interface and audio-rate 2D table
 lookup. The paper proceeds to review methods of navigating multi-parameter sets
 via interpolation and transformation. Some case studies are finally discussed in
 the paper. The author has used this method to control complex sound synthesis
 processes that require control data for more that a thousand parameters.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0079.pdf}
}

@InProceedings{Jathal2016,
  Title                    = {The HandSolo: A Hand Drum Controller for Natural Rhythm Entry and Production},
  Author                   = {Kunal Jathal and Tae-Hong Park},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {218--223},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The majority of electronic percussion controllers on the market
 today are based on location-oriented striking techniques, resulting in a finger
 drumming interaction paradigm, that is both fundamentally eclectic as well as
 imposingly contr. The few controllers that allow hand-drumming
 techniques also invariably conform to region-based triggering design, or, in
 trade-off for expressivity, end up excluding hardware connectivity options that
 are vital to the context of the modern electronic rhythm producer. The HandSolo
 is a timbre-based drum controller that allows the use of natural, hand-drumming
 strokes, whilst offering the same end-goal functionality that percussion
 controller users have come to expect over the past decade.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0044.pdf}
}

@InProceedings{Jensenius2016,
  Title                    = {Trends at NIME---Reflections on Editing A NIME Reader},
  Author                   = {Alexander Refsum Jensenius and Michael J. Lyons},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {439--443},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper provides an overview of the process of editing the
 forthcoming anthology A NIME Reader---Fifteen years of New Interfaces for
 Musical Expression. The selection process is presented, and we reflect on some
 of the trends we have observed in re-discovering the collection of more than 1200
 NIME papers published throughout the 15 yearlong history of the conference. An
 anthology is necessarily selective, and ours is no exception. As we present in
 this paper, the aim has been to represent the wide range of artistic,
 scientific, and technological approaches that characterize the NIME conference.
 The anthology also includes critical discourse, and through acknowledgment of the
 strengths and weaknesses of the NIME community, we propose activities which could
 further diversify and strengthen the field.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0086.pdf}
}

@InProceedings{Johnson2016,
  Title                    = {speaker.motion: A Mechatronic Loudspeaker System for Live Spatialisation},
  Author                   = {Bridget Johnson and Michael Norris and Ajay Kapur},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {41--45},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper provides an overview of a new mechatronic loudspeaker
 system: speaker.motion. The system affords automated positioning of a loudspeaker
 in real-time in order to manipulate the spatial qualities of electronic music.
 The paper gives a technical overview of how the system's hardware and
 software were developed and the design criteria and methodology. There is
 discussion of the unique features of the speaker.motion spatialisation system and
 the methods of user interaction, as well as a look at the creative possibilities
 that the loudspeakers afford. The creative affordances are explored through the
 case study of two new pieces written for the speaker.motion system. It is hoped
 that the speaker.motion system will afford composers and performers with a new
 range of spatial aesthetics to use in spatial performances, and encourage
 exploration of the acoustic properties of physical performance and installation
 spaces in electronic music.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0009.pdf}
}

@InProceedings{Jordnicode2252016,
  Title                    = {Drumming with style: From user needs to a working prototype},
  Author                   = {Sergi Jord\`{a} and Daniel G\'{o}mez-Mar\'{i}n and \'{A}ngel Faraldo and Perfecto Herrera},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {365--370},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents a generative drumming agent built from the
 results of an extensive survey carried out with electronic music producers, in
 two phases. Following the techniques of user-centered interaction design, an
 international group of beat producers was reviewed on the possibility of using AI
 algorithms to help them in the beat production workflow. The analyzed results of
 these tests were used as design requirements for constructing a system that would
 indeed perform some tasks alongside the producer. The first results of this
 working prototype are presented with a description of the system. The prototype
 is a stylistic drum generator that creates new rhythmic patterns after being
 trained with a collection of drum tracks. Further stages of development and
 potential algorithms are discussed.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0071.pdf}
}

@InProceedings{Kapur2016,
  Title                    = {MalletOTon and the Modulets: Modular and Extensible Musical Robots},
  Author                   = {Ajay Kapur and Jim Murphy and Michael Darling and Eric Heep and Bruce Lott and Ness Morris},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {69--72},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents two new musical robot systems and an
 accompanying driver electronics array. These systems are designed to allow for
 modular extensibility and ease of use with different instrument systems. The
 first system discussed is MalletOTon, a mechatronic mallet instrument player that
 may be re-configured to play a number of different instruments. Secondly, the
 Modulet mechatronic noisemakers are presented. These instruments are discrete
 modules that may be installed throughout a space in a wide variety of
 configurations. In addition to presenting the aforementioned new instruments, the
 Novalis system is shown. Novalis is an open-ended driver system for mechatronic
 instruments, designed to afford rapid deployment and modularity. Where prior
 mechatronic instruments are often purpose-built, the robots and robot electronics
 presented in this paper may be re-deployed in a wide-ranging, diverse manner.
 Taken as a whole, the design practices discussed in this paper go toward
 establishing a paradigm of modular and extensible mechatronic instrument
 development.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0015.pdf}
}

@InProceedings{Kleinberger2016,
  Title                    = {Dooremi: a Doorway to Music},
  Author                   = {Rebecca Kleinberger and Akito van Troyer},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {160--161},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The following paper documents the prototype of a musical door that
 interactively plays sounds, melodies, and sound textures when in use. We took the
 natural interactions people have with doors---grabbing and turning
 the knob and pushing and puling motions---and turned them into
 musical activities. The idea behind this project comes from the fact that the
 activity of using a door is almost always accompanied by a sound that is
 generally ignored by the user. We believe that this sound can be considered
 musically rich and expressive because each door has specific sound
 characteristics and each person makes it sound slightly different. By augmenting
 the door to create an unexpected sound, this project encourages us to listen to
 our daily lives with a musician's critical ear, and reminds us of the musicality
 of our everyday activities.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0033.pdf}
}

@InProceedings{Lnicode228hdeoja2016,
  Title                    = {Active Acoustic Instruments for Electronic Chamber Music},
  Author                   = {Otso L\"{a}hdeoja},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {132--136},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents an ongoing project for augmenting acoustic
 instruments with active acoustics. Active acoustics are defined as audio-rate
 vibration driven into the instruments physical structure, inducing air-borne
 sound output. The instrument's acoustic sound is thus doubled by an
 electronic soundscape radiating from the same source. The article is centered on
 a case study on two guitars, one with hexaphonic sound capture and the other with
 monophonic pickup. The article discusses the design, implementation, acoustics,
 sound capture and processing of an active acoustic instrument, as well as
 gestural control using the Leap Motion sensor. Extensions towards other
 instruments are presented, in connection with related artistic projects and
 `electronic chamber music' aesthetics.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0027.pdf}
}

@InProceedings{Larsen2016,
  Title                    = {The Prospects of Musical Instruments For People with Physical Disabilities},
  Author                   = {Jeppe Veirum Larsen and Dan Overholt and Thomas B. Moeslund},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {327--331},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Many forms of enabling technologies exist today. While
 technologies aimed at enabling basic tasks in everyday life (locomotion, eating,
 etc.) are more common, musical instruments for people with disabilities can
 provide a chance for emotional enjoyment, as well as improve physical conditions
 through therapeutic use. The field of musical instruments for people with
 physical disabilities, however, is still an emerging area of research. In this
 article, we look at the current state of developments, including a survey of
 custom designed instruments, augmentations / modifications of existing
 instruments, music-supported therapy, and recent trends in the area. The overview
 is extrapolated to look at where the research is headed, providing insights for
 potential future work.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0064.pdf}
}

@InProceedings{Laurenzo2016,
  Title                    = {5500: performance, control, and politics},
  Author                   = {Tomas Laurenzo},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {36--40},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In the period between June 2014 and June 2015, at least 5,500
 immigrants died trying to reach Europe from Africa while crossing the
 Mediterranean Sea.
 In this paper we present 5500, a piano performance that is a part of an on-going
 project that investigates the incorporation of electrical muscle stimulation
 (EMS) into musical performances, with a particular interest in the political
 significance of the negotiation of control that arises.
 5500 consists of a performance of Beethoven's Sonata Path\'{e}tique, where the
 pianist's execution is disrupted using computer-controlled electrodes
 which stimulate the muscles in his or her arms causing their involuntary
 contractions and affecting the final musical result.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0008.pdf}
}

@InProceedings{Lee2016,
  Title                    = {Live Writing : Writing as a Real-time Audiovisual Performance},
  Author                   = {Sang Won Lee and Georg Essl and Mari Martinez},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {212--217},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper suggests a novel form of audiovisual performance- live
 writing- that transforms creative writing into a real-time performing art. The
 process of typing a poem on the fly is captured and augmented to create an
 audiovisual performance that establishes natural links among the components of
 typing gestures, the poem being written on the fly, and audiovisual artifacts.
 Live writing draws upon ideas from the tradition of live coding in which the
 process of programming is revealed to the audience in real-time. This paper
 discusses the motivation behind the idea, interaction schemes and a performance
 interface for such a performance practice. Our live writing performance system is
 enabled by a custom text editor, writing-sound mapping strategies of our choice,
 a poem-sonification, and temporal typography. We describe two live writing
 performances that take different approaches as they vary the degree of
 composition and improvisation in writing.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0043.pdf}
}

@InProceedings{Leitman2016,
  Title                    = {Music Maker: 3d Printing and Acoustics Curriculum},
  Author                   = {Sasha Leitman and John Granzow},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {118--121},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Music Maker is a free online resource that provides files for 3D
 printing woodwind and brass mouthpieces and tutorials for using those mouthpieces
 to learn about acoustics and music. The mouthpieces are designed to fit into
 standard plumbing and automobile parts that can be easily purchased at home
 improvement and automotive stores. The result is a musical tool that can be used
 as simply as a set of building blocks to bridge the gap between our increasingly
 digital world of fabrication and the real-world materials that make up our daily
 lives.

 An increasing number of schools, libraries and community groups are purchasing 3D
 printers but many are still struggling to create engaging and relevant curriculum
 that ties into academic subjects. Making new musical instruments is a fantastic
 way to learn about acoustics, physics and mathematics.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0024.pdf}
}

@InProceedings{Lind2016,
  Title                    = {Mapping Everyday Objects to Digital Materiality in The Wheel Quintet: Polytempic Music and Participatory Art},
  Author                   = {Anders Lind and Daniel Nyl\'{e}n},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {84--89},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Digitalization has enabled material decoupling of sound from the
 physical devices traditionally used to conceive it. This paper reports an
 artistic exploration of novel mappings between everyday objects and digital
 sound. The Wheel Quintet---a novel musical instrument comprising four
 bicycle wheels and a skateboard---was created using off-the-shelf
 components and visual programming in Max/MSP. The use of everyday objects sought
 to enable people to quickly master the instrument, regardless of their musical
 backgrounds, and collectively create polytempic musical textures in a
 participatory art context. Applying an action research approach, the paper
 examines in detail two key cycles of planning, action, and analysis related to
 the instrument, involving an interactive museum exhibition open to the public and
 a concert hall performance conducted by an animated music notation system.
 Drawing on insights from the study, the paper contributes new knowledge
 concerning the creation and use of novel interfaces for music composition and
 performance enabled by digitalization.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0018.pdf}
}

@InProceedings{Lindell2016,
  Title                    = {Materiality for Musical Expressions: an Approach to Interdisciplinary Syllabus Development for NIME},
  Author                   = {Rikard Lindell and Koray Tahiro{\u{g}}lu and Morten Riis and Jennie Schaeffer},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {344--349},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We organised an elven day intense course in materiality for
 musical expressions to explore underlying principles of New Interfaces for
 Musical Expression (NIME) in higher educa- tion. We grounded the course in
 different aspects of ma- teriality and gathered interdisciplinary student teams
 from three Nordic universities. Electronic music instrument mak- ers participated
 in providing the course. In eleven days the students designed and built
 interfaces for musical expres- sions, composed a piece, and performed at the
 Norberg elec- tronic music festival. The students explored the relationship
 between technology and possible musical expression with a strong connection to
 culture and place. The emphasis on performance provided closure and motivated
 teams to move forward in their design and artistic processes. On the basis of the
 course we discuss an interdisciplinary NIME course syllabus, and we infer that it
 benefits from grounding in materiality and in the place with a strong reference
 to culture.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0067.pdf}
}

@InProceedings{Long2016,
  Title                    = {The Closed-Loop Robotic Glockenspiel: Improving Musical Robots with Embedded Musical Information Retrieval},
  Author                   = {Jason Long and Dale Carnegie and Ajay Kapur},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {2--7},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Musical robots provide artists and musicians with the ability to
 realise complex new musical ideas in real acoustic space. However, most musical
 robots are created with open-loop control systems, many of which require time
 consuming calibration and do not reach the level of reliability of other
 electronic musical instruments such as synthesizers. This paper outlines the
 construction of a new robotic musical instrument, the Closed-Loop Robotic
 Glockenspiel, and discusses the improved robustness, usability and expressive
 capabilities that closed-loop control systems and embedded musical information
 retrieval processes can afford robotic musical instruments. The hardware design
 of the instrument is described along with the firmware of the embedded MIR
 system. The result is a new desktop robotic musical instrument that is capable of
 continuous unaided re-calibration, is as simple to use as more traditional
 hardware electronic sound-sources and provides musicians with new expressive
 capabilities. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0002.pdf}
}

@InProceedings{Long2016a,
  Title                    = {An Analogue Interface for Musical Robots},
  Author                   = {Jason Long and Ajay Kapur and Dale Carnegie},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {51--54},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The majority of musical robotics performances, projects and
 installations utilise microcontroller hardware to digitally interface the robotic
 instruments with sequencer software and other musical controllers, often via a
 personal computer. While in many ways digital interfacing offers considerable
 power and flexibility, digital protocols, equipment and audio workstations often
 tend to suggest particular music-making work-flows and have resolution and timing
 limitations. This paper describes the creation of a hardware interface that
 allows direct communication between analogue synthesizer equipment and simple
 robotic musical instruments entirely in the analogue domain without the use of
 computers, microcontrollers or software of any kind. Several newly created
 musical robots of various designs are presented, together with a custom built
 hardware interface with circuitry that enables analogue synthesizers to interface
 with the robots without any digital intermediary. This enables novel methods of
 musical expression, creates new music-making work-flows for composing and
 improvising with musical robots and takes advantage of the low latency and
 infinite resolution of analogue circuits.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0011.pdf}
}

@InProceedings{Lynch2016,
  Title                    = {SensorChimes: Musical Mapping for Sensor Networks},
  Author                   = {Evan Lynch and Joseph Paradiso},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {137--142},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We present a composition framework that facilitates novel musical
 mappings for large-scale distributed networks of environmental sensors. A library
 of C-externals called ChainFlow for the graphical programming language Max/MSP
 that provides an interface to real-time and historical data for large sensor
 deployments was designed and implemented. This library along with spatialized
 audio techniques were used to create immersive musical compositions which can be
 presented on their own or complemented by a graphical 3D virtual world. Musical
 works driven by a sensor network deployed in a wetland restoration project called
 Tidmarsh are presented as case studies in augmented presence through musical
 mapping.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0028.pdf}
}

@InProceedings{McPherson2016,
  Title                    = {Action-Sound Latency: Are Our Tools Fast Enough?},
  Author                   = {Andrew McPherson and Robert Jack and Giulio Moro},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {20--25},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The importance of low and consistent latency in interactive music
 systems is well-established. So how do commonly-used tools for creating digital
 musical instruments and other tangible interfaces perform in terms of latency
 from user action to sound output? This paper examines several common
 configurations where a microcontroller (e.g. Arduino) or wireless device
 communicates with computer-based sound generator (e.g. Max/MSP, Pd). We find
 that, perhaps surprisingly, almost none of the tested configurations meet
 generally-accepted guidelines for latency and jitter. To address this limitation,
 the paper presents a new embedded platform, Bela, which is capable of complex
 audio and sensor processing at submillisecond latency.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0005.pdf}
}

@InProceedings{Meacham2016,
  Title                    = {The Laptop Accordion},
  Author                   = {Aidan Meacham and Sanjay Kannan and Ge Wang},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {236--240},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The `Laptop Accordion' co-opts the commodity laptop
 computer
 to craft an expressive, whimsical accordion-like instrument.
 It utilizes the opening and closing of the laptop
 screen as a physical metaphor for accordion bellows, and the
 laptop keyboard as musical buttonboard. Motion is tracked
 using the laptop camera via optical flow and mapped to continuous
 control over dynamics, while the sound is generated
 in real-time. The instrument uses both skeuomorphic and
 abstract onscreen graphics which further reference the core
 mechanics of `squeezebox' instruments. The laptop accordion
 provides several game modes, while overall offering an
 unconventional aesthetic experience in music making.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0047.pdf}
}

@InProceedings{Michon2016,
  Title                    = {Augmenting the iPad: the BladeAxe},
  Author                   = {Romain Michon and Julius Orion Iii Smith and Matthew Wright and Chris Chafe},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {247--252},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In this paper, we present the BladeAxe: an iPad-based musical
 instrument leveraging the concepts of augmented mobile device and hybrid
 physical model controller. By being almost fully standalone, it can be used
 easily on stage in the frame of a live performance by simply plugging it to a
 traditional guitar amplifier or to any sound system. Its acoustical plucking
 system provides the performer with an extended expressive potential compared to a
 standard controller.

 After presenting an intermediate version of the BladeAxe, we'll describe
 our final design. We will also introduce a similar instrument: the PlateAxe.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0049.pdf}
}

@InProceedings{Milne2016,
  Title                    = {XronoMorph: Algorithmic Generation of Perfectly Balanced and Well-Formed Rhythms},
  Author                   = {Andrew J. Milne and Steffen A. Herff and David Bulger and William A. Sethares and Roger T. Dean},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {388--393},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We present an application XronoMorph for the
 algorithmic generation of rhythms in the context of creative composition and
 performance, and of musical analysis and education. XronoMorph makes use of
 visual and geometrical conceptualizations of rhythms, and allows the user to
 smoothly morph between rhythms. Sonification of the user generated geometrical
 constructs is possible using a built-in sampler, VST and AU plugins, or
 standalone synthesizers via MIDI. The algorithms are based on two underlying
 mathematical principles: perfect balance and well-formedness, both of which can
 be derived from coefficients of the discrete Fourier transform of the rhythm. The
 mathematical background, musical implications, and their implementation in the
 software are discussed.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0077.pdf}
}

@InProceedings{Nagashim2016,
  Title                    = {Multi Rubbing Tactile Instrument},
  Author                   = {Yoichi Nagashima},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {168--169},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This is a report of a novel tactile musical instrument. This
 instrument is called Multi Rubbing Tactile Instrument (MRTI2015), using ten
 pieces of PAW sensor produced by the RT corporation. Previous research was
 focused on untouchable instruments, but this approach is fully tactile---rub
 and touch. The ten PAW sensors are assigned on the surface of the egg-like
 plastic case to fit the ten fingers grasping the instrument. The controller is
 mbed (NucleoF401RE), and it communicates with the host PC via high speed serial
 (115200bps) by an MIDI-like protocol. Inside the egg- like plastic case, this
 instrument has eight blue-LEDs which are controlled by the host in order to
 display the grasping nuances. The prototype of this instrument contains realtime
 visualizing system with chaotic graphics by Open-GL. I will report on the
 principle of the sensor, and details about realizing the new system.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0035.pdf}
}

@InProceedings{Nakanishi2016,
  Title                    = {NAKANISYNTH: An Intuitive Freehand Drawing Waveform Synthesiser Application for iOS Devices},
  Author                   = {Kyosuke Nakanishi and Paul Haimes and Tetsuaki Baba and Kumiko Kushiyama},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {143--145},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {NAKANISYNTH is a synthesiser application available on iOS devices
 that provides a simple and intuitive interface, allowing users to produce sound
 loops by freehand drawing sound waves and envelope curves. The interface provides
 a simple way of interacting: the only input required involves drawing two
 waveforms, meaning that users can easily produce various sounds intuitively
 without the need for complex manipulation. The application's interface comprises
 of an interchangeable ribbon and keyboard feature, plus two panels where users
 can edit waveforms, allowing users to make sounds. This simple approach to the
 interface means that it is easy for users to understand the relationship between
 a waveform and the sound that it produces. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0029.pdf}
}

@InProceedings{Nash2016,
  Title                    = {The 'E' in QWERTY: Musical Expression with Old Computer Interfaces},
  Author                   = {Chris Nash},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {224--229},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents a development of the ubiquitous computer
 keyboard to capture velocity and other continuous musical properties, in order to
 support more expressive interaction with music software. Building on existing
 `virtual piano' utilities, the device is designed to provide a richer
 mechanism for note entry within predominantly non-realtime editing tasks, in
 applications where keyboard interaction is a central component of the user
 experience (score editors, sequencers, DAWs, trackers, live coding), and in which
 users draw on virtuosities in both music and computing.
 In the keyboard, additional hardware combines existing scan code (key press)
 data with accelerometer readings to create a secondary USB device, using the same
 cable but visible to software as a separate USB MIDI device aside existing USB
 HID functionality. This paper presents and evaluates an initial prototype,
 developed using an Arduino board and inexpensive sensors, and discusses design
 considerations and test findings in musical applications, drawing on user studies
 of keyboard-mediated music interaction. Without challenging more established (and
 expensive) performance devices; significant benefits are demonstrated in
 notation-mediated interaction, where the user's focus rests with
 software.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0045.pdf}
}

@InProceedings{Normark2016,
  Title                    = {The extended clarinet},
  Author                   = {Normark, Carl J\"{u}rgen  and Peter Parnes and Robert Ek and Harald Andersson},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {162--167},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes how a classical instrument, the clarinet, can
 be extended with modern technology to create a new and easy to use augmented
 instrument. The paper describes the design process, technical details and how a
 musician can use the instrument. The clarinet bell is extended with sensor
 technology in order to improve the ways the clarinet is traditionally played and
 improve the performing artist's musical and performative expressions. New
 ways of performing music with a clarinet also opens up for novel ways of
 composing musical pieces. The design is iterated in two versions with improved
 hardware and form factor where everything is packaged into the clarinet bell. The
 clarinet uses electronics that wirelessly sends sensor data to a computer that
 processes a live audio feed via the software MAX 7 and plays it back via
 loudspeakers on the stage. The extended clarinet provides several ways of
 transforming audio and also adds several ways of making performances more
 visually interesting. It is shown that this way of using sensor technology in a
 traditional musical instrument adds new dimensions to the performance and allows
 creative persons to express themselves in new ways as well as giving the audience
 an improved experience. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0034.pdf}
}

@InProceedings{Nort2016,
  Title                    = {Towards a Mappable Database of Emergent Gestural Meaning},
  Author                   = {Doug Van Nort and Ian Jarvis and Michael Palumbo},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {46--50},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents our work towards a database of performance
 activity that is grounded in an embodied view on meaning creation that crosses
 sense modalities. Our system design is informed by the philosophical and
 aesthestic intentions of the laboratory context within which it is designed,
 focused on distribution of performance activity across temporal and spatial
 dimensions, and expanded notions of the instrumental system as environmental
 performative agent. We focus here on design decisions that result from this
 overarching worldview on digitally-mediated performance.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0010.pdf}
}

@InProceedings{Nuannicode225in2016,
  Title                    = {An Interactive Software Instrument for Real-time Rhythmic Concatenative Synthesis},
  Author                   = {C\`{a}rthach \'{O} Nuan\`{a}in and Sergi Jord\`{a} and Perfecto Herrera},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {383--387},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In this paper we describe an approach for generating and
 visualising new rhythmic patterns from existing audio in real-time using
 concatenative synthesis. We introduce a graph-based model enabling novel
 visualisation and manipulation of new patterns that mimics the rhythmic and
 timbral character of an existing target seed pattern using a separate database of
 palette sounds. Our approach is de- scribed, reporting on those features that may
 be useful in describing units of sound related to rhythm and how they might then
 be projected into two-dimensional space for visualisation using reduction
 techniques and clustering. We conclude the paper with our qualitative appraisal
 of using the interface and outline scope for future work.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0076.pdf}
}

@InProceedings{Oda2016,
  Title                    = {The Global Metronome: Absolute Tempo Sync For Networked Musical Performance},
  Author                   = {Reid Oda and Rebecca Fiebrink},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {26--31},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {At a time in the near future, many computers (including devices
 such as smart-phones) will have system clocks that are synchronized to a high
 degree (less than 1 ms of error). This will enable us to coordinate events across
 unconnected devices with a degree of accuracy that was previously impossible. In
 particular, high clock synchronization means that we can use these clocks to
 synchronize tempo between humans or sequencers with little-to-no communication
 between the devices. To facilitate this low-overhead tempo synchronization, we
 propose the Global Metronome, which is a simple, computationally cheap method to
 obtain absolute tempo synchronization. We present experimental results
 demonstrating the effectiveness of using the Global Metronome and compare the
 performance to MIDI clock sync, a common synchronization method. Finally, we
 present an open source implementation of a Global Metronome server using a
 GPS-connected Raspberry Pi that can be built for under $100.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0006.pdf}
}

@InProceedings{Olowe2016,
  Title                    = {residUUm: user mapping and performance strategies for multilayered live audiovisual generation},
  Author                   = {Ireti Olowe and Giulio Moro and Mathieu Barthet},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {271--276},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {We propose residUUm, an audiovisual performance tool that uses
 sonification to orchestrate a particle system of shapes, as an attempt to build
 an audiovisual user interface in which all the actions of a performer on a laptop
 are intended to be explicitly interpreted by the audience. We propose two
 approaches to performing with residUUm and discuss the methods utilized to
 fulfill the promise of audience-visible interaction: mapping and performance
 strategies applied to express audiovisual interactions with multilayered
 sound-image relationships. The system received positive feedback from 34 audience
 participants on aspects such as aesthetics and audiovisual integration, and we
 identified further design challenges around performance clarity and strategy. We
 discuss residUUm's development objectives, modes of interaction and the impact of
 an audience-visible interface on the performer and observer. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0053.pdf}
}

@InProceedings{Olson2016,
  Title                    = {Transforming 8-Bit Video Games into Musical Interfaces via Reverse Engineering and Augmentation},
  Author                   = {Ben Olson},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {73--77},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Video games and music have influenced each other since the
 beginning of the consumer video game era. In particular the chiptune genre of
 music uses sounds from 8-bit video games; these sounds have even found their way
 into contemporary popular music. However, in this genre, game sounds are arranged
 using conventional musical interfaces, meaning the games themselves (their
 algorithms, design and interactivity) play no role in the creation of the music.

 This paper describes a new way of creating music with 8-bit games, by reverse
 engineering and augmenting them with run-time scripts. A new API, Emstrument, is
 presented which allows these scripts to send MIDI to music production software.
 The end result is game-derived musical interfaces any computer musician can use
 with their existing workflow. This enhances prior work in repurposing games as
 musical interfaces by allowing musicians to use the original games instead of
 having to build new versions with added musical capabilities.

 Several examples of both new musical instruments and dynamic interactive musical
 compositions using Emstrument are presented, using iconic games from the 8-bit
 era.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0016.pdf}
}

@InProceedings{Ozdemir2016,
  Title                    = {PORTAL: An Audiovisual Laser Performance System},
  Author                   = {Gorkem Ozdemir and Anil Camci and Angus Forbes},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {338--343},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {PORTAL is an interactive performance tool that uses a laser
 projector to visualize computer-generated audio signals. In this paper, we first
 offer an overview of earlier work on audiovisual and laser art that inspired the
 current project. We then discuss our own implementation, focusing not only on the
 technical issues related to the use of a laser projector in an artistic context,
 but also on the aesthetic considerations in dealing with the translation of
 sounds into visuals, and vice versa. We provide detailed descriptions of our
 hardware implementation, our software system, and its desktop and mobile
 interfaces, which are made available online. Finally, we offer the results of a
 user study we conducted in the form of an interactive online survey on audience
 perception of the relationship between analogous sounds and visuals, which was
 explored as part of our performance practice.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0066.pdf}
}

@InProceedings{Paine2016,
  Title                    = {Now},
  Author                   = {Garth Paine},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {425--426},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The question of sound as an experience of now, as a conduit to the
 quality of our belonging to the present, is challenging. Yet it is a crucial
 issue in discussions about ecological listening. I have come to think of sound as
 a viscous material, a vibrating field of energy that has texture and density and
 a physicality that is unlike most other media. 

 Now suggests a desire of becoming present in the resonating sound field of our
 immediate environment. The energy in the field constantly modulates and drifts. I
 draw on voices and forces from the natural environment, humans and machines. The
 work seeks to draw the listeners into an inner space in which they can be both
 present and aware of their sonic environment and become immersed in it. Now is
 partly inspired by Samuel Beckett's novel Watt, specifically Watt's
 mysterious journey into to the unknown. 
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0083.pdf}
}

@InProceedings{Reid2016,
  Title                    = {Minimally Invasive Gesture Sensing Interface (MIGSI) for Trumpet},
  Author                   = {Sarah Reid and Ryan Gaston and Colin Honigman and Ajay Kapur},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {419--424},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes the design of a Minimally Invasive Gesture
 Sensing Interface (MIGSI) for trumpet. The interface attaches effortlessly to any
 B-flat or C trumpet and requires no permanent modifications to the
 host-instrument. It was designed first and foremost with accessibility in
 mind an approach that is uncommon in augmented instrument design and
 seeks to strike a balance between minimal design and robust control. MIGSI uses
 sensor technology to capture gestural data such as valve displacement, hand
 tension, and instrument position, to offer extended control and expressivity to
 trumpet players. Several streams of continuous data are transmitted wirelessly
 from MIGSI to the receiving computer, where MIGSI Mapping application (a simple
 graphical user interface) parses the incoming data into individually accessible
 variables. It is our hope that MIGSI will be adopted by trumpet players and
 composers, and that over time a new body of repertoire for the augmented trumpet
 will emerge.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0082.pdf}
}

@InProceedings{Resch2016,
  Title                    = {Controlling complex virtuel instruments---A setup with note~ for Max and prepared piano sound synthesis},
  Author                   = {Thomas Resch and Stefan Bilbao},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {295--299},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes a setup for embedding complex virtual
 instruments such as a physical model of the prepared piano sound synthesis in the
 sequencing library note~ for Max. Based on the requirements of contemporary music
 and media arts, note~ introduces computer-aided composition techniques and
 graphical user interfaces for sequencing and editing into the real time world of
 Max/MSP. A piano roll, a microtonal musical score and the capability to attach
 floating-point lists of (theoretically) arbitrary length to a single note-on
 event, enables artists to play, edit and record compound sound synthesis with the
 necessary precision.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0058.pdf}
}

@InProceedings{Rieger2016,
  Title                    = {Driftwood: Redefining Sound Sculpture Controllers},
  Author                   = {Alexandra Rieger and Spencer Topel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {158--159},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The Driftwood is a maneuverable sculptural instrument &
 controller. Tactilely, it is a micro-terrain one can explore with the hands as
 with the ears. Closed circuit sensors, moving wooden parts and Piezo microphones
 are discussed in the design phase alongside background and musical implementation
 concepts. Electronics and nature converge in this instrument harmoniously
 referencing our changing world and environment. When engaging with the sonic
 sculpture silent objects become audible and rest-wood is venerated. It is
 revealed to the musician interacting with Driftwood that our actions intervene
 directly with issues relating to sustainability and the amount of value we place
 on the world we live in. Every scrap of wood was once a tree, Driftwood reminds
 us of this in a multi-sensory playing experience. The Driftwood proposes a
 reinterpretation of the process of music creation, awareness and expression.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0032.pdf}
}

@InProceedings{Snicode248derberg2016,
  Title                    = {Music Aid---Towards a Collaborative Experience for Deaf and Hearing People in Creating Music},
  Author                   = {S\"{o}derberg, Ene Alicia and Odgaard, Rasmus Emil and Sarah Bitsch and Oliver H\"{o}eg-Jensen and Christensen, Nikolaj Schildt and Poulsen, S\"{o}ren Dahl and Steven Gelineck},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {321--326},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper explores the possibility of breaking the barrier
 between deaf and hearing people when it comes to the subject of making music.
 Suggestions on how deaf and hearing people can collaborate in creating music
 together, are presented. The conducted research will focus on deaf people with a
 general interest in music as well as hearing musicians as target groups. Through
 reviewing different related research areas, it is found that visualization of
 sound along with a haptic feedback can help deaf people interpret and interact
 with music. With this in mind, three variations of a collaborative user interface
 are presented, in which deaf and hearing people are meant to collaborate in
 creating short beats and melody sequences. Through evaluating the three
 prototypes, with two deaf people and two hearing musicians, it is found that the
 target groups can collaborate to some extent in creating beats. However, in order
 for the target groups to create melodic sequences together in a satisfactory
 manner, more detailed visualization and distributed haptic output is necessary,
 mostly due to the fact that the deaf test participants struggle in distinguishing
 between higher pitch and timbre. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0063.pdf}
}

@InProceedings{Schlei2016,
  Title                    = {PourOver: A Sensor-Driven Generative Music Platform},
  Author                   = {Kevin Schlei and Chris Burns and Aidan Menuge},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {355--358},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The PourOver Sensor Framework is an open iOS framework designed to
 connect iOS control sources (hardware sensors, user input, custom algorithms) to
 an audio graph's parameters. The design of the framework, motivation, and use
 cases are discussed. The framework is demonstrated in an end-user friendly iOS
 app PourOver, in which users can run Pd patches with easy access to hardware
 sensors and iOS APIs.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0069.pdf}
}

@InProceedings{Schlienger2016,
  Title                    = {Acoustic Localisation for Spatial Reproduction of Moving Sound Source: Application Scenarios \& Proof of Concept},
  Author                   = {Dominik Schlienger},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {407--412},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Despite the near ubiquitous availability of interfaces for spatial
 interaction, standard audio spatialisation technology makes very little use of
 it. In fact, we find that audio technology often impedes spatial interaction: In
 the workshop on music, space and interaction we thus developed the idea of a
 real-time panning whereby a moving sound source is reproduced as a virtual source
 on a panning trajectory. We define a series of application scenarios where we
 describe in detail what functionality is required to inform an implementation. In
 our earlier work we showed that Acoustic Localisation (AL) potentially can
 provide a pervasive technique for spatially interactive audio applications.
 Playing through the application scenarios with AL in mind provides interesting
 approaches. For one scenario we show an example implementation as proof of
 concept.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0080.pdf}
}

@InProceedings{Sello2016,
  Title                    = {The Hexenkessel: A Hybrid Musical Instrument for Multimedia Performances},
  Author                   = {Jacob T. Sello},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {122--131},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper introduces the Hexenkessel---an augmented musical
 instrument for interactive multimedia arts. The Hexenkessel is a classical
 timpani with its drumhead acting as a tangible user interface for expressive
 multimedia performances on stage.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0025.pdf}
}

@InProceedings{Shapiro2016,
  Title                    = {BlockyTalky: A Physical and Distributed Computer Music Toolkit for Kids},
  Author                   = {R. Benjamin Shapiro and Rebecca Fiebrink and Matthew Ahrens and Annie Kelly},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {427--432},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {NIME research realizes a vision of performance by means of
 computational expression, linking body and space to sound and imagery through
 eclectic forms of sensing and interaction. This vision could dramatically impact
 computer science education, simultaneously modernizing the field and drawing in
 diverse new participants. We describe our work creating a NIME-inspired computer
 music toolkit for kids called BlockyTalky; the toolkit enables users to create
 networks of sensing devices and synthesizers. We offer findings from our research
 on student learning through programming and performance. We conclude by
 suggesting a number of future directions for NIME researchers interested in
 education.
 },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0084.pdf}
}

@InProceedings{Shaw2016,
  Title                    = {Unfoldings: Multiple Explorations of Sound and Space},
  Author                   = {Tim Shaw and Simon Bowen and John Bowers},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {152--157},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes a long term, collaborative project Sound
 Spaces. Within this project we creatively investigated various environments and
 built a collection of artworks in response to material gathered through a number
 of practical field visits. Our responses were presented in numerous,
 idiosyncratic ways and took shape through a number of concerted making
 activities. The work was conducted both in and with the public, allowing
 participants to inform the creative decisions made throughout the project as well
 as experiencing the building of the artworks. Within this essay we report on our
 process, presentation and offer alternative methods for collecting material and
 presenting representations of space. We describe the many responses made during
 our time and related these to research concerns relevant to the NIME community.
 We conclude with our findings and, through the production of an annotated
 portfolio, offer our main emerging themes as points of discussion. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0031.pdf}
}

@InProceedings{Sheffield2016,
  Title                    = {The Haptic Capstans: Rotational Force Feedback for Music using a FireFader Derivative Device},
  Author                   = {Eric Sheffield and Edgar Berdahl and Andrew Pfalz},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {1--2},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The Haptic Capstans are two rotational force-feedback knobs
 circumscribed by eye-catching LED rings. In this work, the Haptic Capstans are
 programmed using physical models in order to experiment with audio-visual-haptic
 interactions for music applications.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Demonstrations},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper00012.pdf}
}

@InProceedings{Smallwood2016,
  Title                    = {Coronium 3500: A Solarsonic Installation for Caramoor},
  Author                   = {Scott Smallwood},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {32--35},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper describes the development, creation, and deployment of
 a sound installation entitled Coronium 3500 (Lucie's Halo), commissioned by
 the Caramoor Center for Music and the Arts. The piece, a 12-channel immersive
 sound installation driven by solar power, was exhibited as part of the exhibition
 In the Garden of Sonic Delights from June 7 to Nov. 4, 2014, and again for
 similar duration in 2015. Herein I describe the aesthetic and technical details
 of the piece and its ultimate deployment, as well as reflecting on the results
 and the implications for future work.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0007.pdf}
}

@InProceedings{Soraghan2016,
  Title                    = {Towards a perceptual framework for interface design in digital environments for timbre manipulation},
  Author                   = {Sean Soraghan and Alain Renaud and Ben Supper},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {413--418},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {Many commercial software applications for timbre creation and
 manipulation feature an engineering-focused, parametric layout. This paper argues
 the case for a perceptually motivated approach to interface design in such tools.
 `Perceptually motivated' in this context refers to the use of common semantic
 timbre descriptors to influence the digital representation of timbre. A review is
 given of existing research into semantic descriptors of timbre, as well as
 corresponding acoustic features of timbre. Discussion is also given on existing
 interface design techniques. The perceptually motivated approach to interface
 design is demonstrated using an example system, which makes use of perceptually
 relevant mappings from acoustic timbre features to semantic timbre descriptors
 and visualises sounds as physical objects.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0081.pdf}
}

@InProceedings{Tahironicode287lu2016,
  Title                    = {Non-intrusive Counter-actions: Maintaining Progressively Engaging Interactions for Music Performance},
  Author                   = {Koray Tahiro{\u{g}}lu and Juan Carlos Vasquez and Johan Kildal},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {444--449},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {In this paper we present the new development of a semi-autonomous
 response module for the NOISA system. NOISA is an interactive music system that
 predicts performer's engagement levels, learns from the performer, decides what
 to do and does it at the right moment. As an improvement for the above, we
 implemented real-time adaptive features that respond to a detailed monitoring of
 the performer's engagement and to overall sonic space, while evaluating the
 impact of its actions. Through these new features, the response module produces
 meaningful and non-intrusive counter actions, attempting to deepen and maintain
 the performer's engagement in musical interaction. In a formative study we
 compared our designed response module against a random control system of events,
 in which the former performed consistently better than the latter.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0087.pdf}
}

@InProceedings{Vickery2016,
  Title                    = {Rhizomatic approaches to screen-based music notation},
  Author                   = {Lindsay Vickery},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {394--400},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {The rhizome concept explored by Deleuze and Guatarri has had an
 important influence on formal thinking in music and new media. This paper
 explores the development of rhizomatic musical scores that are arranged
 cartographically with nodal points allowing for alternate pathways to be
 traversed. The challenges of pre-digital exemplars of rhizomatic structure are
 discussed. It follows the development of concepts and technology used in the
 creation of five works by the author Ubahn c. 1985: the Rosenberg Variations
 [2012], The Last Years [2012], Sacrificial Zones [2014], detritus [2015] and
 trash vortex [2015]. The paper discusses the potential for the evolution of novel
 formal structures using rhizomatic structures. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0078.pdf}
}

@InProceedings{Vindriis2016,
  Title                    = {StrumBot---An Overview of a Strumming Guitar Robot},
  Author                   = {Richard Vindriis and Dale Carnegie},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {146--151},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {StrumBot is a novel standalone six stringed robotic guitar
 consisting of mechanisms designed to enable musical expressivity and minimise
 acoustic noise. It is desirable for less than 60 dBA of noise at 1 m to be
 emitted to allow StrumBot to play in intimate venues such as caf\'{e}s or
 restaurants without loud motor noises detracting from the musical experience. 

 StrumBot improves upon previous RMI's by allowing additional expressive
 opportunities for a composer to utilise. StrumBot can perform slides, vibrato,
 muting techniques, pitch bends, pluck power variances, timbre control, complex
 chords and fast strumming patterns.

 A MIDI input allows commercial or custom controllers to operate StrumBot. Novel
 note allocation algorithms were created to allow a single MIDI stream of notes to
 be allocated across the six guitar strings.

 Latency measurements from MIDI input to string pluck are as low as 40 ms for a
 best case scenario strum, allowing StrumBot to accompany a live musician with
 minimal audible delay. 

 A relay based loop switcher is incorporated, allowing StrumBot to activate
 standard commercial guitar pedals based on a MIDI instruction. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0030.pdf}
}

@InProceedings{Volioti2016,
  Title                    = {x2Gesture: how machines could learn expressive gesture variations of expert musicians},
  Author                   = {Christina Volioti and Sotiris Manitsaris and Eleni Katsouli and Athanasios Manitsaris},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {310--315},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {There is a growing interest in `unlocking' the motor
 skills of expert musicians. Motivated by this need, the main objective of this
 paper is to present a new way of modeling expressive gesture variations in
 musical performance. For this purpose, the 3D gesture recognition engine
 `x2Gesture' (eXpert eXpressive Gesture) has been developed, inspired
 by the Gesture Variation Follower, which is initially designed and developed at
 IRCAM in Paris and then extended at Goldsmiths College in London. x2Gesture
 supports both learning of musical gestures and live performing, through gesture
 sonification, as a unified user experience. The deeper understanding of the
 expressive gestural variations permits to define the confidence bounds of the
 expert's gestures, which are used during the decoding phase of the
 recognition. The first experiments show promising results in terms of recognition
 accuracy and temporal alignment between template and performed gesture, which
 leads to a better fluidity and immediacy and thus gesture sonification. },
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0061.pdf}
}

@InProceedings{Waite2016,
  Title                    = {Church Belles: An Interactive System and Composition Using Real-World Metaphors},
  Author                   = {Si Waite},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {265--270},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents a brief review of current literature detailing
 some of the issues and trends in composition and performance with interactive
 music systems. Of particular interest is how musicians interact with a separate
 machine entity that exercises agency over the creative process. The use of
 real-world metaphors as a strategy for increasing audience engagement is also
 discussed. 

 The composition and system Church Belles is presented, analyzed and evaluated in
 terms of its architecture, how it relates to existing studies of musician-machine
 creative interaction and how the use of a real-world metaphor can promote
 audience perceptions of liveness. This develops previous NIME work by offering a
 detailed case study of the development process of both a system and a piece for
 popular, non-improvisational vocal/guitar music.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0052.pdf}
}

@InProceedings{Wang2016,
  Title                    = {Game Design for Expressive Mobile Music},
  Author                   = {Ge Wang},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {182--187},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This article presents observations and strategies for designing
 game- like elements for expressive mobile musical interactions. The designs of
 several popular commercial mobile music instruments are discussed and compared,
 along with the different ways they integrate musical information and game-like
 elements. In particular, issues of designing goals, rules, and interactions are
 balanced with articulating expressiveness. These experiences aim to invite and
 engage users with game design while maintaining and encouraging open-ended
 musical expression and exploration. A set of observations is derived, leading to
 a broader design motivation and philosophy.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0038.pdf}
}

@InProceedings{Wu2016,
  Title                    = {Evaluating the Audience's Perception of Real-time Gestural Control and Mapping Mechanisms in Electroacoustic Vocal Performance},
  Author                   = {Jiayue Cecilia Wu and Madeline Huberth and Yoo Hsiu Yeh and Matt Wright},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {206--211},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents an empirical evaluation of a digital music
 instrument (DMI) for electroacoustic vocal performance, the Tibetan Singing
 Prayer Wheel (TSPW). Specifically, we study audience preference for the way it
 maps horizontal spinning gestures to vocal processing parameters. We filmed six
 songs with the singer using the TSPW, and created two alternative soundtracks for
 each song: one desynchronized, and one with the mapping inverted. Participants
 viewed all six songs with either the original or desynchronized soundtrack
 (Experiment 1), or either the original or inverted-mapping soundtrack (Experiment
 2). Participants were asked several questions via questionnaire after each song.
 Overall, they reported higher engagement and preference for the original
 versions, suggesting that audiences of the TSPW prefer more highly synchronized
 performances, as well as more intuitive mappings, though level of perceived
 expression of the performer only significantly differed in Experiment 1. Further,
 we believe that our experimental methods contribute to how DMIs can be evaluated
 from the audience's (a recently noted under- represented stakeholder)
 perspective.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0042.pdf}
}

@InProceedings{Xiao2016,
  Title                    = {Kin\'{e}phone: Exploring the Musical Potential of an Actuated Pin-Based Shape Display},
  Author                   = {Xiao Xiao and Donald Derek Haddad and Thomas Sanchez and Akito van Troyer and R\'{e}becca Kleinberger and Penny Webb and Joe Paradiso and Tod Machover and Hiroshi Ishii},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {259--264},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper explores how an actuated pin-based shape display may
 serve as a platform on which to build musical instruments and controllers. We
 designed and prototyped three new instruments that use the shape display not only
 as an input device, but also as a source of acoustic sound. These cover a range
 of interaction paradigms to generate ambient textures, polyrhythms, and melodies.
 This paper first presents existing work from which we drew interactions and
 metaphors for our designs. We then introduce each of our instruments and the
 back-end software we used to prototype them. Finally, we offer reflections on
 some central themes of NIME, including the relationship between musician and
 machine.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0051.pdf}
}

@InProceedings{Zhang2016,
  Title                    = {A Web Application for Audience Participation in Live Music Performance: The Open Symphony Use Case},
  Author                   = {Leshao Zhang and Yongmeng Wu and Mathieu Barthet},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2016},

  Address                  = {Brisbane, Australia},
  Pages                    = {170--175},
  Publisher                = {Queensland Conservatorium Griffith University},
  Series                   = {2220-4806},
  Volume                   = {16},

  Abstract                 = {This paper presents a web-based application enabling audiences to
 collaboratively contribute to the creative process during live music
 performances. The system aims at enhancing audience engagement and creating new
 forms of live music experiences. Interaction between audience and performers is
 made possible through a client/server architecture enabling bidirectional
 communication of creative data. Audience members can vote for pre-determined
 musical attributes using a smartphone-friendly and cross-platform web
 application. The system gathers audience members' votes and provide feedback
 through visualisations that can be tailored for specific needs. In order to
 support multiple performers and large audiences, automatic audience-to-performer
 groupings are handled by the application. The framework was applied to support
 live interactive musical improvisations where creative roles are shared amongst
 audience and performers (Open Symphony). Qualitative analyses of user surveys
 highlighted very positive feedback related to themes such as engagement and
 creativity and also identified further design challenges around audience sense of
 control and latency.},
  ISBN                     = {978-1-925455-13-7},
  Track                    = {Papers},
  Url                      = {http://www.nime.org/proceedings/2016/nime2016_paper0036.pdf}
}
