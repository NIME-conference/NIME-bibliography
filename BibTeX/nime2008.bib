@inproceedings{Platz2008,
author = {Ananya, Misra and Essl, Georg and Rohs, Michael},
url = {http://www.nime.org/proceedings/2008/nime2008_185.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Microphone as Sensor in Mobile Phone Performance},
year = {2008},
abstract = {Many mobile devices, specifically mobile phones, come equipped with a microphone. Microphones are high-fidelity sensors that can pick up sounds relating to a range of physical phenomena. Using simple feature extraction methods,parameters can be found that sensibly map to synthesis algorithms to allow expressive and interactive performance.For example blowing noise can be used as a wind instrument excitation source. Also other types of interactionscan be detected via microphones, such as striking. Hencethe microphone, in addition to allowing literal recording,serves as an additional source of input to the developingfield of mobile phone performance.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {mobile music making, microphone, mobile-stk },
pages = {185--188},
}
@inproceedings{Barbosa2008,
author = {Barbosa, \`{A}lvaro},
url = {http://www.nime.org/proceedings/2008/nime2008_009.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Ten-Hand Piano : A Networked Music Installation},
year = {2008},
abstract = {This paper presents the latest developments of the Public Sound Objects (PSOs) system, an experimental framework to implement and test new concepts for Networked Music. The project of a Public interactive installation using the PSOs system was commissioned in 2007 by Casa da Musica, the main concert hall space in Porto. It resulted in a distributed musical structure with up to ten interactive performance terminals distributed along the Casa da Musica's hallways, collectively controlling a shared acoustic piano. The installation allows the visitors to collaborate remotely with each other, within the building, using a software interface custom developed to facilitate collaborative music practices and with no requirements in terms previous knowledge of musical performance. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {algorithmic composition,behavioral driven,electronic music instruments,interfaces,network music instruments,nime08,performance,public music,real-time collaborative,sound},
pages = {9--12},
}
@inproceedings{Bau2008,
author = {Bau, Olivier and Tanaka, Atau and Mackay, Wendy E.},
url = {http://www.nime.org/proceedings/2008/nime2008_091.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The A20 : Musical Metaphors for Interface Design},
year = {2008},
abstract = {We combine two concepts, the musical instrument as metaphorand technology probes, to explore how tangible interfaces canexploit the semantic richness of sound. Using participatorydesign methods from Human-Computer Interaction (HCI), wedesigned and tested the A20, a polyhedron-shaped, multichannel audio input/output device. The software maps soundaround the edges and responds to the user's gestural input,allowing both aural and haptic modes of interaction as well asdirect manipulation of media content. The software is designedto be very flexible and can be adapted to a wide range ofshapes. Our tests of the A20's perceptual and interactionproperties showed that users can successfully detect soundplacement, movement and haptic effects on this device. Ourparticipatory design workshops explored the possibilities of theA20 as a generative tool for the design of an extended,collaborative personal music player. The A20 helped users toenact scenarios of everyday mobile music player use and togenerate new design ideas.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Generative design tools, Instrument building, Multi-faceted audio, Personal music devices, Tangible user interfaces, Technology probes },
pages = {91--96},
}
@inproceedings{Bencina2008,
author = {Bencina, Ross and Wilde, Danielle and Langley, Somaya},
url = {http://www.nime.org/proceedings/2008/nime2008_197.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Gesture ≈ Sound Experiments : Process and Mappings},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {gestural control,mapping,nime08,prototyping,three-axis accelerometers,vocal,wii remote},
pages = {197--202},
}
@inproceedings{Berdahl2008,
author = {Berdahl, Edgar and Smith, Julius O.},
url = {http://www.nime.org/proceedings/2008/nime2008_299.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Tangible Virtual Vibrating String : A Physically Motivated Virtual Musical Instrument Interface},
year = {2008},
abstract = {We introduce physically motivated interfaces for playing virtual musical instruments, and we suggest that they lie somewhere in between commonplace interfaces and haptic interfaces in terms of their complexity. Next, we review guitarlike interfaces, and we design an interface to a virtual string.The excitation signal and pitch are sensed separately usingtwo independent string segments. These parameters controla two-axis digital waveguide virtual string, which modelsvibrations in the horizontal and vertical transverse axes aswell as the coupling between them. Finally, we consider theadvantages of using a multi-axis pickup for measuring theexcitation signal.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {physically motivated, physical, models, modeling, vibrating string, guitar, pitch detection, interface, excitation, coupled strings, haptic },
pages = {299--302},
}
@inproceedings{Berdahl2008a,
author = {Berdahl, Edgar and Steiner, Hans-Christoph and Oldham, Collin},
url = {http://www.nime.org/proceedings/2008/nime2008_061.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Practical Hardware and Algorithms for Creating Haptic Musical Instruments},
year = {2008},
abstract = {The music community has long had a strong interest in haptic technology. Recently, more effort has been put into making it more and more accessible to instrument designers.This paper covers some of these technologies with the aimof helping instrument designers add haptic feedback to theirinstruments. We begin by giving a brief overview of practicalactuators. Next, we compare and contrast using embeddedmicrocontrollers versus general purpose computers as controllers. Along the way, we mention some common softwareenvironments for implementing control algorithms. Then wediscuss the fundamental haptic control algorithms as well assome more complex ones. Finally, we present two practicaland effective haptic musical instruments: the haptic drumand the Cellomobo.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {haptic, actuator, practical, immersion, embedded, sampling rate, woofer, haptic drum, Cellomobo },
pages = {61--66},
}
@inproceedings{Bouillot2008,
author = {Bouillot, Nicolas and Wozniewski, Mike and Settel, Zack and Cooperstock, Jeremy R.},
url = {http://www.nime.org/proceedings/2008/nime2008_189.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Mobile Wireless Augmented Guitar},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {189--192},
}
@inproceedings{Bouenard2008,
author = {Bou\"{e}nard, Alexandre and Gibet, Sylvie and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2008/nime2008_038.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Enhancing the Visualization of Percussion Gestures by Virtual Character Animation},
year = {2008},
abstract = {A new interface for visualizing and analyzing percussion gestures is presented, proposing enhancements of existing motion capture analysis tools. This is achieved by offering apercussion gesture analysis protocol using motion capture.A virtual character dynamic model is then designed in order to take advantage of gesture characteristics, yielding toimprove gesture analysis with visualization and interactioncues of different types.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Gesture and sound, interface, percussion gesture, virtual character, interaction. },
pages = {38--43},
}
@inproceedings{Bozzolan2008,
author = {Bozzolan, Matteo and Cospito, Giovanni},
url = {http://www.nime.org/proceedings/2008/nime2008_024.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SMuSIM : a Prototype of Multichannel Spatialization System with Multimodal Interaction Interface},
year = {2008},
abstract = {The continuous evolutions in the human-computer interfaces field have allowed the development of control devicesthat let have a more and more intuitive, gestural and noninvasive interaction.Such devices find a natural employment also in the musicapplied informatics and in particular in the electronic music,always searching for new expressive means.This paper presents a prototype of a system for the realtime control of sound spatialization in a multichannel configuration with a multimodal interaction interface. The spatializer, called SMuSIM, employs interaction devices thatrange from the simple and well-established mouse and keyboard to a classical gaming used joystick (gamepad), finallyexploiting more advanced and innovative typologies basedon image analysis (as a webcam).},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Sound spatialization, multimodal interaction, interaction interfaces, EyesWeb, Pure data. },
pages = {24--27},
}
@inproceedings{Butler2008,
author = {Butler, Jennifer},
url = {http://www.nime.org/proceedings/2008/nime2008_077.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Creating Pedagogical Etudes for Interactive Instruments},
year = {2008},
abstract = {In this paper I discuss the importance of and need forpedagogical materials to support the development of newinterfaces and new instruments for electronic music. I describemy method for creating a graduated series of pedagogicaletudes composed using Max/MSP. The etudes will helpperformers and instrument designers learn the most commonlyused basic skills necessary to perform with interactiveelectronic music instruments. My intention is that the finalseries will guide a beginner from these initial steps through agraduated method, eventually incorporating some of the moreadvanced techniques regularly used by electronic musiccomposers.I describe the order of the series, and discuss the benefits (bothto performers and to composers) of having a logical sequence ofskill-based etudes. I also connect the significance of skilledperformers to the development of two essential areas that Iperceive are still just emerging in this field: the creation of acomposed repertoire and an increase in musical expressionduring performance.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {composition,etudes,max,msp,musical controllers,musical expression,nime08,pedagogy,repertoire},
pages = {77--80},
}
@inproceedings{Camurri2008,
author = {Camurri, Antonio and Canepa, Corrado and Coletta, Paolo and Mazzarino, Barbara and Volpe, Gualtiero},
url = {http://www.nime.org/proceedings/2008/nime2008_134.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mappe per Affetti Erranti : a Multimodal System for Social Active Listening and Expressive Performance},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Active listening of music, expressive interfaces, full-body motion analysis and expressive gesture processing, multimodal interactive systems for music and performing arts applications, collaborative environments, social interaction.  },
pages = {134--139},
}
@inproceedings{Canazza2008,
author = {Canazza, Sergio and Dattolo, Antonina},
url = {http://www.nime.org/proceedings/2008/nime2008_140.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {New Data Structure for Old Musical Open Works},
year = {2008},
abstract = {Musical open works can be often thought like sequences of musical structures, which can be arranged by anyone who had access to them and who wished to realize the work. This paper proposes an innovative agent-based system to model the information and organize it in structured knowledge; to create effective, graph-centric browsing perspectives and views for the user; to use ,
,
authoring tools for the performance of open work of electro-acoustic music. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Musical Open Work, Multimedia Information Systems,  Software Agents, zz-structures.  },
pages = {140--143},
}
@inproceedings{Chordia2008,
author = {Chordia, Parag and Rae, Alex},
url = {http://www.nime.org/proceedings/2008/nime2008_331.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Real-Time Raag Recognition for Interactive Music},
year = {2008},
abstract = {We describe a system that can listen to a performance of Indian music and recognize the raag, the fundamental melodicframework that Indian classical musicians improvise within.In addition to determining the most likely raag being performed, the system displays the estimated the likelihoodof each of the other possible raags, visualizing the changesover time. The system computes the pitch-class distributionand uses a Bayesian decision rule to classify the resultingtwelve dimensional feature vector, where each feature represents the relative use of each pitch class. We show that thesystem achieves high performance on a variety of sources,making it a viable tool for interactive performance.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {automatic recognition,indian music,nime08,raag,raga},
pages = {331--334},
}
@inproceedings{Ciglar2008,
author = {Ciglar, Miha},
url = {http://www.nime.org/proceedings/2008/nime2008_203.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {"3rd. Pole" – A Composition Performed via Gestural Cues},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {1,dancer,fig,from the system in,gesture recognition,haptic feedback,in,markers attached to the,motion tracking,nime08,s limbs,the dancer receives feedback,two ways},
pages = {203--206},
}
@inproceedings{Coghlan2008,
author = {Coghlan, Niall and Knapp, Benjamin},
url = {http://www.nime.org/proceedings/2008/nime2008_233.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sensory Chairs : A System for Biosignal Research and Performance},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Ubiquitous computing, context -awareness, networking, embedded systems, chairs, digital artefacts, emotional state sensing, affective computing, biosignals. },
pages = {233--236},
}
@inproceedings{Corness2008,
author = {Corness, Greg},
url = {http://www.nime.org/proceedings/2008/nime2008_265.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Performer Model : Towards a Framework for Interactive Performance Based on Perceived Intention},
year = {2008},
abstract = {Through the developing of tools for analyzing the performerssonic and movement-based gestures, research into the systemperformer interaction has focused on the computer's ability torespond to the performer. Where as such work shows interestwithin the community in developing an interaction paradigmmodeled on the player, by focusing on the perception andreasoning of the system, this research assumes that theperformer's manner of interaction is in agreement with thiscomputational model. My study presents an alternative model ofinteraction designed for improvisatory performance centered onthe perception of the performer as understood by theories takenfrom performance practices and cognitive science.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Interactive performance, Perception, HCI },
pages = {265--268},
}
@inproceedings{Crevoisier2008,
author = {Crevoisier, Alain and Kellum, Greg},
url = {http://www.nime.org/proceedings/2008/nime2008_113.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Transforming Ordinary Surfaces into Multi-touch Controllers},
year = {2008},
abstract = {In this paper, we describe a set of hardware and software tools for creating musical controllers with any flat surface or simple object, such as tables, walls, metallic plates, wood boards, etc. The system makes possible to transform such physical objects and surfaces into virtual control interfaces, by using computer vision technologies to track the interaction made by the musician, either with the hands, mallets or sticks. These new musical interfaces, freely reconfigurable, can be used to control standard sound modules or effect processors, by defining zones on their surface and assigning them musical commands, such as the triggering of notes or the modulation of parameters.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Computer Vision, Multi-touch Interaction, Musical Interfaces.  },
pages = {113--116},
}
@inproceedings{DeJong2008,
author = {de Jong, Staas},
url = {http://www.nime.org/proceedings/2008/nime2008_370.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Cyclotactor : Towards a Tactile Platform for Musical Interaction},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {370--371},
}
@inproceedings{DelleMonache2008,
author = {Delle Monache, Stefano and Polotti, Pietro and Papetti, Stefano and Rocchesso, Davide},
url = {http://www.nime.org/proceedings/2008/nime2008_154.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sonically Augmented Found Objects},
year = {2008},
abstract = {We present our work with augmented everyday objectstransformed into sound sources for music generation. The idea isto give voice to objects through technology. More specifically, theparadigm of the birth of musical instruments as a sonification ofobjects used in domestic or work everyday environments is hereconsidered and transposed into the technologically augmentedscenarios of our contemporary world.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Rag-time washboard, sounding objects, physics-based sound synthesis, interactivity, sonification, augmented everyday objects. },
pages = {154--157},
}
@inproceedings{Demey2008,
author = {Demey, Michiel and Leman, Marc and Bossuyt, Frederick and Vanfleteren, Jan},
url = {http://www.nime.org/proceedings/2008/nime2008_372.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Musical Synchrotron : Using Wireless Motion Sensors to Study How Social Interaction Affects Synchronization with Musical Tempo},
year = {2008},
abstract = {The Musical Synchrotron is a software interface that connects wireless motion sensors to a real-time interactive environment (Pure Data, Max/MSP). In addition to the measurement of movement, the system provides audio playback and visual feedback. The Musical Synchrotron outputs a score with the degree in which synchronization with the presented music is successful. The interface has been used to measure how people move in response to music. The system was used for experiments at public events. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Wireless sensors, tempo perception, social interaction, music and movement, embodied music cognition },
pages = {372--373},
}
@inproceedings{Dimitrov2008,
author = {Dimitrov, Smilen and Alonso, Marcos and Serafin, Stefania},
url = {http://www.nime.org/proceedings/2008/nime2008_211.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Developing Block-Movement, Physical-Model Based Objects for the Reactable},
year = {2008},
abstract = {This paper reports on a Short-Term Scientific Mission (STSM)sponsored by the Sonic Interaction Design (SID) EuropeanCOST Action IC601.Prototypes of objects for the novel instrument Reactablewere developed, with the goal of studying sonification ofmovements on this platform using physical models. A physical model of frictional interactions between rubbed dry surfaces was used as an audio generation engine, which alloweddevelopment in two directions - a set of objects that affordsmotions similar to sliding, and a single object aiming tosonify contact friction sound. Informal evaluation was obtained from a Reactable expert user, regarding these sets ofobjects. Experiments with the objects were also performed- related to both audio filtering, and interfacing with otherobjects for the Reactable.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Reactable, physical model, motion sonification, contact fric- tion },
pages = {211--214},
}
@inproceedings{Dubrau2008,
author = {Dubrau, Josh and Havryliv, Mark},
url = {http://www.nime.org/proceedings/2008/nime2008_164.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {P[a]ra[pra]xis : Poetry in Motion},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Poetry, language sonification, psychoanalysis, linguistics, Freud, realtime poetry.  },
pages = {164--167},
}
@inproceedings{Eigenfeldt2008,
author = {Eigenfeldt, Arne and Kapur, Ajay},
url = {http://www.nime.org/proceedings/2008/nime2008_144.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Agent-based System for Robotic Musical Performance},
year = {2008},
abstract = {This paper presents an agent-based architecture for robotic musical instruments that generate polyphonic rhythmic patterns that continuously evolve and develop in a musically "intelligent" manner. Agent-based software offers a new method for real-time composition that allows for complex interactions between individual voices while requiring very little user interaction or supervision. The system described, Kinetic Engine, is an environment in which individual software agents, emulate drummers improvising within a percussion ensemble. Player agents assume roles and personalities within the ensemble, and communicate with one another to create complex rhythmic interactions. In this project, the ensemble is comprised of a 12-armed musical robot, MahaDeviBot, in which each limb has its own software agent controlling what it performs. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Robotic Musical Instruments, Agents, Machine Musicianship. },
pages = {144--149},
}
@inproceedings{Endo2008,
author = {Endo, Ayaka and Kuhara, Yasuo},
url = {http://www.nime.org/proceedings/2008/nime2008_345.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Rhythmic Instruments Ensemble Simulator Generating Animation Movies Using Bluetooth Game Controller},
year = {2008},
abstract = {We developed a rhythmic instruments ensemble simulator generating animation using game controllers. The motion of a player is transformed into musical expression data of MIDI to generate sounds, and MIDI data are transformed into animation control parameters to generate movies. These animations and music are shown as the reflection of player performance. Multiple players can perform a musical ensemble to make more varied patterns of animation. Our system is so easy that everyone can enjoy performing a fusion of music and animation. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Wii Remote, Wireless game controller, MIDI, Max/MSP, Flash movie, Gesture music and animation.  },
pages = {345--346},
}
@inproceedings{Favilla2008,
author = {Favilla, Stuart and Cannon, Joanne and Hicks, Tony and Chant, Dale and Favilla, Paris},
url = {http://www.nime.org/proceedings/2008/nime2008_366.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Gluisax : Bent Leather Band’s Augmented Saxophone Project},
year = {2008},
abstract = {This demonstration presents three new augmented and metasaxophone interface/instruments, built by the Bent LeatherBand. The instruments are designed for virtuosic liveperformance and make use of Sukandar Kartadinata's Gluion[OSC] interfaces. The project rationale and research outcomesfor the first twelve months is discussed. Instruments/interfacesdescribed include the Gluisop, Gluialto and Leathersop.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Augmented saxophone, Gluion, OSC, virtuosic performance systems },
pages = {366--369},
}
@inproceedings{Flanigan2008,
author = {Flanigan, Lesley and Doro, Andrew},
url = {http://www.nime.org/proceedings/2008/nime2008_349.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Plink Jet},
year = {2008},
abstract = {Plink Jet is a robotic musical instrument made from scavenged inkjet printers and guitar parts. We investigate the expressive capabilities of everyday machine technology by recontextualizing the relatively high-tech mechanisms of typical office debris into an electro-acoustic musical instrument. We also explore the performative relationship between human and machine.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Interaction Design, Repurposing of Consumer Technology, DIY, Performing Technology, Robotics, Automation, Infra-Instrument  },
pages = {349--351},
}
@inproceedings{Follmer2008,
author = {Follmer, Sean and Warren, Chris and Marquez-Borbon, Adnan},
url = {http://www.nime.org/proceedings/2008/nime2008_354.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Pond : Interactive Multimedia Installation},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {354--355},
}
@inproceedings{Fraietta2008,
author = {Fraietta, Angelo},
url = {http://www.nime.org/proceedings/2008/nime2008_019.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Open Sound Control : Constraints and Limitations},
year = {2008},
abstract = {Open Sound Control (OSC) is being used successfully as amessaging protocol among many computers, gesturalcontrollers and multimedia systems. Although OSC hasaddressed some of the shortcomings of MIDI, OSC cannotdeliver on its promises as a real-time communication protocolfor constrained embedded systems. This paper will examinesome of the advantages but also dispel some of the mythsconcerning OSC. The paper will also describe how some of thebest features of OSC can be used to develop a lightweightprotocol that is microcontroller friendly.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {a,data transmission protocols,gestural controllers,has been implemented as,midi,nime08,open sound control,osc},
pages = {19--23},
}
@inproceedings{Freed2008,
author = {Freed, Adrian},
url = {http://www.nime.org/proceedings/2008/nime2008_107.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Application of new Fiber and Malleable Materials for Agile Development of Augmented Instruments and Controllers},
year = {2008},
abstract = {The paper introduces new fiber and malleable materials,including piezoresistive fabric and conductive heat-shrinktubing, and shows techniques and examples of how they maybe used for rapid prototyping and agile development of musicalinstrument controllers. New implementations of well-knowndesigns are covered as well as enhancements of existingcontrollers. Finally, two new controllers are introduced that aremade possible by these recently available materials andconstruction techniques.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Agile Development, Rapid Prototyping, Conductive fabric, Piezoresistive fabric, conductive heatshrink tubing, augmented instruments. },
pages = {107--112},
}
@inproceedings{Gatzsche2008,
author = {Gatzsche, Gabriel and Mehnert, Markus and St\"{o}cklmeier, Christian},
url = {http://www.nime.org/proceedings/2008/nime2008_325.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Interaction with Tonal Pitch Spaces},
year = {2008},
abstract = {In this paper, we present a pitch space based musical interface approach. A pitch space arranges tones in a way that meaningful tone combinations can be easily generated. Using a touch sensitive surface or a 3D-Joystick a player can move through the pitch space and create the desired sound by selecting tones. The more optimal the tones are geometrically arranged, the less control parameters are required to move through the space and to select the desired pitches. For this the quality of pitch space based musical interfaces depends on two factors: 1. the way how the tones are organized within the pitch space and 2. the way how the parameters of a given controller are used to move through the space and to select pitches. This paper presents a musical interface based on a tonal pitch space derived from a four dimensional model found by the music psychologists [11], [2]. The proposed pitch space particularly eases the creation of tonal harmonic music. Simultaneously it outlines music psychological and theoretical principles of music. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Pitch space, musical interface, Carol L. Krumhansl, music psychology, music theory, western tonal music, 3D tonality model, spiral of thirds, 3D, Hardware controller, Symmetry model  },
pages = {325--330},
}
@inproceedings{Geiger2008,
author = {Geiger, Christian and Reckter, Holger and Paschke, David and Schulz, Florian and Poepel, Cornelius},
url = {http://www.nime.org/proceedings/2008/nime2008_303.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards Participatory Design and Evaluation of Theremin-based Musical Interfaces},
year = {2008},
abstract = {Being one of the earliest electronic instruments the basic principles of the Theremin have often been used to design new musical interfaces. We present the structured design and evaluation of a set of 3D interfaces for a virtual Theremin, the VRemin. The variants differ in the size of the interaction space, the interface complexity, and the applied IO devices. We conducted a formal evaluation based on the well-known AttrakDiff questionnaire for evaluating the hedonic and pragmatic quality of interactive products. The presented work is a first approach towards a participatory design process for musical interfaces that includes user evaluation at early design phases. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {3d interaction techniques,an important concept for,both hands,evaluation,few wimp interface concepts,in contrast the use,make efficient use of,nime08,of both hands is,theremin-based interfaces},
pages = {303--306},
}
@inproceedings{Godbehere2008,
author = {Godbehere, Andrew B. and Ward, Nathan J.},
url = {http://www.nime.org/proceedings/2008/nime2008_237.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Wearable Interfaces for Cyberphysical Musical Expression},
year = {2008},
abstract = {We present examples of a wireless sensor network as applied to wearable digital music controllers. Recent advances in wireless Personal Area Networks (PANs) have precipitated the IEEE 802.15.4 standard for low-power, low-cost wireless sensor networks. We have applied this new technology to create a fully wireless, wearable network of accelerometers which are small enough to be hidden under clothing. Various motion analysis and machine learning techniques are applied to the raw accelerometer data in real-time to generate and control music on the fly. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Wearable computing, personal area networks, accelerometers, 802.15.4, motion analysis, human-computer interaction, live performance, digital musical controllers, gestural control  },
pages = {237--240},
}
@inproceedings{Goina2008,
author = {Goina, Maurizio and Polotti, Pietro},
url = {http://www.nime.org/proceedings/2008/nime2008_150.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Elementary Gestalts for Gesture Sonification},
year = {2008},
abstract = {In this paper, we investigate the relationships between gesture and sound by means of an elementary gesture sonification. This work takes inspiration from Bauhaus' ideals and Paul Klee's investigation into forms and pictorial representation. In line with these ideas, the main aim of this work is to reduce gesture to a combination of a small number of elementary components (gestalts) used to control a corresponding small set of sounds. By means of a demonstrative tool, we introduce here a line of research that is at its initial stage. The envisaged goal of future developments is a novel system that could be a composing/improvising tool as well as an interface for interactive dance and performance. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Bauhaus, Klee, gesture analysis, sonification.  },
pages = {150--153},
}
@inproceedings{Grosshauser2008,
author = {Grosshauser, Tobias},
url = {http://www.nime.org/proceedings/2008/nime2008_097.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Low Force Pressure Measurement : Pressure Sensor Matrices for Gesture Analysis , Stiffness Recognition and Augmented Instruments},
year = {2008},
abstract = {The described project is a new approach to use highly sensitive low force pressure sensor matrices for malposition, cramping and tension of hands and fingers, gesture and keystroke analysis and for new musical expression. In the latter, sensors are used as additional touch sensitive switches and keys. In pedagogical issues, new ways of technology enhanced teaching, self teaching and exercising are described. The used sensors are custom made in collaboration with the ReactiveS Sensorlab. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Pressure Measurement, Force, Sensor, Finger, Violin, Strings, Piano, Left Hand, Right Hand, Time Line, Cramping, Gesture and Posture Analysis.  },
pages = {97--102},
}
@inproceedings{Hadjakos2008,
author = {Hadjakos, Aristotelis and Aitenbichler, Erwin and M\"{u}hlh\"{a}user, Max},
url = {http://www.nime.org/proceedings/2008/nime2008_285.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Elbow Piano : Sonification of Piano Playing Movements},
year = {2008},
abstract = {The Elbow Piano distinguishes two types of piano touch: a touchwith movement in the elbow joint and a touch without. A playednote is first mapped to the left or right hand by visual tracking.Custom-built goniometers attached to the player's arms are usedto detect the type of touch. The two different types of touchesare sonified by different instrument sounds. This gives theplayer an increased awareness of his elbow movements, which isconsidered valuable for piano education. We have implementedthe system and evaluated it with a group of music students.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Piano, education, sonification, feedback, gesture. },
pages = {285--288},
}
@inproceedings{Hansen2008,
author = {Hansen, Kjetil F. and Alonso, Marcos},
url = {http://www.nime.org/proceedings/2008/nime2008_207.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {More DJ Techniques on the reactable},
year = {2008},
abstract = {This paper describes a project started for implementing DJscratching techniques on the reactable. By interacting withobjects representing scratch patterns commonly performedon the turntable and the crossfader, the musician can playwith DJ techniques and manipulate how they are executedin a performance. This is a novel approach to the digital DJapplications and hardware. Two expert musicians practisedand performed on the reactable in order to both evaluate theplayability and improve the design of the DJ techniques.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {dj scratch techniques,interfaces,nime08,playability,reactable},
pages = {207--210},
}
@inproceedings{Hartman2008,
author = {Hartman, Ethan and Cooper, Jeff and Spratt, Kyle},
url = {http://www.nime.org/proceedings/2008/nime2008_356.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Swing Set : Musical Controllers with Inherent Physical Dynamics},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {356--357},
}
@inproceedings{Hashida2008,
author = {Hashida, Mitsuyo and Ito, Yosuke and Katayose, Haruhiro},
url = {http://www.nime.org/proceedings/2008/nime2008_277.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Directable Performance Rendering System : Itopul},
year = {2008},
abstract = {One of the advantages of case-based systems is that theycan generate expressions even if the user doesn't know howthe system applies expression rules. However, the systemscannot avoid the problem of data sparseness and do notpermit a user to improve the expression of a certain part ofa melody directly. After discussing the functions requiredfor user-oriented interface for performance rendering systems, this paper proposes a directable case-based performance rendering system, called Itopul. Itopul is characterized by 1) a combination of the phrasing model and thepulse model, 2) the use of a hierarchical music structure foravoiding from the data sparseness problem, 3) visualizationof the processing progress, and 4) music structures directlymodifiable by the user.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Performance Rendering, User Interface, Case-based Approach },
pages = {277--280},
}
@inproceedings{Hayafuchi2008,
author = {Hayafuchi, Kouki and Suzuki, Kenji},
url = {http://www.nime.org/proceedings/2008/nime2008_241.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {MusicGlove : A Wearable Musical Controller for Massive Media Library},
year = {2008},
abstract = {This research aims to develop a wearable musical interfacewhich enables to control audio and video signals by usinghand gestures and human body motions. We have beendeveloping an audio-visual manipulation system that realizes tracks control, time-based operations and searching fortracks from massive music library. It aims to build an emotional and affecting musical interaction, and will providea better method of music listening to people. A sophisticated glove-like device with an acceleration sensor and several strain sensors has been developed. A realtime signalprocessing and musical control are executed as a result ofgesture recognition. We also developed a stand-alone device that performs as a musical controller and player at thesame time. In this paper, we describe the development of acompact and sophisticated sensor device, and demonstrateits performance of audio and video signals control.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Embodied Sound Media, Music Controller, Gestures, Body Motion, Musical Interface },
pages = {241--244},
}
@inproceedings{Hazlewood2008,
author = {Hazlewood, William R. and Knopke, Ian},
url = {http://www.nime.org/proceedings/2008/nime2008_281.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Designing Ambient Musical Information Systems},
year = {2008},
abstract = {In this work we describe our initial explorations in building a musical instrument specifically for providing listenerswith simple, but useful, ambient information. The termAmbient Musical Information Systems (AMIS) is proposedto describe this kind of research. Instruments like these differ from standard musical instruments in that they are tobe perceived indirectly from outside one's primary focus ofattention. We describe our rationale for creating such a device, a discussion on the appropriate qualities of sound fordelivering ambient information, and a description of an instrument created for use in a series of experiments that wewill use to test out ideas. We conclude with a discussion ofour initial findings, and some further directions we wish toexplore.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Ambient Musical Information Systems, musical instruments, human computer interaction, Markov chain, probability, al- gorithmic composition },
pages = {281--284},
}
@inproceedings{Henriques2008,
author = {Henriques, Tom\'{a}s},
url = {http://www.nime.org/proceedings/2008/nime2008_307.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {META-EVI Innovative Performance Paths with a Wind Controller},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {computer music,musical instrument,nime08,sensor technologies},
pages = {307--310},
}
@inproceedings{Jacobs2008,
author = {Jacobs, Robert and Feldmeier, Mark and Paradiso, Joseph A.},
url = {http://www.nime.org/proceedings/2008/nime2008_193.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Mobile Music Environment Using a PD Compiler and Wireless Sensors},
year = {2008},
abstract = {None},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {None},
pages = {193--196},
}
@inproceedings{Jo2008,
author = {Jo, Kazuhiro and Nagano, Norihisa},
url = {http://www.nime.org/proceedings/2008/nime2008_315.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Monalisa : "See the Sound , Hear the Image"},
year = {2008},
abstract = {Monalisa is a software platform that enables to "see the sound, hear the image". It consists of three software: Monalisa Application, Monalisa-Audio Unit, and Monalisa-Image Unit, and an installation: Monalisa "shadow of the sound". In this paper, we describe the implementation of each software and installation with the explanation of the basic algorithms to treat the image data and the sound data transparently.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Sound and Image Processing Software, Plug-in, Installation },
pages = {315--318},
}
@inproceedings{Kamiyama2008,
author = {Kamiyama, Yusuke and Tanaka, Mai and Tanaka, Hiroya},
url = {http://www.nime.org/proceedings/2008/nime2008_352.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Oto-Shigure : An Umbrella-Shaped Sound Generator for Musical Expression},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {umbrella, musical expression, sound generating device, 3D sound system, sound-field arrangement. },
pages = {352--353},
}
@inproceedings{Kiefer2008,
author = {Kiefer, Chris and Collins, Nick and Fitzpatrick, Geraldine},
url = {http://www.nime.org/proceedings/2008/nime2008_087.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {HCI Methodology For Evaluating Musical Controllers : A Case Study},
year = {2008},
abstract = {There is small but useful body of research concerning theevaluation of musical interfaces with HCI techniques. Inthis paper, we present a case study in implementing thesetechniques; we describe a usability experiment which evaluated the Nintendo Wiimote as a musical controller, andreflect on the effectiveness of our choice of HCI methodologies in this context. The study offered some valuable results,but our picture of the Wiimote was incomplete as we lackeddata concerning the participants' instantaneous musical experience. Recent trends in HCI are leading researchers totackle this problem of evaluating user experience; we reviewsome of their work and suggest that with some adaptation itcould provide useful new tools and methodologies for computer musicians.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {HCI Methodology, Wiimote, Evaluating Musical Interac- tion },
pages = {87--90},
}
@inproceedings{KimBoyle2008,
author = {Kim-Boyle, David},
url = {http://www.nime.org/proceedings/2008/nime2008_003.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Network Musics - Play , Engagement and the Democratization of Performance},
year = {2008},
abstract = {The rapid development of network communicationtechnologies has allowed composers to create new ways inwhich to directly engage participants in the exploration of newmusical environments. A number of distinctive aestheticapproaches to the musical application of networks will beoutlined in this paper each of which is mediated andconditioned by the technical and aesthetic foundations of thenetwork technologies themselves. Recent work in the field byartists such as Atau Tanaka and Metraform will be examined, aswill some of the earlier pioneering work in the genre by MaxNeuhaus. While recognizing the historical context ofcollaborative work, the ,
,
author will examine how the strategiesemployed in the work of these artists have helped redefine anew aesthetics of engagement in which play, spatial andtemporal dislocation are amongst the genre's definingcharacteristics.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Networks, collaborative, open-form, play, interface. },
pages = {3--8},
}
@inproceedings{Kimura2008,
author = {Kimura, Mari},
url = {http://www.nime.org/proceedings/2008/nime2008_219.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Making of VITESSIMO for Augmented Violin : Compositional Process and Performance},
year = {2008},
abstract = {This paper describes the compositional process for creatingthe interactive work for violin entitled VITESSIMO using theAugmented Violin [1].},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Augmented Violin, gesture tracking, interactive performance },
pages = {219--220},
}
@inproceedings{Kuyken2008,
author = {Kuyken, Bart and Verstichel, Wouter and Bossuyt, Frederick and Vanfleteren, Jan and Demey, Michiel and Leman, Marc},
url = {http://www.nime.org/proceedings/2008/nime2008_229.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The HOP Sensor : Wireless Motion Sensor},
year = {2008},
abstract = {This paper describes the HOP system. It consists of a wireless module built up by multiple nodes and a base station. The nodes detect acceleration of e.g. human movement. At a rate of 100 Hertz the base station collects the acceleration samples. The data can be acquired in real-time software like Pure Data and Max/MSP. The data can be used to analyze and/or sonify movement. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Digital Musical Instrument, Wireless Sensors, Inertial Sensing, Hop Sensor  },
pages = {229--232},
}
@inproceedings{Kallblad2008,
author = {K\"{a}llblad, Anna and Friberg, Anders and Svensson, Karl and Edelholm, Elisabet S.},
url = {http://www.nime.org/proceedings/2008/nime2008_128.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Hoppsa Universum – An Interactive Dance Installation for Children},
year = {2008},
abstract = {It started with an idea to create an empty space in which you activated music and light as you moved around. In responding to the music and lighting you would activate more or different sounds and thereby communicate with the space through your body. This led to an artistic research project in which children's spontaneous movement was observed, a choreography made based on the children's movements and music written and recorded for the choreography. This music was then decomposed and choreographed into an empty space at Botkyrka konsthall creating an interactive dance installation. It was realized using an interactive sound and light system in which 5 video cameras were detecting the motion in the room connected to a 4-channel sound system and a set of 14 light modules. During five weeks people of all ages came to dance and move around in the installation. The installation attracted a wide range of people of all ages and the tentative evaluation indicates that it was very positively received and that it encouraged free movement in the intended way. Besides observing the activity in the installation interviews were made with schoolchildren age 7 who had participated in the installation. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Installation, dance, video recognition, children's movement, interactive multimedia  },
pages = {128--133},
}
@inproceedings{Lanzalone2008,
author = {Lanzalone, Silvia},
url = {http://www.nime.org/proceedings/2008/nime2008_273.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The 'Suspended Clarinet' with the 'Uncaused Sound' : Description of a Renewed Musical Instrument},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {273--276},
}
@inproceedings{Laurson2008,
author = {Laurson, Mikael and Kuuskankare, Mika},
url = {http://www.nime.org/proceedings/2008/nime2008_034.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards Idiomatic and Flexible Score-based Gestural Control with a Scripting Language},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {synthesis control, expressive timing, playing styles },
pages = {34--37},
}
@inproceedings{Loviscach2008,
author = {Loviscach, J\"{o}rn},
url = {http://www.nime.org/proceedings/2008/nime2008_221.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Programming a Music Synthesizer through Data Mining},
year = {2008},
abstract = {Sound libraries for music synthesizers easily comprise onethousand or more programs ("patches"). Thus, there areenough raw data to apply data mining to reveal typicalsettings and to extract dependencies. Intelligent user interfaces for music synthesizers can be based on such statistics.This paper proposes two approaches: First, the user setsany number of parameters and then lets the system find thenearest sounds in the database, a kind of patch autocompletion. Second, all parameters are "live" as usual, but turningone knob or setting a switch will also change the settingsof other, statistically related controls. Both approaches canbe used with the standard interface of the synthesizer. Ontop of that, this paper introduces alternative or additionalinterfaces based on data visualization.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Information visualization, mutual information, intelligent user interfaces },
pages = {221--224},
}
@inproceedings{Lahdeoja2008,
author = {L\"{a}hdeoja, Otso},
url = {http://www.nime.org/proceedings/2008/nime2008_053.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Approach to Instrument Augmentation : the Electric Guitar},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Augmented instrument, electric guitar, gesture-sound relationship },
pages = {53--56},
}
@inproceedings{Macrae2008,
author = {Macrae, Robert and Dixon, Simon},
url = {http://www.nime.org/proceedings/2008/nime2008_364.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {From Toy to Tutor : Note-Scroller is a Game to Teach Music},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Graphical Interface, Computer Game, MIDI Display },
pages = {364--365},
}
@inproceedings{Maniatakos2008,
author = {Maniatakos, Vassilios-Fivos A. and Jacquemin, Christian},
url = {http://www.nime.org/proceedings/2008/nime2008_122.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards an Affective Gesture Interface for Expressive Music Performance},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {affective computing, interactive performance, HMM, gesture recognition, intelligent mapping, affective interface },
pages = {122--127},
}
@inproceedings{McMillen2008,
author = {McMillen, Keith A.},
url = {http://www.nime.org/proceedings/2008/nime2008_347.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Stage-Worthy Sensor Bows for Stringed Instruments},
year = {2008},
abstract = {The demonstration of a series of properly weighted and balanced Bluetooth sensor bows for violin, viola, cello and bass. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Sensor bow, stringed instruments, bluetooth  },
pages = {347--348},
}
@inproceedings{Menzies2008,
author = {Menzies, Dylan},
url = {http://www.nime.org/proceedings/2008/nime2008_071.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Virtual Intimacy : Phya as an Instrument},
year = {2008},
abstract = {Phya is an open source C++ library originally designed foradding physically modeled contact sounds into computergame environments equipped with physics engines. We review some aspects of this system, and also consider it fromthe purely aesthetic perspective of musical expression.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {NIME, musical expression, virtual reality, physical model- ing, audio synthesis },
pages = {71--76},
}
@inproceedings{Modler2008,
author = {Modler, Paul and Myatt, Tony},
url = {http://www.nime.org/proceedings/2008/nime2008_358.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Video Based Recognition of Hand Gestures by Neural Networks for the Control of Sound and Music},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {358--359},
}
@inproceedings{Nash2008,
author = {Nash, Chris and Blackwell, Alan},
url = {http://www.nime.org/proceedings/2008/nime2008_028.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Realtime Representation and Gestural Control of Musical Polytempi},
year = {2008},
abstract = {Over the last century, composers have made increasingly ambitious experiments with musical time, but have been impeded in expressing more temporally-complex musical processes by the limitations of both music notations and human performers. In this paper, we describe a computer-based notation and gestural control system for independently manipulating the tempi of musical parts within a piece, at performance time. We describe how the problem was approached, drawing upon feedback and suggestions from consultations across multiple disciplines, seeking analogous problems in other fields. Throughout, our approach is guided and, ultimately, assessed by an established professional composer, who was able to interact with a working prototype of the system. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {composition,gesture,nime08,performance,polytempi,realtime,tempo},
pages = {28--33},
}
@inproceedings{Ng2008,
author = {Ng, Kia and Nesi, Paolo},
url = {http://www.nime.org/proceedings/2008/nime2008_225.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {i-Maestro : Technology-Enhanced Learning and Teaching for Music},
year = {2008},
abstract = {This paper presents a project called i-Maestro (www.i-maestro.org) which develops interactive multimedia environments for technology enhanced music education. The project explores novel solutions for music training in both theory and performance, building on recent innovations resulting from the development of computer and information technologies, by exploiting new pedagogical paradigms with cooperative and interactive self-learning environments, gesture interfaces, and augmented instruments. This paper discusses the general context along with the background and current developments of the project, together with an overview of the framework and discussions on a number of selected tools to support technology-enhanced music learning and teaching. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {augmented instrument,education,gesture,interactive,interface,motion,multimedia,music,nime08,notation,sensor,sonification,technology-enhanced learning,visualisation},
pages = {225--228},
}
@inproceedings{Pakarinen2008,
author = {Pakarinen, Jyri and V\"{a}lim\"{a}ki, Vesa and Puputti, Tapio},
url = {http://www.nime.org/proceedings/2008/nime2008_049.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Slide Guitar Synthesizer with Gestural Control},
year = {2008},
abstract = {This article discusses a virtual slide guitar instrument, recently introduced in [7]. The instrument consists of a novelphysics-based synthesis model and a gestural user interface.The synthesis engine uses energy-compensated time-varyingdigital waveguides. The string algorithm also contains aparametric model for synthesizing the tube-string contactsounds. The real-time virtual slide guitar user interface employs optical gesture recognition, so that the user can playthis virtual instrument simply by making slide guitar playing gestures in front of a camera.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Sound synthesis, slide guitar, gesture control, physical mod- eling },
pages = {49--52},
}
@inproceedings{PalacioQuintin2008,
author = {Palacio-Quintin, Cl\'{e}o},
url = {http://www.nime.org/proceedings/2008/nime2008_293.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Eight Years of Practice on the Hyper-Flute : Technological and Musical Perspectives},
year = {2008},
abstract = {After eight years of practice on the first hyper-flute prototype (a flute extended with sensors), this article presentsa retrospective of its instrumental practice and the newdevelopments planned from both technological and musical perspectives. Design, performance skills, and mappingstrategies are discussed, as well as interactive compositionand improvisation.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {composition,gestural control,hyper-flute,hyper-instruments,improvisation,interactive music,mapping,nime08,sensors},
pages = {293--298},
}
@inproceedings{Pelletier2008,
author = {Pelletier, Jean-Marc},
url = {http://www.nime.org/proceedings/2008/nime2008_158.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sonified Motion Flow Fields as a Means of Musical Expression},
year = {2008},
abstract = {This paper describes a generalized motion-based framework forthe generation of large musical control fields from imaging data.The framework is general in the sense that it does not depend ona particular source of sensing data. Real-time images of stageperformers, pre-recorded and live video, as well as more exoticdata from imaging systems such as thermography, pressuresensor arrays, etc. can be used as a source of control. Featurepoints are extracted from the candidate images, from whichmotion vector fields are calculated. After some processing, thesemotion vectors are mapped individually to sound synthesisparameters. Suitable synthesis techniques include granular andmicrosonic algorithms, additive synthesis and micro-polyphonicorchestration. Implementation details of this framework isdiscussed, as well as suitable creative and artistic uses andapproaches.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Computer vision, control field, image analysis, imaging, mapping, microsound, motion flow, sonification, synthesis },
pages = {158--163},
}
@inproceedings{Place2008,
author = {Place, Timothy and Lossius, Trond and Jensenius, Alexander R. and Peters, Nils},
url = {http://www.nime.org/proceedings/2008/nime2008_181.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Addressing Classes by Differentiating Values and Properties in OSC},
year = {2008},
abstract = {An approach for creating structured Open Sound Control(OSC) messages by separating the addressing of node valuesand node properties is suggested. This includes a methodfor querying values and properties. As a result, it is possibleto address complex nodes as classes inside of more complextree structures using an OSC namespace. This is particularly useful for creating flexible communication in modularsystems. A prototype implementation is presented and discussed.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {jamoma,namespace,nime08,osc,standardization},
pages = {181--184},
}
@inproceedings{Price2008,
author = {Price, Robin and Rebelo, Pedro},
url = {http://www.nime.org/proceedings/2008/nime2008_311.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Database and Mapping Design for Audiovisual Prepared Radio Set Installation},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Mapping, database, audiovisual, radio, installation art.  },
pages = {311--314},
}
@inproceedings{Robertson2008,
author = {Robertson, Andrew and Plumbley, Mark D. and Bryan-Kinns, Nick},
url = {http://www.nime.org/proceedings/2008/nime2008_319.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Turing Test for B-Keeper : Evaluating an Interactive},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Automatic Accompaniment, Beat Tracking, Human-Computer Interaction, Musical Interface Evaluation },
pages = {319--324},
}
@inproceedings{Roma2008,
author = {Roma, Gerard and Xamb\'{o}, Anna},
url = {http://www.nime.org/proceedings/2008/nime2008_249.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Tabletop Waveform Editor for Live Performance},
year = {2008},
abstract = {We present an audio waveform editor that can be operated in real time through a tabletop interface. The systemcombines multi-touch and tangible interaction techniques inorder to implement the metaphor of a toolkit that allows direct manipulation of a sound sample. The resulting instrument is well suited for live performance based on evolvingloops.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {tangible interface, tabletop interface, musical performance, interaction techniques },
pages = {249--252},
}
@inproceedings{Raisanen2008,
author = {R\"{a}is\"{a}nen, Juhani},
url = {http://www.nime.org/proceedings/2008/nime2008_057.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sormina – a New Virtual and Tangible Instrument},
year = {2008},
abstract = {This paper describes the Sormina, a new virtual and tangibleinstrument, which has its origins in both virtual technology andthe heritage of traditional instrument design. The motivationbehind the project is presented, as well as hardware andsoftware design. Insights gained through collaboration withacoustic musicians are presented, as well as comparison tohistorical instrument design.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Gestural controller, digital musical instrument, usability, music history, design. },
pages = {57--60},
}
@inproceedings{Schacher2008,
author = {Schacher, Jan C.},
url = {http://www.nime.org/proceedings/2008/nime2008_168.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Davos Soundscape, a Location Based Interactive Composition},
year = {2008},
abstract = {Moving out of doors with digital tools and electronic music and creating musically rich experiences is made possible by the increased availability of ever smaller and more powerful mobile computers. Composing music for and in a landscape instead of for a closed architectural space offers new perspectives but also raises questions about interaction and composition of electronic music. The work we present here was commissioned by a festival and ran on a daily basis over a period of three months. A GPS-enabled embedded Linux system is assembled to serve as a location-aware sound platform. Several challenges have to be overcome both technically and artistically to achieve a seamless experience and provide a simple device to be handed to the public. By building this interactive experience, which relies as much on the user's willingness to explore the invisible sonic landscape as on the ability to deploy the technology, a number of new avenues for exploring electronic music and interactivity in location-based media open up. New ways of composing music for and in a landscape and for creating audience interaction are explored. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Location-based, electronic music, composition, embedded Linux, GPS, Pure Data, interaction, mapping, soundscape },
pages = {168--171},
}
@inproceedings{Schedel2008,
author = {Schedel, Margaret and Rootberg, Alison and de Martelly, Elizabeth},
url = {http://www.nime.org/proceedings/2008/nime2008_339.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Scoring an Interactive, Multimedia Performance Work},
year = {2008},
abstract = {The Color of Waiting is an interactive theater workwith music, dance, and video which was developed atSTEIM in Amsterdam and further refined at CMMASin Morelia Mexico with funding from Meet theComposer. Using Max/MSP/ Jitter a cellist is able tocontrol sound and video during the performancewhile performing a structured improvisation inresponse to the dancer's movement. In order toensure. repeated performances of The Color o fWaiting , Kinesthetech Sense created the scorecontained in this paper. Performance is essential tothe practice of time-based art as a living form, buthas been complicated by the unique challenges ininterpretation and re-creation posed by worksincorporating technology. Creating a detailed scoreis one of the ways artists working with technologycan combat obsolescence.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {339--342},
}
@inproceedings{Schmeder2008,
author = {Schmeder, Andrew and Freed, Adrian},
url = {http://www.nime.org/proceedings/2008/nime2008_175.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {uOSC : The Open Sound Control Reference Platform for Embedded Devices},
year = {2008},
abstract = {A general-purpose firmware for a low cost microcontroller is described that employs the Open Sound Control protocol over USB. The firmware is designed with considerations for integration in new musical interfaces and embedded devices. Features of note include stateless design, efficient floating-point support, temporally correct data handling, and protocol completeness. A timing performance analysis is conducted.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {jitter,latency,nime08,open sound control,pic microcontroller,usb},
pages = {175--180},
}
@inproceedings{Sjuve2008,
author = {Sjuve, Eva},
url = {http://www.nime.org/proceedings/2008/nime2008_362.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Prototype GO : Wireless Controller for Pure Data},
year = {2008},
abstract = {This paper describes the development of a wireless wearablecontroller, GO, for both sound processing and interactionwith wearable lights. Pure Data is used for sound processing.The GO prototype is built using a PIC microcontroller usingvarious sensors for receiving information from physicalmovements.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Wireless controller, Pure Data, Gestural interface, Interactive Lights. },
pages = {362--363},
}
@inproceedings{Stowell2008,
author = {Stowell, Dan and Plumbley, Mark D. and Bryan-Kinns, Nick},
url = {http://www.nime.org/proceedings/2008/nime2008_081.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Discourse Analysis Evaluation Method for Expressive Musical Interfaces},
year = {2008},
abstract = {The expressive and creative affordances of an interface aredifficult to evaluate, particularly with quantitative methods.However, rigorous qualitative methods do exist and can beused to investigate such topics. We present a methodologybased around user studies involving Discourse Analysis ofspeech. We also present an example of the methodologyin use: we evaluate a musical interface which utilises vocaltimbre, with a user group of beatboxers.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {discourse analysis,evaluation,nime08,qualitative methods,voice},
pages = {81--86},
}
@inproceedings{Suzuki2008,
author = {Suzuki, Kenji and Kyoya, Miho and Kamatani, Takahiro and Uchiyama, Toshiaki},
url = {http://www.nime.org/proceedings/2008/nime2008_360.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {beacon : Embodied Sound Media Environment for Socio-Musical Interaction},
year = {2008},
abstract = {This research aims to develop a novel instrument for sociomusical interaction where a number of participants can produce sounds by feet in collaboration with each other. Thedeveloped instrument, beacon, is regarded as embodied soundmedia product that will provide an interactive environmentaround it. The beacon produces laser beams lying on theground and rotating. Audio sounds are then produced whenthe beams pass individual performer's foot. As the performers are able to control the pitch and sound length accordingto the foot location and angles facing the instrument, theperformer's body motion and foot behavior can be translated into sound and music in an intuitive manner.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Embodied sound media, Hyper-instrument, Laser beams },
pages = {360--361},
}
@inproceedings{Takegawa2008,
author = {Takegawa, Yoshinari and Tsukamoto, Masahiko},
url = {http://www.nime.org/proceedings/2008/nime2008_289.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {UnitKeyboard : An Easily Configurable Compact Clavier},
year = {2008},
abstract = {Musical keyboard instruments have a long history, whichresulted in many kinds of keyboards (claviers) today. Sincethe hardware of conventional musical keyboards cannot bechanged, such as the number of keys, musicians have tocarry these large keyboards for playing music that requiresonly a small diapason. To solve this problem, the goal ofour study is to construct UnitKeyboard, which has only 12keys (7 white keys and 5 black keys) and connectors fordocking with other UnitKeyboards. We can build variouskinds of musical keyboard configurations by connecting oneUnitKeyboard to others, since they have automatic settingsfor multiple keyboard instruments. We discuss the usabilityof the UnitKeyboard from reviews by several amateur andprofessional pianists who used the UnitKeyboard.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Portable keyboard instruments, block interface, Automatic settings },
pages = {289--292},
}
@inproceedings{Teles2008,
author = {Teles, Paulo C. and Boyle, Aidan},
url = {http://www.nime.org/proceedings/2008/nime2008_269.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Developing an "Antigenous" Art Installation Based on a Touchless Endosystem Interface},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {269--272},
}
@inproceedings{Thiebaut2008,
author = {Thiebaut, Jean-Baptiste and Abdallah, Samer and Robertson, Andrew and Bryan-Kinns, Nick and Plumbley, Mark D.},
url = {http://www.nime.org/proceedings/2008/nime2008_215.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Real Time Gesture Learning and Recognition : Towards Automatic Categorization},
year = {2008},
abstract = {This research focuses on real-time gesture learning and recognition. Events arrive in a continuous stream without explicitly given boundaries. To obtain temporal accuracy, weneed to consider the lag between the detection of an eventand any effects we wish to trigger with it. Two methodsfor real time gesture recognition using a Nintendo Wii controller are presented. The first detects gestures similar to agiven template using either a Euclidean distance or a cosinesimilarity measure. The second method uses novel information theoretic methods to detect and categorize gestures inan unsupervised way. The role of supervision, detection lagand the importance of haptic feedback are discussed.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Gesture recognition, supervised and unsupervised learning, interaction, haptic feedback, information dynamics, HMMs },
pages = {215--218},
}
@inproceedings{Torre2008,
author = {Torre, Giuseppe and Torres, Javier and Fernstr\"{o}m, Mikael},
url = {http://www.nime.org/proceedings/2008/nime2008_103.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Development of Motion Tracking Algorithms for Low Cost Inertial Measurement Units},
year = {2008},
abstract = {In this paper, we describe an algorithm for the numericalevaluation of the orientation of an object to which a clusterof accelerometers, gyroscopes and magnetometers has beenattached. The algorithm is implemented through a set ofMax/Msp and pd new externals. Through the successfulimplementation of the algorithm, we introduce Pointingat, a new gesture device for the control of sound in a 3Denvironment. This work has been at the core of the Celeritas Project, an interdisciplinary research project on motiontracking technology and multimedia live performances between the Tyndall Institute of Cork and the InteractionDesign Centre of Limerick.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {eu-,ler,max,micro-electro-mechanical,msp,nime08,orientation matrix,pd,pitch yaw and roll,quaternion,sensors,surement unit,tracking orientation,wimu,wireless inertial mea-},
pages = {103--106},
}
@inproceedings{Valle2008,
author = {Valle, Andrea},
url = {http://www.nime.org/proceedings/2008/nime2008_257.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {GeoGraphy : a Real-Time, Graph-Based Composition Environment},
year = {2008},
abstract = {This paper is about GeoGraphy, a graph-based system forthe control of both musical composition and interactive performance and its implementation in a real-time, interactiveapplication. The implementation includes a flexible userinterface system.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {a graph,composition,figure 1,interfaces,left,live coding,musical algorithmic composition,nime08,performance,vertex durations and coor-},
pages = {257--260},
}
@inproceedings{Valle2008a,
author = {Valle, Andrea},
url = {http://www.nime.org/proceedings/2008/nime2008_253.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Integrated Algorithmic Composition Fluid systems for including notation in music composition cycle},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {algorithmic composition,automatic notation,nime08},
pages = {253--256},
}
@inproceedings{Vinjar2008,
author = {Vinjar, Anders},
url = {http://www.nime.org/proceedings/2008/nime2008_335.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Bending Common Music with Physical Models},
year = {2008},
abstract = {A general CAC1-environment charged with physical-modelling capabilities is described. It combines CommonMusic,ODE and Fluxus in a modular way, making a powerful andflexible environment for experimenting with physical modelsin composition.Composition in this respect refers to the generation andmanipulation of structure typically on or above a note, phrase or voice-level. Compared to efforts in synthesisand performance little work has gone into applying physicalmodels to composition. Potentials in composition-applications are presumably large.The implementation of the physically equipped CAC-environment is described in detail.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Physical Models in composition, CommonMusic, Musical mapping },
pages = {335--338},
}
@inproceedings{Ward2008,
author = {Ward, Nicholas and Penfield, Kedzie and O'Modhrain, Sile and Knapp, Benjamin},
url = {http://www.nime.org/proceedings/2008/nime2008_117.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Study of Two Thereminists : Towards Movement Informed Instrument Design},
year = {2008},
abstract = {This paper presents a comparison of the movement styles of two theremin players based on observation and analysis of video recordings. The premise behind this research is that a consideration of musicians' movements could form the basis for a new framework for the design of new instruments. Laban Movement Analysis is used to qualitatively analyse the movement styles of the musicians and to argue that the Recuperation phase of their phrasing is essential to achieve satisfactory performance. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Effort Phrasing, Recuperation, Laban Movement Analysis, Theremin },
pages = {117--121},
}
@inproceedings{Wozniewski2008,
author = {Wozniewski, Mike and Bouillot, Nicolas and Settel, Zack and Cooperstock, Jeremy R.},
url = {http://www.nime.org/proceedings/2008/nime2008_013.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Large-Scale Mobile Audio Environments for Collaborative Musical Interaction},
year = {2008},
abstract = {New application spaces and artistic forms can emerge whenusers are freed from constraints. In the general case ofhuman-computer interfaces, users are often confined to afixed location, severely limiting mobility. To overcome thisconstraint in the context of musical interaction, we presenta system to manage large-scale collaborative mobile audioenvironments, driven by user movement. Multiple participants navigate through physical space while sharing overlaid virtual elements. Each user is equipped with a mobilecomputing device, GPS receiver, orientation sensor, microphone, headphones, or various combinations of these technologies. We investigate methods of location tracking, wireless audio streaming, and state management between mobiledevices and centralized servers. The result is a system thatallows mobile users, with subjective 3-D audio rendering,to share virtual scenes. The audio elements of these scenescan be organized into large-scale spatial audio interfaces,thus allowing for immersive mobile performance, locativeaudio installations, and many new forms of collaborativesonic activity.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {sonic navigation, mobile music, spatial interaction, wireless audio streaming, locative media, collaborative interfaces },
pages = {13--18},
}
@inproceedings{Young2008,
author = {Young, Diana},
url = {http://www.nime.org/proceedings/2008/nime2008_044.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Classification of Common Violin Bowing Techniques Using Gesture Data from a Playable Measurement System},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {bowing, gesture, playing technique, principal component anal- ysis, classification },
pages = {44--48},
}
@inproceedings{Zannos2008,
author = {Zannos, Iannis},
url = {http://www.nime.org/proceedings/2008/nime2008_261.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Multi-Platform Development of Audiovisual and Kinetic Installations},
year = {2008},
abstract = {In this paper, we describe the development of multi-platform tools for Audiovisual and Kinetic installations. These involve the connection of three development environments: Python, SuperCollider and Processing, in order to drive kinetic art installations and to combine these with digital synthesis of sound and image in real time. By connecting these three platforms via the OSC protocol, we enable the control in real time of analog physical media (a device that draws figures on sand), sound synthesis and image synthesis. We worked on the development of algorithms for drawing figures and synthesizing images and sound on all three platforms and experimented with various mechanisms for coordinating synthesis and rendering in different media. Several problems were addressed: How to coordinate the timing between different platforms? What configuration to use? Clientserver (who is the client who the server?), equal partners, mixed configurations. A library was developed in SuperCollider to enable the packaging of algorithms into modules with automatic generation of GUI from specifications, and the saving of configurations of modules into session files as scripts in SuperCollider code. The application of this library as a framework for both driving graphic synthesis in Processing and receiving control data from it resulted in an environment for experimentation that is also being used successfully in teaching interactive audiovisual media. },
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {kinetic art, audiovisual installations, python, SuperCollider, Processing, algorithmic art, tools for multi-platform development  },
pages = {261--264},
}
@inproceedings{Zbyszynski2008,
author = {Zbyszynski, Michael},
url = {http://www.nime.org/proceedings/2008/nime2008_245.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Elementary Method for Tablet},
year = {2008},
abstract = {This paper proposes the creation of a method book for tabletbased instruments, evaluating pedagogical materials fortraditional instruments as well as research in human-computerinteraction and tablet interfaces.},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {Wacom tablet, digitizing tablet, expressivity, gesture, mapping, pedagogy, practice },
pages = {245--248},
}
@inproceedings{Zoran2008,
author = {Zoran, Amit and Maes, Pattie},
url = {http://www.nime.org/proceedings/2008/nime2008_067.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Considering Virtual \& Physical Aspects in Acoustic Guitar Design},
year = {2008},
editor = {Camurri, Antonio and Volpe, Gualtiero and Serafin, Stefania},
address = {Genoa, Italy},
keywords = {nime08},
pages = {67--70},
}
