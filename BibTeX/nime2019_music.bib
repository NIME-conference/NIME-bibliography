@inproceedings{nime19-music-Rust,
  author = {Anna R{\"u}st},
  title = {Bad Mother / Good Mother - an audiovisual performance},
  pages = {8--10},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Bad Mother / Good Mother is an audiovisual performance involving a projection, a modified electronic breast pump as a sound generator, and a sound- reactive LED pumping costume. The project has four songs that critically explore technologies directed specifically at women like breast pumps and fertility extending treatments such as egg-freezing (social freezing). Depending on the song, the breast pump is either a solo instrument or part of an arrangement. The idea is to use workplace lactation as a departure point to uncover a web of societal politics and pre-conceived perceptions (pun intended) of ideal and non-ideal motherhood.}
}

@inproceedings{nime19-music-DAlessandro,
  author = {Christophe D’Alessandro and Xiao Xiao and Grégoire Locqueville and Boris Doval},
  title = {Borrowed Voices},
  pages = {11--14},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Borrowed voices is a performance featuring performative voice synthesis, with two types of instruments: C-Voks and T-Voks. The voices are played a cappella in a double choir of natural and synthetic voices. Performative singing synthesis is a new paradigm in the already long history of artificial voices. The singing voice is played like an instrument, allowing singing with the borrowed voice of another. The relationship of embodiment between the singer’s gestures and the vocal sound produced is broken. A voice is singing, with realism, expressivity and musicality, but it is not the musician’s own voice, and a vocal apparatus does not control it. The project focuses on control gestures: the music explores vocal sounds produced by the vocal apparatus (the basic sound material), and “played” by the natural voice, by free-hand Theremin-controlled gestures, and by writing gestures on a graphic tablet. The same (types of) sounds but different gestures give different musical “instruments” and expressive possibilities. Another interesting aspect is the distance between synthetic voices and the player, the voice being at the same time embodied (by the player gestures playing the instrument with her/his body) and externalized (because the instrument is not her/his own voice): two different voices sung/played by the same person.}
}

@inproceedings{nime19-music-Dooley,
  author = {James Dooley},
  title = {colligation},
  pages = {15-16},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music003.pdf},
  abstract = {colligation (to bring or tie together) is a physical performance work for one performer that explores the idea of sculpting sound through gesture. Treating sound as if it were a tangible object capable of being fashioned into new sonic forms, "pieces" of sound are captured, shaped and sculpted by the performer's hand and arm gestures, appearing pliable as they are thrown around and transformed into new sonic material. colligation uses two Thalmic Labs Myo armbands, one placed on the left arm and the other on the right arm. The Myo Mapper [1] software is used to transmit scaled data via OSC from the armbands to Pure Data. Positional (yaw, pitch and roll) and electromyographic data (EMG) from the devices are mapped to parameters controlling a hybrid synth created in Pure Data. The synth utilises a combination of Phase Aligned Formant synthesis [2] and Frequency Modulation synthesis [3] to allow a range of complex audio spectra to be explored. Pitch, yaw and roll data from the left Myo are respectively mapped to the PAF synth’s carrier frequency (ranging from 8.175-12543.9Hz), bandwidth and relative centre frequency. Pitch, yaw and roll data from the right Myo are respectively mapped to FM modulation frequency (relative to and ranging from 0.01-10 times the PAF carrier frequency), modulation depth (relative to and ranging from 0.01-10 times the PAF carrier frequency), and modulation wave shape (crossfading between sine, triangle, square, rising sawtooth and impulse). Data from the left and right Myo's EMG sensors are mapped respectively to amplitude control of the left and right audio channels, giving the performer control over the level and panning of the audio within the stereo field. By employing both positional and bio data, an embodied relationship between action and response is created; the gesture and the resulting sonic transformation become inextricably entwined.}
}

@inproceedings{nime19-music-Ahn,
  author = {Sabina Hyoju Ahn},
  title = {DIY Bionoise},
  pages = {17--20},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music004.pdf},
  abstract = {DIY Bionoise (2018) is an instrument in which the performer can generate sound and noise, deriving from their own body. It contains a circuit that can measure the bioelectricity from living beings to control the instrument by tactile sense. This instrument has two functions – a modular synthesizer with an eight-step sequencer and a bionoise control mode.}
}

@inproceedings{nime19-music-Tom,
  author = {Ajin Tom},
  title = {FlexSynth – Blending Multi-Dimensional Sonic Scenes},
  pages = {21--24},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music005.pdf},
  abstract = {FlexSynth is an interpretation of The Sponge, a DMI embedded with sensors to detect squeeze, flexion and torsion along with buttons to form an interface using which musical sounds are generated and the sound is sculpted. The key idea of the sponge is to harness the properties of a retractable, flexible object that gives the performer wide range of multi- parametric controls with high resolution in a maximized gesture space, considering its high manoeuvrability.}
}

@inproceedings{nime19-music-Tragtenberg,
  author = {João Tragtenberg, Filipe Calegario},
  title = {Gira},
  pages = {25--28},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music006.pdf},
  abstract = {Gira is a music and dance performance with Giromin, a wearable wireless digital instrument. With this Digital Dance and Music Instrument a gesture is transformed into sound by motion sensors and an analog synthesizer. This transmutation of languages allows dance to generate music, which stimulates a new dance in an infinite feedback loop.}
}

@inproceedings{nime19-music-Cadiz,
  author = {Rodrigo F. Cádiz},
  title = {iCons},
  pages = {29--31},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music007.pdf},
  abstract = {iCons is an interactive multi-channel music piece for live computer and a gesture sensor system designed by the composer especially for this piece, called AirTouch. Such system allows a much more musical approach to controlling sounds than the computer keyboard or mouse. Using only movements of the hands in the air it is possible to control most aspects of the music, such as sound shapes in time, loops, space positioning, or create very rich spectral densities.}
}

@inproceedings{nime19-music-Galvao,
  author = {Martim Galvão},
  title = {MusiCursor},
  pages = {32--34},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music008.pdf},
  abstract = {MusiCursor is an interactive multimedia performance/interface that reimagines consumer-facing technologies as sites for creative expression. The piece draws inspiration from established UI/UX design paradigms and the role of the user in relation to these technologies. The performer assumes the role of a user installing a musically-driven navigation interface on their computer. After an installation prompt, they are guided through a series of demos, in which a software assistant instructs the performer to accomplish several tasks. Through their playing, the performer controls the cursor’s navigation and clicking behavior. In lieu of a traditional score, the performer relies on text instructions and visual indicators from a software assistant. The software tracks the progress of the user throughout the piece and moves onto the next section only once a task has been completed. Each of the main tasks takes place on the web, where the user navigates across YouTube, Wikipedia, and Google Maps.}
}

@inproceedings{nime19-music-Cullen,
  author = {Barry Cullen and Miguel Ortiz and Paul Stapleton},
  title = {Pandemonium Trio perform Drone and Drama v2},
  pages = {35--38},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music009.pdf},
  abstract = {Pandemonium Trio is Barry Cullen, Miguel Ortiz and Paul Stapleton. Our performance research trio has been set up to explore multiple instantiations of custom-made electronic instruments through improvisation. We are particularly interested in exploiting irregularities in the qualities of circuit components (e.g. imprecise tolerances/values), and how this allows for the development of stylistic differences across multiple instrument-performer configurations. We are also interested in how skill, style and performance techniques are developed in different ways on similar devices over extended periods of time, and how our existing musical practices are reconfigured through such collaborative exchanges.}
}

@inproceedings{nime19-music-DallAra-Majek,
  author = {Ana Dall’Ara-Majek and Takuto Fukuda},
  title = {Pythagorean Domino},
  pages = {39--42},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music010.pdf},
  abstract = {Pythagorean Domino is an improvisatory composition composed in 2019 for an augmented Theremin and a gyro-based gestural controller. This work aims to integrate music concrete techniques and an algorithmic compositional approach in the context of composition for gestural controllers. While music concrete compositional practice brings out the concept of “composite object”—a sound object made up of several distinct and successive elements [1]—in the piece, our algorithmic compositional approach delivers an interpolation technique which entails gradual transformations of the composite objects over time. Our challenge is to perform a chain of short fragmental elements in tandem in the way to form a single musical unit, while the algorithms for transformation are autonomously changing synthetic and control parameter settings. This approach derives closely interconnected triangular interactions between two performers and a computer.}
}

@inproceedings{nime19-music-Nie,
  author = {Yiyao Nie},
  title = {River},
  pages = {43--46},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music011.pdf},
  abstract = {“No one can step into the same river twice.” This instrument, named as River, contains rules and randomness. What exactly is music and how does it connect to and shape our form? Traditional musical instruments always have fixed physical forms that require performers to adjust to them. How about making a musical instrument that is more fluid and more expressive via deforming according to performers’ movements? This was the question I attempted to explore when I started making this project. For this project, I combine the movement of dancing with music to present a fluid and dynamic shape of musical instrument. The fabric of this instrument can be separated as an extension to wash. It’s portable, wireless, chargeable, stable and beautiful. This musical instrument generates sound by detecting different movements of the performer. It has four different modes selected by toggling the switches on the instrument interface. Each mode has different movement detection methods, generating various sound and music. Moreover, it can be played as a transmitting Tambourine. As for the music in my performance, it’s all played by myself lively, consisting of different sound triggered and changed by performers’ gestures and melody composed myself. Like the name of this instrument River, the four toggles and their detection methods and their corresponding generated sounds are intentionally designed. From simple node, beat, loop, drum, to various node, melody, music, the detection methods and their triggered sounds are becoming more and more complex and various, developing like a journey of a river.}
}

@inproceedings{nime19-music-Park,
  author = {Jiyun Park},
  title = {Self-Built Instrument (sound performance)},
  pages = {47--49},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music012.pdf},
  abstract = {Self-Built Instrument project is focused on sound performance with an experi- mental instrument which is composed of strings and metallic sound box, pro- ducing overtones, harmonics and feed- back. It is capable to play with different sound colours : Resonances by cooper, bowing on strings, overtones and feed- back. All of factors triggers each other’s sound. It is not a point to play a specific tone or to make a musical harmony, because the instrument is not able to per- fectly control. Playing this Instrument is a challenge to your capacity, such as gestures and sonic phenomenon following sense and space. The artist composed a piece and use few repertoire partly, however, mostly it is interesting to find what kind of sound comes to nest in mesh. The Artist tried to get over typical aesthetics of classical music, such as using precise pitches, melodies, and read scores. Instead of that, her approach towards to discover unusual sound elements which are considered as mistake in tradi- tional way. And play with them, for instance, strings without tuning, hitting a stuffs, unorganized pitch, also so-called clicker which happens unskilled.}
}

@inproceedings{nime19-music-Martins,
  author = {André L. Martins and Paulo Assis Barbosa},
  title = {Tanto Mar},
  pages = {50--51},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music013.pdf},
  abstract = {"Tanto Mar" seeks to recreate the properties present in history between Portugal and Brazil, embracing the idea of an aqueous sound that dances and moves as much by cadence as by voluminous waves. The Atlantic Ocean, which separates and unites the two countries, serves as an inspiration for this quadraphonic performance, involving musical instruments and live electronics, where the sounds move through the four speakers. Each speaker symbolizes the paths that the sea travels uninterruptedly, in a unique dance of latitudes and longitudes. The intersection of sounds occurs through processes of reverberations, spatializations, echoes, modulations and grains that slowly form the sound material, composing, decomposing and manipulating the sound waves. Sound characters such as wind, oars, storms, calm, among others, are metaphorically evidenced through the sound material, creating a kind of rhythmic movement of a caravel at sea. The sounds of "Tanto Mar" move between entropy and chaos, between stillness and tsunami, between starboard and port, culminating in a textural dance where the objective is to take the listener away from electronic processing, and propose a dive in an intensified, attentive, deep and involving listening. New musical possibilities can happen through the experimentation of new routes, unusual routes and horizons not yet covered. The sea and its imprecise distances represent permanent challenges. "Tanto Mar" seeks to revive the feeling of the Portuguese poet Fernando Pessoa, when he wrote: "to dream even if it is impossible".}
}

@inproceedings{nime19-music-Carrascoza,
  author = {Cassia Carrascoza and Felipe Merker Castellani},
  title = {Tempo Transversal – Flauta Expandida},
  pages = {52--55},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music014.pdf},
  abstract = {“Tempo Transversal – Flauta Expandida” aims to establish a computer- controlled catalyzer, which simultaneously combines and extends the flutist body actions, electronic sounds and the performative physical space. Some flute performance fragments, captured in real time by video cameras, besides pre-recorded images, built the visual projection. The flute player develops two pieces of experimental music for flute and electronic. All these heterogeneous elements are interrelated with each other in a network mediated by the computer. The result is a continuously unfolded interactive performance, which intends to manipulate settings of space-time perception. Brazilian contemporary repertoire for amplified bass flute and electronic sounds establishes the proposal.}
}

@inproceedings{nime19-music-Hamilton,
  author = {Rob Hamilton},
  title = {Trois Machins de la Grâce Aimante (Coretet no. 1)},
  pages = {56--59},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music015.pdf},
  abstract = {Trois Machins de la Grâce Aimante is a composition intended to explore Twenty-First century technological and musical paradigms. At its heart Trois Machins is a string quartet fundamentally descended from a tradition that spans back to the 18th century. As such, the work primarily explores timbral material based around the sound of a bowed string, in this case realized using a set of physically modeled bowed strings controlled by Coretet, a virtual reality string instrument and networked performance environment. The composition - for four performers, preferably from an existing string quartet ensemble - takes the form of three distinct movements, each exploring different capabilities of the instrument itself and requiring different forms of communication and collaboration between the four performers.}
}

@inproceedings{nime19-music-Stapleton,
  author = {Paul Stapleton},
  title = {uncertain rhythms},
  pages = {60--62},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music016.pdf},
  abstract = {This work is a continuation of my research into developing new performance ecosystems for improvisation. For this project I developed a new volatile assemblage, aka VOLA. My self-designed musical instruments are shaped by my history as a performer working in acoustic, mechanical, electronic and digital musics, blending and exploring the boundaries and breaking points of these different domains. My instruments support many of my existing techniques originally developed on more conventional instruments, while also affording the development of extended and novel techniques and performance strategies. In much of my work I am particularly focused on the exploration of musical timbre and texture; however, for this project my attention is also directed towards time, flow, pulse, duration, friction, disruption – in short, qualitative rhythms and defamiliarisation.}
}

@inproceedings{nime19-music-Erdem,
  author = {Çağri Erdem and Katja Henriksen Schia and Alexander Refsum Jensenius},
  title = {Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance},
  pages = {63--65},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music017.pdf},
  abstract = {What if a musician could step outside the familiar instrumental paradigm and adopt a new embodied language for moving through sound with a dancer in true partnership? And what if a dancer’s body could coalesce with a musician’s skills and intuitively render movements into instrumental actions for active sound- making? Vrengt is a multi-user instrument, specifically developed for music-dance performance, with a particular focus on exploring the boundaries between standstill vs motion, and silence vs sound. We sought for creating a work for one, hybrid corporeality, in which a dancer and a musician would co-creatively and co- dependently interact with their bodies and a machine. The challenge, then, was how could two performers with distinct embodied skills unite in a continuous entanglement of intentions, senses and experiences to control the same sonic and musical parameters? This was conceptually different than they had done before in the context of interactive dance performances.}
}

@inproceedings{nime19-music-Barbosa,
  author = {Paulo Assis Barbosa and Miguel Antar},
  title = {We Bass: inter(actions) on a hybrid instrument},
  pages = {66--67},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music018.pdf},
  abstract = {The key for a collective process of free improvisation is the interaction, dependence and surrender of its parts, so the resulting sound flux is more than the sum of each individual layer. The We Bass performance is an exploration of the symbiosis of two performers playing the same instrument: Their actions have direct consequence on the resulting sound, challenging the other player with instability and interference. From the experiments of the English scientist Thomas Young (1773-1829) on the phenomena of diffraction and interference of light waves, we observe that interferences generated by overlapping light waves can have a character of annihilation, when they are out of phase (destructive interference), or a reinforcing character when in phase (constructive interference). From this reflection we try to deepen the discussion about the interferences of the performers inputs involved in a free improvisation session. We seek a model of connection between the performers that promotes processes of creation in the free improvisation, exploring the dialectics between reinforcement actions (processes of interaction that reinforces a certain sound moment) and movement actions (that destabilizes and transforms the flow). We Bass is a duo performance exploring the interactions between the musicians playing one hybrid machine: an electric upright bass guitar with live electronics processing. The instrument consists of an electric upright bass with movement sensors and a live processing machine with a controller that interacts with the sensors, changing some processing parameters and some controller mapping settings, creating an instable ground for the musicians.}
}

@inproceedings{nime19-music-introduction,
  author = {Federico Visi and Rodrigo Schramm},
  title = {Introduction},
  pages = {4},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music00I.pdf},
}

@inproceedings{nime19-music-program,
  title = {NIME 2019 Concert Program},
  pages = {5},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music0II.pdf},
}

@inproceedings{nime19-music-PC-members,
  title = {NIME 2019 Program Committee Members},
  pages = {6},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_musicIII.pdf},
}
