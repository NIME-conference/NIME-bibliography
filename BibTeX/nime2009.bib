@inproceedings{Baalman2009,
author = {Baalman, Marije A.},
url = {http://www.nime.org/proceedings/2009/nime2009_329.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Code LiveCode Live, or livecode Embodied},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {329--329},
}
@inproceedings{Baalman2009a,
author = {Baalman, Marije A. and Smoak, Harry C. and Salter, Christopher L. and Malloch, Joseph and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2009/nime2009_131.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sharing Data in Collaborative, Interactive Performances : the SenseWorld DataNetwork},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Data exchange, collaborative performance, in- teractive performance, interactive art works, sensor data, Open- SoundControl, SuperCollider, Max/MSP Introduction and Background The SenseWorld Data Network addresses one of the major challenges in the research/creation of interactive live per- formance work the sharing and manipulation of raw and/or conditioned sensor data among different media systems (real time audio and video, lighting, mechatronics, show control, etc). While the },
pages = {131--134},
}
@inproceedings{Barri2009,
author = {Barri, Tarik},
url = {http://www.nime.org/proceedings/2009/nime2009_264.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Versum : Audiovisual Composing in 3d},
year = {2009},
abstract = {This paper introduces the new audiovisual sequencing system "Versum" that allows users to compose in three dimensions. In the present paper the conceptual soil from which this system has sprung is discussed first. Secondly, the basic concepts with which Versum operates are explained, providing a general idea of what is meant by sequencing in three dimensions and explaining what compositions made in Versum can look and sound like. Thirdly, the practical ways in which a composer can use Versum to make his own audiovisual compositions are presented by means of a more detailed description of the different graphical user interface elements. Fourthly, a short description is given of the modular structure of the software underlying Versum. Finally, several foresights regarding the directions in which Versum will continue to develop in the near future are presented. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {audiovisual, sequencing, collaboration.  },
pages = {264--265},
}
@inproceedings{Barri2009a,
author = {Barri, Tarik},
url = {http://www.nime.org/proceedings/2009/nime2009_325.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Versum – Fluor},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {325--325},
}
@inproceedings{Berdahl2009,
author = {Berdahl, Edgar and Niemeyer, G\"{u}nter and Smith, Julius O.},
url = {http://www.nime.org/proceedings/2009/nime2009_262.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {HSP : A Simple and Effective Open-Source Platform for Implementing Haptic Musical Instruments},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {but,com-,currently chai 3d is,figure 1,fully supported only on,grip,haptic musical instrument,haptics,hsp,musician holding the falcon,nime09,novint,pd,physical modeling,pure data,puter music,windows},
pages = {262--263},
}
@inproceedings{Berdahl2009a,
author = {Berdahl, Edgar and Niemeyer, G\"{u}nter and Smith, Julius O.},
url = {http://www.nime.org/proceedings/2009/nime2009_183.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Using Haptic Devices to Interface Directly with Digital Waveguide-Based Musical Instruments},
year = {2009},
abstract = {A haptic musical instrument is an electronic musical instrument that provides the musician not only with audio feedback but also with force feedback. By programming feedback controllers to emulate the laws of physics, many haptic musical instruments have been previously designed thatmimic real acoustic musical instruments. The controllerprograms have been implemented using finite difference and(approximate) hybrid digital waveguide models. We presenta novel method for constructing haptic musical instrumentsin which a haptic device is directly interfaced with a conventional digital waveguide model by way of a junction element, improving the quality of the musician's interactionwith the virtual instrument. We introduce both the explicitdigital waveguide control junction and the implicit digitalwaveguide control junction.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {haptic musical instrument, digital waveguide, control junction, explicit, implicit, teleoperation },
pages = {183--186},
}
@inproceedings{Berdahl2009b,
author = {Berdahl, Edgar and Niemeyer, G\"{u}nter and Smith, Julius O.},
url = {http://www.nime.org/proceedings/2009/nime2009_177.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Using Haptics to Assist Performers in Making Gestures to a Musical Instrument},
year = {2009},
abstract = {Haptic technology, providing force cues and creating a programmable physical instrument interface, can assist musicians in making gestures. The finite reaction time of thehuman motor control system implies that the execution of abrief musical gesture does not rely on immediate feedbackfrom the senses, rather it is preprogrammed to some degree.Consequently, we suggest designing relatively simple anddeterministic interfaces for providing haptic assistance.In this paper, we consider the specific problem of assisting a musician in selecting pitches from a continuous range.We build on a prior study by O'Modhrain of the accuracyof pitches selected by musicians on a Theremin-like hapticinterface. To improve the assistance, we augment the interface with programmed detents so that the musician can feelthe locations of equal tempered pitches. Nevertheless, themusician can still perform arbitrary pitch inflections such asglissandi, falls, and scoops. We investigate various formsof haptic detents, including fixed detent levels and forcesensitive detent levels. Preliminary results from a subjecttest confirm improved accuracy in pitch selection broughtabout by detents.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Haptic, detent, pitch selection, human motor system, feedback control, response time, gravity well },
pages = {177--182},
}
@inproceedings{Bianchi2009,
author = {Bianchi, Andrea and Yeo, Woon Seung},
url = {http://www.nime.org/proceedings/2009/nime2009_316.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Drummer : a Collaborative Musical Interface with Mobility},
year = {2009},
abstract = {It has been shown that collaborative musical interfaces encourage novice users to explore the sound space and promote their participation as music performers. Nevertheless, such interfaces are generally physically situated and can limit the possibility of movements on the stage, a critical factor in live music performance. In this paper we introduce the Drummer, a networked digital musical interface that allows multiple performers to design and play drum kits simultaneously while, at the same time, keeping their ability to freely move on the stage. The system consists of multiple Nintendo DS clients with an intuitive, user-configurable interface and a server computer which plays drum sounds. The Drummer Machine, a small piece of hardware to augment the performance of the Drummer, is also introduced. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {2,collaborative interface,expression,figure 1,game control,motivations and related work,multiplayer,musical,musical control,nime09,nintendo ds,on a nintendo ds,the drummer client running},
pages = {316--319},
}
@inproceedings{Bouillot2009,
author = {Bouillot, Nicolas and Cooperstock, Jeremy R.},
url = {http://www.nime.org/proceedings/2009/nime2009_135.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Challenges and Performance of High-Fidelity Audio Streaming for Interactive Performances},
year = {2009},
abstract = {Low-latency streaming of high-quality audio has the potential to dramatically transform the world of interactive musical applications. We provide methods for accurately measuring the end-to-end latency and audio quality of a delivered audio stream and apply these methods to an empirical evaluation of several streaming engines. In anticipationof future demands for emerging applications involving audio interaction, we also review key features of streamingengines and discuss potential challenges that remain to beovercome.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Networked Musical Performance, high-fidelity audio streaming, glitch detection, latency measurement },
pages = {135--140},
}
@inproceedings{Bukvic2009,
author = {Bukvic, Ivika and Standley, Eric},
url = {http://www.nime.org/proceedings/2009/nime2009_337.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Elemental \& Cyrene Reefs},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {337--337},
}
@inproceedings{Bullock2009,
author = {Bullock, Jamie and Coccioli, Lamberto},
url = {http://www.nime.org/proceedings/2009/nime2009_266.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards a Humane Graphical User Interface for Live Electronic Music},
year = {2009},
abstract = {In this paper we describe findings related to user interfacerequirements for live electronic music arising from researchconducted as part of the first three-year phase of the EUfunded Integra project. A number of graphical user interface(GUI) prototypes developed during the Integra project initial phase are described and conclusions drawn about theirdesign and implementation.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Integra, User Interface, Usability, Design, Live Electronics, Music Technology },
pages = {266--267},
}
@inproceedings{Bottcher2009,
author = {B\"{o}ttcher, Niels and Dimitrov, Smilen},
url = {http://www.nime.org/proceedings/2009/nime2009_151.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Early Prototype of the Augmented PsychoPhone},
year = {2009},
abstract = {In this poster we present the early prototype of the augmented Psychophone - a saxophone with various applied sensors, allowing the saxophone player to attach effects like pitch shifting, wah-wah and ring modulation to the saxophone, simply by moving the saxophone as one would do when really being enthusiastic and involved in the performance. The possibility of scratching on the previously recorded sound is also possible directly on the saxophone.  },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Augmented saxophone, Physical computing, hyper instruments, mapping. },
pages = {151--152},
}
@inproceedings{Collicutt2009,
author = {Collicutt, Mike and Casciato, Carmine and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2009/nime2009_001.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {From Real to Virtual : A Comparison of Input Devices for Percussion Tasks},
year = {2009},
abstract = {This paper presents an evaluation and comparison of four input devices for percussion tasks: a standard tom drum, Roland V-Drum, and two established examples of gestural controllers: the Buchla Lightning II, and the Radio Baton. The primary goal of this study was to determine how players' actions changed when moving from an acoustic instrument like the tom drum, to a gestural controller like the Buchla Lightning, which bears little resemblance to an acoustic percussion instrument. Motion capture data was analyzed by comparing a subject's hand height variability and timing accuracy across the four instruments as they performed simple musical tasks. Results suggest that certain gestures such as hand height amplitude can be adapted to these gestural controllers with little change and that in general subjects' timing variability is significantly affected when playing on the Lightning and Radio Baton when compared to the more familiar tom drum and VDrum. Possible explanations and other observations are also presented. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Evaluation of Input Devices, Motion Capture, Buchla Lightning II, Radio Baton.  },
pages = {1--6},
}
@inproceedings{Cook2009,
author = {Cook, Perry R.},
url = {http://www.nime.org/proceedings/2009/nime2009_218.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Re-Designing Principles for Computer Music Controllers : a Case Study of SqueezeVox Maggie},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {1,batteries,composed instruments,hci,i will restate the,laptop orchestras,nime09,original 13 principles for,sensas,the original principles,to begin,voice synthesis,wireless},
pages = {218--221},
}
@inproceedings{Crawford2009,
author = {Crawford, Langdon and Fastenow, William D.},
url = {http://www.nime.org/proceedings/2009/nime2009_149.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Midi-AirGuitar , A serious Musical Controller with a Funny Name Music Technology Program},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {149--150},
}
@inproceedings{dAlessandro2009,
author = {d'Alessandro, Nicolas and Dutoit, Thierry},
url = {http://www.nime.org/proceedings/2009/nime2009_173.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Advanced Techniques for Vertical Tablet Playing A Overview of Two Years of Practicing the HandSketch 1.x},
year = {2009},
abstract = {In this paper we present new issues and challenges relatedto the vertical tablet playing. The approach is based on apreviously presented instrument, the HANDSKETCH. Thisinstrument has now been played regularly for more than twoyears by several performers. Therefore this is an opportunityto propose a better understanding of the performing strategy.We present the behavior of the whole body as an underlyingaspect in the manipulation of the instrument.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {graphic tablet, playing position, techniques },
pages = {173--174},
}
@inproceedings{DeJong2009,
author = {de Jong, Staas},
url = {http://www.nime.org/proceedings/2009/nime2009_163.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Developing the Cyclotactor},
year = {2009},
abstract = {This paper presents developments in the technology underlying the cyclotactor, a finger-based tactile I/O device for musical interaction. These include significant improvements both in the basic characteristics of tactile interaction and in the related (vibro)tactile sample rates, latencies, and timing precision. After presenting the new prototype's tactile output force landscape, some of the new possibilities for interaction are discussed, especially those for musical interaction with zero audio/tactile latency.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Musical controller, tactile interface. },
pages = {163--164},
}
@inproceedings{Dolphin2009,
author = {Dolphin, Andy},
url = {http://www.nime.org/proceedings/2009/nime2009_056.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SpiralSet : A Sound Toy Utilizing Game Engine Technologies},
year = {2009},
abstract = {SpiralSet is a sound toy incorporating game enginesoftware used in conjunction with a spectral synthesissound engine constructed in Max/MSP/Jitter. SpiralSetwas presented as an interactive installation piece at theSonic Arts Expo 2008, in Brighton, UK. A custom madesensor-based interface is used for control of the system.The user interactions are designed to be quickly accessiblein an installation context, yet allowing the potential forsonic depth and variation.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Sound Toys, Game Engines, Animated Interfaces, Spectral Synthesis, Open Work, Max/MSP. },
pages = {56--57},
}
@inproceedings{Dolphin2009a,
author = {Dolphin, Andy},
url = {http://www.nime.org/proceedings/2009/nime2009_159.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {MagNular : Symbolic Control of an External Sound Engine Using an Animated Interface},
year = {2009},
abstract = {This paper reports on work in progress on the creativeproject MagNular, part of a wider practical study of thepotential collaborative compositional applications of gameengine technologies. MagNular is a sound toy utilizingcomputer game and physics engine technologies to createan animated interface used in conjunction with an externalsound engine developed within Max/MSP. The playercontrols virtual magnets that attract or repel numerousparticle objects, moving them freely around the virtualspace. Particle object collision data is mapped to controlsound onsets and synthesis/DSP (Digital SignalProcessing) parameters. The user "composes" bycontrolling and influencing the simulated physicalbehaviors of the particle objects within the animatedinterface.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Sound Toys, Open Work, Game Engines, Animated Interfaces, Max/MSP. },
pages = {159--160},
}
@inproceedings{Dubois2009,
author = {Dubois, R. Luke and Flanigan, Lesley},
url = {http://www.nime.org/proceedings/2009/nime2009_336.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Bioluminescence},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {336--336},
}
@inproceedings{Essl2009,
author = {Essl, Georg},
url = {http://www.nime.org/proceedings/2009/nime2009_270.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SpeedDial : Rapid and On-The-Fly Mapping of Mobile Phone Instruments},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {mobile phone instruments,nime,nime09,on-the-fly},
pages = {270--273},
}
@inproceedings{Feehan2009,
author = {Feehan, Noah},
url = {http://www.nime.org/proceedings/2009/nime2009_161.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Audio Orienteering – Navigating an Invisible Terrain},
year = {2009},
abstract = {AUDIO ORIENTEERING is a collaborative performance environment in which physical tokens are used to navigate an invisible sonic landscape. In this paper, I describe the hardware and software used to implement a prototype audio terrain with multiple interaction modes and sonic behaviors mapped onto three-dimensional space. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {wii, 3-d positioning, audio terrain,  collaborative performance.  },
pages = {161--162},
}
@inproceedings{Fels2009,
author = {Fels, Sidney S. and Pritchard, Bob and Lenters, Allison},
url = {http://www.nime.org/proceedings/2009/nime2009_274.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {ForTouch : A Wearable Digital Ventriloquized Actor},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {274--275},
}
@inproceedings{Ferguson2009,
author = {Ferguson, Sam and Beilharz, Kirsty},
url = {http://www.nime.org/proceedings/2009/nime2009_035.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Interface for Live Interactive Sonification},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Sonification, Interactive Sonification, Auditory Display.  },
pages = {35--36},
}
@inproceedings{Fiebrink2009,
author = {Fiebrink, Rebecca and Trueman, Dan and Cook, Perry R.},
url = {http://www.nime.org/proceedings/2009/nime2009_280.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Meta-Instrument for Interactive, On-the-Fly Machine Learning},
year = {2009},
abstract = {Supervised learning methods have long been used to allow musical interface designers to generate new mappings by example. We propose a method for harnessing machine learning algorithms within a radically interactive paradigm, in which the designer may repeatedly generate examples, train a learner, evaluate outcomes, and modify parameters in real-time within a single software environment. We describe our meta-instrument, the Wekinator, which allows a user to engage in on-the-fly learning using arbitrary control modalities and sound synthesis environments. We provide details regarding the system implementation and discuss our experiences using the Wekinator for experimentation and performance. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Machine learning, mapping, tools.  },
pages = {280--285},
}
@inproceedings{Freed2009,
author = {Freed, Adrian},
url = {http://www.nime.org/proceedings/2009/nime2009_230.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Novel and Forgotten Current-steering Techniques for Resistive Multitouch, Duotouch, and Polytouch Position Sensing with Pressure},
year = {2009},
abstract = {A compendium of foundational circuits for interfacing resistive pressure and position sensors is presented with example applications for music controllers and tangible interfaces. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Piezoresistive Touch Sensor Pressure Sensing Current Steering Multitouch.  },
pages = {230--235},
}
@inproceedings{Freed2009a,
author = {Freed, Adrian and Schmeder, Andrew},
url = {http://www.nime.org/proceedings/2009/nime2009_116.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Features and Future of Open Sound Control version 1.1 for NIME},
year = {2009},
abstract = {The history and future of Open Sound Control (OSC) is discussed and the next iteration of the OSC specification is introduced with discussion of new features to support NIME community activities. The roadmap to a major revision of OSC is developed. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Open Sound Control, Time Tag, OSC, Reservation Protocols.  },
pages = {116--120},
}
@inproceedings{Fyans2009,
author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
url = {http://www.nime.org/proceedings/2009/nime2009_171.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Where Did It All Go Wrong ? A Model of Error From the Spectator’s Perspective},
year = {2009},
abstract = {The development of new interfaces for musical expressionhas created a need to study how spectators comprehend newperformance technologies and practices. As part of a largerproject examining how interactions with technology can becommunicated with the spectator, we relate our model ofspectator understanding of error to the NIME discourse surrounding transparency, mapping, skill and success.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {performance, skill, transparency, design, HCI },
pages = {171--172},
}
@inproceedings{Gallin2009,
author = {Gallin, Emmanuelle and Sirguy, Marc},
url = {http://www.nime.org/proceedings/2009/nime2009_199.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sensor Technology and the Remaking of Instruments from the Past},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Controller, Sensor, MIDI, USB, Computer Music, ribbon controllers, ribbon cello.  },
pages = {199--202},
}
@inproceedings{Gao2009,
author = {Gao, Mingfei and Hanson, Craig},
url = {http://www.nime.org/proceedings/2009/nime2009_058.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {LUMI : Live Performance Paradigms Utilizing Software Integrated Touch Screen and Pressure Sensitive Button Matrix},
year = {2009},
abstract = {This paper explores a rapidly developed, new musical interface involving a touch-screen, 32 pressure sensitive button pads, infrared sensor, 8 knobs and cross-fader. We provide a versatile platform for computer-based music performance and production using a human computer interface that has strong visual and tactile feedback as well as robust software that exploits the strengths of each individual system component. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {live performance interface,lumi,nime09,pressure},
pages = {58--59},
}
@inproceedings{Gelineck2009,
author = {Gelineck, Steven and Serafin, Stefania},
url = {http://www.nime.org/proceedings/2009/nime2009_013.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Quantitative Evaluation of the Differences between Knobs and Sliders},
year = {2009},
abstract = {This paper presents a HCI inspired evaluation of simple physical interfaces used to control physical models. Specifically knobs and sliders are compared in a creative and exploratory framework, which simulates the natural environment in which an electronic musician would normally explore a new instrument. No significant difference was measured between using knobs and sliders for controlling parameters of a physical modeling electronic instrument. Thereported difference between the tested instruments were mostlydue to the sound synthesis models.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Evaluation, Interfaces, Sliders, Knobs, Physi- cal Modeling, Electronic Musicians, Exploration, Creativ- ity, Affordances. },
pages = {13--18},
}
@inproceedings{Gillian2009,
author = {Gillian, Nicholas and Knapp, Benjamin and O'Modhrain, Sile},
url = {http://www.nime.org/proceedings/2009/nime2009_060.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The SARC EyesWeb Catalog : A Pattern Recognition Toolbox for Musician-Computer Interaction},
year = {2009},
abstract = {This paper presents the SARC EyesWeb Catalog (SEC), agroup of blocks designed for real-time gesture recognitionthat have been developed for the open source program EyesWeb. We describe how the recognition of real-time bodymovements can be used for musician-computer-interaction.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {SARC EyesWeb Catalog, gesture recognition },
pages = {60--61},
}
@inproceedings{Gillian2009a,
author = {Gillian, Nicholas and O'Modhrain, Sile and Essl, Georg},
url = {http://www.nime.org/proceedings/2009/nime2009_308.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Scratch-Off : A Gesture Based Mobile Music Game with Tactile Feedback},
year = {2009},
abstract = {This paper presents "Scratch-Off", a new musical multiplayer DJ game that has been designed for a mobile phone. We describe how the game is used as a test platform for experimenting with various types of multimodal feedback. The game uses movement gestures made by the players to scratch a record and control crossfades between tracks, with the objective of the game to make the correct scratch at the correct time in relation to the music. Gestures are detected using the devices built-in tri-axis accelerometer and multi-touch screen display. The players receive visual, audio and various types of vibrotactile feedback to help them make the correct scratch on the beat of the music track. We also discuss the results of a pilot study using this interface. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Mobile devices, gesture, audio games.  },
pages = {308--311},
}
@inproceedings{Gong2009,
author = {Gong, Nan-Wei and Laibowitz, Mat and Paradiso, Joseph A.},
url = {http://www.nime.org/proceedings/2009/nime2009_074.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {MusicGrip : A Writing Instrument for Music Control},
year = {2009},
abstract = {In this project, we have developed a real-time writing instrument for music control. The controller, MusicGrip, can capture the subtle dynamics of the user's grip while writing or drawing and map this to musical control signals and sonic outputs. This paper discusses this conversion of the common motor motion of handwriting into an innovative form of music expression. The presented example instrument can be used to integrate the composing aspect of music with painting and writing, creating a new art form from the resultant aural and visual representation of the collaborative performing process. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Interactive music control, writing instrument, pen controller, MIDI, group performing activity.  },
pages = {74--77},
}
@inproceedings{Goto2009,
author = {Goto, Suguru},
url = {http://www.nime.org/proceedings/2009/nime2009_328.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {BodyJack},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {328--328},
}
@inproceedings{Goto2009a,
author = {Goto, Suguru and Powell, Rob},
url = {http://www.nime.org/proceedings/2009/nime2009_048.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {netBody - "Augmented Body and Virtual Body II" with the System, BodySuit, Powered Suit and Second Life - Its Introduction of an Application of the System},
year = {2009},
abstract = {This is intended to introduce the system, which combines BodySuit, especially Powered Suit, and Second Life, as well as its possibilities and its uses in a musical performance application. The system which we propose contains both a gesture controller and robots at the same time. In this system, the Data Suit, BodySuit controls the avatar in Second Life and Second Life controls the exoskeleton, Powered Suit in real time. These are related with each other in conjunction with Second Life in Internet. BodySuit doesn't contain a hand-held controller. A performer, for example a dancer, wears a suit. Gestures are transformed into electronic signals by sensors. Powered Suit is another suit that a dancer wears, but gestures are generated by motors. This is a sort of wearable robot. Second Life is software that is developed by Linden Lab. It allows creating a virtual world and a virtual human (avatar) in Internet. Working together with BodySuit, Powered Suit, and Second Life the idea behind the system is that a human body is augmented by electronic signals and is reflected in a virtual world in order to be able to perform interactively. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {artificial intelligence,gesture controller,humanoid robot,interaction,internet,nime09,robot},
pages = {48--49},
}
@inproceedings{GreshamLancaster2009,
author = {Gresham-Lancaster, Scot and Bull, Steve},
url = {http://www.nime.org/proceedings/2009/nime2009_338.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Cellphonia: 4'33"},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {338--338},
}
@inproceedings{Gurevich2009,
author = {Gurevich, Michael and Stapleton, Paul and Bennett, Peter},
url = {http://www.nime.org/proceedings/2009/nime2009_213.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Designing for Style in New Musical Interactions},
year = {2009},
abstract = {In this paper we discuss the concept of style, focusing in particular on methods of designing new instruments that facilitate the cultivation and recognition of style. We distinguishbetween style and structure of an interaction and discuss thesignificance of this formulation within the context of NIME.Two workshops that were conducted to explore style in interaction design are described, from which we identify elements of style that can inform and influence the design process. From these, we suggest steps toward designing forstyle in new musical interactions.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {expression, style, structure, skill, virtuosity },
pages = {213--217},
}
@inproceedings{Hadjakos2009,
author = {Hadjakos, Aristotelis and Aitenbichler, Erwin and M\"{u}hlh\"{a}user, Max},
url = {http://www.nime.org/proceedings/2009/nime2009_007.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Probabilistic Model of Pianists’ Arm Touch Movements},
year = {2009},
abstract = {Measurement of pianists' arm movement provides a signal,which is composed of controlled movements and noise. Thenoise is composed of uncontrolled movement generated bythe interaction of the arm with the piano action and measurement error. We propose a probabilistic model for armtouch movements, which allows to estimate the amount ofnoise in a joint. This estimation helps to interpret the movement signal, which is of interest for augmented piano andpiano pedagogy applications.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Piano, arm movement, gesture, classification, augmented instrument, inertial sensing. },
pages = {7--12},
}
@inproceedings{Havryliv2009,
author = {Havryliv, Mark and Naghdy, Fazel and Schiemer, Greg and Hurd, Timothy},
url = {http://www.nime.org/proceedings/2009/nime2009_187.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Haptic Carillon – Analysis \& Design of the Carillon Mechanism},
year = {2009},
abstract = {The carillon is one of the few instruments that elicit sophisticated haptic interaction from amateur and professional players alike. Like the piano keyboard, the velocity of a player's impact on each carillon key, or baton, affects the quality of the resultant tone; unlike the piano, each carillon baton returns a different forcefeedback. Force-feedback varies widely from one baton to the next across the entire range of the instrument and with further idiosyncratic variation from one instrument to another. This makes the carillon an ideal candidate for haptic simulation. The application of synthesized forcefeedback based on an analysis of forces operating in a typical carillon mechanism offers a blueprint for the design of an electronic practice clavier and with it the solution to a problem that has vexed carillonists for centuries, namely the inability to rehearse repertoire in private. This paper will focus on design and implementation of a haptic carillon clavier derived from an analysis of the Australian National Carillon in Canberra. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Haptics, force-feedback, mechanical analysis.  },
pages = {187--192},
}
@inproceedings{Henriques2009,
author = {Henriques, Tom\'{a}s},
url = {http://www.nime.org/proceedings/2009/nime2009_260.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Double Slide Controller},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {a,a double slide mechanism,computer music,consisting of a set,hardware and software design,making,musical instrument,nime09,of two,sensor technologies,sensors used in their,these are as follows},
pages = {260--261},
}
@inproceedings{Hindman2009,
author = {Hindman, David and Drummond, Evan},
url = {http://www.nime.org/proceedings/2009/nime2009_332.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Performance: Modal Kombat Plays PONG},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {332--332},
}
@inproceedings{Hockman2009,
author = {Hockman, Jason A. and Wanderley, Marcelo M. and Fujinaga, Ichiro},
url = {http://www.nime.org/proceedings/2009/nime2009_090.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Real-Time Phase Vocoder Manipulation by Runner’s Pace},
year = {2009},
abstract = {This paper presents a method for using a runner's pacefor real-time control of the time-scaling facility of a phasevocoder, resulting in the automated synchronization of anaudio track tempo to the generated control signal. The increase in usage of portable music players during exercisehas given rise to the development of new personal exerciseaids, most notably the Nike+iPod system, which relies onembedded sensor technologies to provide kinematic workout statistics. There are also systems that select songs basedon the measured step frequency of a runner. The proposedsystem also uses the pace of a runner, but this information isused to change the tempo of the music.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {NIME, synchronization, exercise, time-scaling. },
pages = {90--93},
}
@inproceedings{Hong2009,
author = {Hong, Min Eui},
url = {http://www.nime.org/proceedings/2009/nime2009_322.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Cosmic Strings II},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {322--322},
}
@inproceedings{Hsu2009,
author = {Hsu, William and Sosnick, Marc},
url = {http://www.nime.org/proceedings/2009/nime2009_025.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Evaluating Interactive Music Systems : An HCI Approach},
year = {2009},
abstract = {In this paper, we discuss a number of issues related to the design of evaluation tests for comparing interactive music systems for improvisation. Our testing procedure covers rehearsal and performance environments, and captures the experiences of a musician/participant as well as an audience member/observer. We attempt to isolate salient components of system behavior, and test whether the musician or audience are able to discern between systems with significantly different behavioral components. We report on our experiences with our testing methodology, in comparative studies of our London and ARHS improvisation systems [1]. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Interactive music systems, human computer interaction, evaluation tests.  },
pages = {25--28},
}
@inproceedings{Humphrey2009,
author = {Humphrey, Eric and Leider, Colby},
url = {http://www.nime.org/proceedings/2009/nime2009_031.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Navi Activity Monitor : Toward Using Kinematic Data to Humanize Computer Music},
year = {2009},
abstract = {Motivated by previous work aimed at developing mathematical models to describe expressive timing in music, and specifically the final ritardandi, using measured kinematic data, we further investigate the linkage of locomotion and timing in music. The natural running behavior of four subjects is measured with a wearable sensor prototype and analyzed to create normalized tempo curves. The resulting curves are then used to modulate the final ritard of MIDI scores, which are also performed by an expert musician. A Turing-inspired listening test is conducted to observe a human listener's ability to determine the nature of the performer. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Musical kinematics, expressive tempo,  machine music.  },
pages = {31--32},
}
@inproceedings{Hoofer2009,
author = {H\"{o}ofer, Andreas and Hadjakos, Aristotelis and M\"{u}hlh\"{a}user, Max},
url = {http://www.nime.org/proceedings/2009/nime2009_175.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Gyroscope-Based Conducting Gesture Recognition},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {175--176},
}
@inproceedings{Jessop2009,
author = {Jessop, Elena},
url = {http://www.nime.org/proceedings/2009/nime2009_256.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Vocal Augmentation and Manipulation Prosthesis (VAMP): A Conducting-Based Gestural Controller for Vocal Performance},
year = {2009},
abstract = {This paper describes The Vocal Augmentation and Manipulation Prosthesis (VAMP) a gesture-based wearable controller for live-time vocal performance. This controller allows a singer to capture and manipulate single notes that he or she sings, using a gestural vocabulary developed from that of choral conducting. By drawing from a familiar gestural vocabulary, this controller and the associated mappings can be more intuitive and expressive for both performer and audience. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {musical expressivity, vocal performance,  gestural control, conducting.  },
pages = {256--259},
}
@inproceedings{Johnston2009,
author = {Johnston, Andrew and Candy, Linda and Edmonds, Ernest},
url = {http://www.nime.org/proceedings/2009/nime2009_207.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Designing for Conversational Interaction},
year = {2009},
abstract = {In this paper we describe an interaction framework whichclassifies musicians' interactions with virtual musical instruments into three modes: instrumental, ornamental andconversational. We argue that conversational interactionsare the most difficult to design for, but also the most interesting. To illustrate our approach to designing for conversational interactions we describe the performance workPartial Reflections 3 for two clarinets and interactive software. This software uses simulated physical models to create a virtual sound sculpture which both responds to andproduces sounds and visuals.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Music, instruments, interaction. },
pages = {207--212},
}
@inproceedings{Jones2009,
author = {Jones, Daniel and Hodgson, Tim and Grant, Jane and Matthias, John and Outram, Nicholas and Ryan, Nick},
url = {http://www.nime.org/proceedings/2009/nime2009_297.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Fragmented Orchestra},
year = {2009},
abstract = {The Fragmented Orchestra is a distributed musical instrument which combines live audio streams from geographically disparate sites, and granulates each according to thespike timings of an artificial spiking neural network. Thispaper introduces the work, outlining its historical context,technical architecture, neuronal model and network infrastructure, making specific reference to modes of interactionwith the public.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {distributed,emergent,environmental,installation,neural network,nime09,sound,streaming audio},
pages = {297--302},
}
@inproceedings{Jones2009a,
author = {Jones, Randy and Driessen, Peter and Schloss, Andrew and Tzanetakis, George},
url = {http://www.nime.org/proceedings/2009/nime2009_236.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Force-Sensitive Surface for Intimate Control},
year = {2009},
abstract = {This paper presents a new force-sensitive surface designedfor playing music. A prototype system has been implemented using a passive capacitive sensor, a commodity multichannel audio interface, and decoding software running ona laptop computer. This setup has been a successful, lowcost route to a number of experiments in intimate musicalcontrol.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Multitouch, sensors, tactile, capacitive, percus- sion controllers. },
pages = {236--241},
}
@inproceedings{Kahrs2009,
author = {Kahrs, Mark and Skulina, David and Bilbao, Stefan and Campbell, Murray},
url = {http://www.nime.org/proceedings/2009/nime2009_106.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Electroacoustically Controlled Vibrating Plate},
year = {2009},
abstract = {Large vibrating plates are used as thunder sheets in orchestras. We have extended the use of flat plates by cementing aflat panel electroacoustic transducer on a large brass sheet.Because of the thickness of the panel, the output is subject tononlinear distortion. When combined with a real-time inputand signal processing algorithm, the active brass plate canbecome an effective musical instrument for performance ofnew music.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Electroacoustics, flat panel },
pages = {106--109},
}
@inproceedings{Kanda2009,
author = {Kanda, Ryo and Hashida, Mitsuyo and Katayose, Haruhiro},
url = {http://www.nime.org/proceedings/2009/nime2009_045.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mims : Interactive Multimedia Live Performance System},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Interaction, audience, performer, visualize, sen- sor, physical, gesture. },
pages = {45--47},
}
@inproceedings{Kapuscinski2009,
author = {Kapuscinski, Jaroslaw and Sanchez, Javier},
url = {http://www.nime.org/proceedings/2009/nime2009_222.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Interfacing Graphic and Musical Elements in Counterlines},
year = {2009},
abstract = {This paper reports on initial stages of research leading to the development of an intermedia performance Counterlines - a duet for Disklavier and Wacom Cintiq, in which both performers generate audiovisual gestures that relate to each other contrapuntally. The pianist generates graphic elements while playing music and the graphic performer generates piano notes by drawing lines. The paper focuses on interfacing sounds and images performed by the pianist. It provides rationale for the choice of materials of great simplicity and describes our approach to mapping. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {intermedia, Disklavier, piano, Wacom Cintiq, mapping, visual music  },
pages = {222--225},
}
@inproceedings{Keith2009,
author = {Keith, Sarah},
url = {http://www.nime.org/proceedings/2009/nime2009_054.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Controlling Live Generative Electronic Music with Deviate},
year = {2009},
abstract = {Deviate generates multiple streams of melodic and rhythmic output in real-time, according to user-specified control parameters. This performance system has been implemented using Max 5 [1] within the genre of popular contemporary electronic music, incorporating techno, IDM, and related forms. The aim of this project is not musical style synthesis, but to construct an environment in which a range of creative and musical goals may be achieved. A key aspect is control over generative processes, as well as consistent yet varied output. An approach is described which frees the user from determining note-level output while allowing control to be maintained over larger structural details, focusing specifically on the melodic aspect of this system. Audio examples are located online at http://www.cetenbaath.com/cb/about-deviate/. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {generative, performance, laptop, popular music  },
pages = {54--55},
}
@inproceedings{Kellum2009,
author = {Kellum, Greg and Crevoisier, Alain},
url = {http://www.nime.org/proceedings/2009/nime2009_242.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Flexible Mapping Editor for Multi-touch Musical Instruments},
year = {2009},
abstract = {This paper introduces a flexible mapping editor, which transforms multi-touch devices into musical instruments. The editor enables users to create interfaces by dragging and dropping components onto the interface and attaching actions to them, which will be executed when certain userdefined conditions obtain. The editor receives touch information via the non-proprietary communication protocol, TUIO [9], and can, therefore, be used together with a variety of different multi-touch input devices. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {NIME, multi-touch, multi-modal interface, sonic interaction design.  },
pages = {242--245},
}
@inproceedings{Kiefer2009,
author = {Kiefer, Chris and Collins, Nick and Fitzpatrick, Geraldine},
url = {http://www.nime.org/proceedings/2009/nime2009_246.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Phalanger : Controlling Music Software With Hand Movement Using A Computer Vision and Machine Learning Approach},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {246--249},
}
@inproceedings{Kirk2009,
author = {Kirk, Jonathon and Weisert, Lee},
url = {http://www.nime.org/proceedings/2009/nime2009_290.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Argus Project : Underwater Soundscape Composition with Laser- Controlled Modulation},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {290--292},
}
@inproceedings{Lai2009,
author = {Lai, Chi-Hsia},
url = {http://www.nime.org/proceedings/2009/nime2009_039.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Hands On Stage : A Sound and Image Performance Interface},
year = {2009},
abstract = {Hands On Stage, designed from a percussionist's perspective, is a new performance interface designed for audiovisual improvisation. It comprises a custom-built table interface and a performance system programmed in two environments, SuperCollider 3 and Isadora. This paper traces the interface's evolution over matters of relevant technology, concept, construction, system design, and its creative outcomes. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {audiovisual, interface design, performance.  },
pages = {39--40},
}
@inproceedings{Laurenzo2009,
author = {Laurenzo, Tomas and Rodr\'{\i}guez, Ernesto and Castro, Juan Fabrizio},
url = {http://www.nime.org/proceedings/2009/nime2009_268.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {YARMI : an Augmented Reality Musical Instrument},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Interactive music instruments, visual interfaces, visual feedback, tangible interfaces, augmented reality, collaborative music, networked musical instruments, real-time musical systems, musical sequencer.  },
pages = {268--269},
}
@inproceedings{Leeuw2009,
author = {Leeuw, Hans},
url = {http://www.nime.org/proceedings/2009/nime2009_193.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Electrumpet , a Hybrid Electro-Acoustic Instrument},
year = {2009},
abstract = {The Electrumpet is an enhancement of a normal trumpet with a variety of electronic sensors and buttons. It is a new hybrid instrument that facilitates simultaneous acoustic and electronic playing. The normal playing skills of a trumpet player apply to the new instrument. The placing of the buttons and sensors is not a hindrance to acoustic use of the instrument and they are conveniently located. The device can be easily attached to and detached from a normal Bb-trumpet. The device has a wireless connection with the computer through Bluetooth-serial (Arduino). Audio and data processing in the computer is effected by three separate instances of MAX/MSP connected through OSC (controller data) and Soundflower (sound data). The current prototype consists of 7 analogue sensors (4 valve-like potentiometers, 2 pressure sensors, 1 "Ribbon" controller) and 9 digital switches. An LCD screen that is controlled by a separate Arduino (mini) is attached to the trumpet and displays the current controller settings that are sent through a serial connection. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Trumpet, multiple Arduinos, Bluetooth, LCD, low latency, OSC, MAX/MSP.  },
pages = {193--198},
}
@inproceedings{Leider2009,
author = {Leider, Colby},
url = {http://www.nime.org/proceedings/2009/nime2009_333.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Afflux/Reflux},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {333--333},
}
@inproceedings{Leider2009a,
author = {Leider, Colby and Mann, Doug and Plazas, Daniel and Battaglia, Michael and Draper, Reid},
url = {http://www.nime.org/proceedings/2009/nime2009_147.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The elBo and footPad : Toward Personalized Hardware for Audio Manipulation},
year = {2009},
abstract = {We describe initial prototypes and a design strategy for new, user-customized audio-manipulation and editing tools. These tools are designed to enable intuitive control of audio-processing tasks while anthropomorphically matching the target user. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {user modeling, user customization  },
pages = {147--148},
}
@inproceedings{Lieberman2009,
author = {Lieberman, David},
url = {http://www.nime.org/proceedings/2009/nime2009_321.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Anigraphical Etude 9},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {321--321},
}
@inproceedings{Lyon2009,
author = {Lyon, Eric and Knapp, Benjamin and Ouzounian, Gascia},
url = {http://www.nime.org/proceedings/2009/nime2009_327.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Biomuse Trio},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {327--327},
}
@inproceedings{Lahdeoja2009,
author = {L\"{a}hdeoja, Otso},
url = {http://www.nime.org/proceedings/2009/nime2009_102.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Augmenting Chordophones with Hybrid Percussive Sound Possibilities},
year = {2009},
abstract = {In this paper we describe an approach for introducing newelectronic percussive sound possibilities for stringinstruments by "listening" to the sounds of the instrument'sbody and extracting audio and data from the wood'sacoustic vibrations. A method for capturing, localizing andanalyzing the percussive hits on the instrument's body ispresented, in connection with an audio-driven electronicpercussive sound module. The system introduces a newgesture-sound relationship in the electric string instrumentplaying environment, namely the use of percussivetechniques on the instrument's body which are null inregular circumstances due to selective and exclusivemicrophone use for the strings. Instrument bodypercussions are widely used in the acoustic instrumentalpraxis. They yield a strong potential for providing anextended soundscape via instrument augmentation, directlycontrolled by the musician through haptic manipulation ofthe instrument itself. The research work was carried out onthe electric guitar, but the method used can apply to anystring instrument with a resonating body.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {augmented instrument,chordophone,contact microphone systems,electric,electronic percussion,even with,guitar,leaving the instrument body,nime09,there is always a,trade-off,virtually mute},
pages = {102--105},
}
@inproceedings{Mann2009,
author = {Mann, Yotam and Lubow, Jeff and Freed, Adrian},
url = {http://www.nime.org/proceedings/2009/nime2009_086.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Tactus : a Tangible , Rhythmic Grid Interface Using Found-Objects},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {86--89},
}
@inproceedings{McDonald2009,
author = {McDonald, Kyle and Kouttron, Dane and Bahn, Curtis and Braasch, Jonas and Oliveros, Pauline},
url = {http://www.nime.org/proceedings/2009/nime2009_041.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Vibrobyte : A Haptic Interface for Co-Located Performance},
year = {2009},
abstract = {The Vibrobyte is a wireless haptic interface specialized forco-located musical performance. The hardware is designedaround the open source Arduino platform, with haptic control data encapsulated in OSC messages, and OSC/hardwarecommunications handled by Processing. The Vibrobyte wasfeatured at the International Computer Music Conference2008 (ICMC) in a telematic performance between ensembles in Belfast, Palo Alto (California, USA), and Troy (NewYork, USA).},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {haptics,interface,nime09,performance,telematic},
pages = {41--42},
}
@inproceedings{Mclean2009,
author = {Mclean, Alex and Wiggins, Geraint},
url = {http://www.nime.org/proceedings/2009/nime2009_276.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Words , Movement and Timbre},
year = {2009},
abstract = {Phonetic symbols describe movements of the vocal tract,tongue and lips, and are combined into complex movementsforming the words of language. In music, vocables are wordsthat describe musical sounds, by relating vocal movementsto articulations of a musical instrument. We posit that vocable words allow the composers and listeners to engageclosely with dimensions of timbre, and that vocables couldsee greater use in electronic music interfaces. A preliminarysystem for controlling percussive physical modelling synthesis with textual words is introduced, with particular application in expressive specification of timbre during computer music performances.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09,timbre,vocable synthesis},
pages = {276--279},
}
@inproceedings{Min2009,
author = {Min, Hye Ki},
url = {http://www.nime.org/proceedings/2009/nime2009_082.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SORISU : Sound with Numbers},
year = {2009},
abstract = {It is surely not difficult for anyone with experience in thesubject known as Music Theory to realize that there is avery definite and precise relationship between music andmathematics. This paper describes the SoriSu, a newelectronic musical instrument based on Sudoku puzzles,which probe the expressive possibilities of mathematicalconcepts in music. The concept proposes a new way ofmapping numbers to sound. This interface was designed toprovide easy and pleasing access to music for users whoare unfamiliar or uncomfortable with current musicaldevices. The motivation behind the project is presented, aswell as hardware and software design.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Numbers, Game Interfaces, Mathematics and Sound, Mathematics in Music, Puzzles, Tangible User Interfaces. },
pages = {82--85},
}
@inproceedings{Miyama2009,
author = {Miyama, Chikashi},
url = {http://www.nime.org/proceedings/2009/nime2009_326.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Angry Sparrow},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {326--326},
}
@inproceedings{Muller2009,
author = {M\"{u}ller, Alexander and Essl, Georg},
url = {http://www.nime.org/proceedings/2009/nime2009_033.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Utilizing Tactile Feedback to Guide Movements Between Sounds},
year = {2009},
abstract = {Vibetone is a musical input device which was build to explore tactile feedback in gesture based interaction. It is a prototype aimed to allow the performer to play both continuously and discrete pitched sounds in the same space. Our primary focus is on tactile feedback to guide the artist's movements during his performance. Thus, also untrained users are enabled to musical expression through bodily actions and precisely arm movements, guided through tactile feedback signals. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {tactile feedback, intuitive interaction, gestural interaction, MIDI controller  },
pages = {33--34},
}
@inproceedings{Nagashima2009,
author = {Nagashima, Yoichi},
url = {http://www.nime.org/proceedings/2009/nime2009_169.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Parallel Processing System Design with "Propeller" Processor},
year = {2009},
abstract = {This is a technical and experimental report of parallel processing, using the "Propeller" chip. Its eight 32 bits processors (cogs) can operate simultaneously, either independently or cooperatively, sharing common resources through a central hub. I introduce this unique processor and discuss about the possibility to develop interactive systems and smart interfaces in media arts, because we need many kinds of tasks at a same time with NIMErelated systems and installations. I will report about (1) Propeller chip and its powerful IDE, (2) external interfaces for analog/digital inputs/outputs, (3) VGA/NTSC/PAL video generation, (4) audio signal processing, and (5) originally-developed MIDI input/output method. I also introduce three experimental prototype systems.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Propeller, parallel processing, MIDI, sensor, interfaces. },
pages = {169--170},
}
@inproceedings{Nakra2009,
author = {Nakra, Teresa M. and Ivanov, Yuri and Smaragdis, Paris and Ault, Chris},
url = {http://www.nime.org/proceedings/2009/nime2009_250.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The UBS Virtual Maestro : an Interactive Conducting System},
year = {2009},
abstract = {The UBS Virtual Maestro is an interactive conducting system designed by Immersion Music to simulate the experience of orchestral conducting for the general public attending a classical music concert. The system utilizes the Wii Remote, which users hold and move like a conducting baton to affect the tempo and dynamics of an orchestral video/audio recording. The accelerometer data from the Wii Remote is used to control playback speed and volume in real-time. The system is housed in a UBSbranded kiosk that has toured classical performing arts venues throughout the United States and Europe in 2007 and 2008. In this paper we share our experiences in designing this standalone system for thousands of users, and lessons that we learned from the project. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {conducting, gesture, interactive installations, Wii Remote  },
pages = {250--255},
}
@inproceedings{Neill2009,
author = {Neill, Ben and Singer, Eric},
url = {http://www.nime.org/proceedings/2009/nime2009_331.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Ben Neill and LEMUR},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {331--331},
}
@inproceedings{Nicolls2009,
author = {Nicolls, Sarah},
url = {http://www.nime.org/proceedings/2009/nime2009_203.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Twenty-First Century Piano},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {sensor, gestural, technology, performance, piano, motors, interactive  },
pages = {203--206},
}
@inproceedings{Nishino2009,
author = {Nishino, Hiroki},
url = {http://www.nime.org/proceedings/2009/nime2009_062.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A 2D Fiducial Tracking Method based on Topological Region Adjacency and Angle Information},
year = {2009},
abstract = {We describe a new method for 2D fiducial tracking. We use region adjacency information together with angles between regions to encode IDs inside fiducials, whereas previous research by Kaltenbrunner and Bencina utilize region adjacency tree. Our method supports a wide ID range and is fast enough to accommodate real-time video. It is also very robust against false positive detection. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {fiducial tracking, computer vision, tangible user interface, interaction techniques.  },
pages = {62--63},
}
@inproceedings{Nymoen2009,
author = {Nymoen, Kristian and Jensenius, Alexander R.},
url = {http://www.nime.org/proceedings/2009/nime2009_094.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Discussion of Multidimensional Mapping in Nymophone2},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {94--97},
}
@inproceedings{Ogawa2009,
author = {Ogawa, Keisuke and Kuhara, Yasuo},
url = {http://www.nime.org/proceedings/2009/nime2009_050.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Life Game Orchestra as an Interactive Music Composition System Translating Cellular Patterns of Automata into Musical Scales},
year = {2009},
abstract = {We developed a system called Life Game Orchestra that generates music by translating cellular patterns of Conway's Game of Life into musical scales. A performer can compose music by controlling varying cell patterns and sounds with visual and auditory fun. A performer assigns the elements of tone to two-dimensional cell patterns in the matrix of the Game of Life. Our system searches defined cell patterns in the varying matrix dynamically. If the patterns are matched, corresponding tones are generated. A performer can make cells in the matrix by moving in front of a camera and interactively influencing the generation of music. The progress of the Game of Life is controlled with a clock defined by the performer to configure the groove of the music. By running multiple matrices with different pattern mapping, clock timing, and instruments, we can perform an ensemble. The Life Game Orchestra is a fusion system of the design of a performer and the emergence of cellular automata as a complex system. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Conway's Game of Life, Cellular automata, Cell pattern, scale, Interactive composition, performance.  },
pages = {50--51},
}
@inproceedings{Overholt2009,
author = {Overholt, Dan and Lahey, Byron and {Skriver Hansen}, Anne-Marie and Burleson, Winslow and {Norrgaard Jensen}, Camilla},
url = {http://www.nime.org/proceedings/2009/nime2009_339.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Pendaphonics},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {339--339},
}
@inproceedings{Paine2009,
author = {Paine, Garth and Atherton, Michael},
url = {http://www.nime.org/proceedings/2009/nime2009_324.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Fue Sho – Electrofusion},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {324--324},
}
@inproceedings{Parson2009,
author = {Parson, Dale E.},
url = {http://www.nime.org/proceedings/2009/nime2009_157.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Chess-Based Composition and Improvisation for Non-Musicians},
year = {2009},
abstract = {"Music for 32 Chess Pieces" is a software system that supports composing, performing and improvising music by playing a chess game. A game server stores a representation of the state of a game, validates proposed moves by players, updates game state, and extracts a graph of piece-to-piece relationships. It also loads a plugin code module that acts as a composition. A plugin maps pieces and relationships on the board, such as support or attack relationships, to a timed sequence of notes and accents. The server transmits notes in a sequence to an audio renderer process via network datagrams. Two players can perform a composition by playing chess, and a player can improvise by adjusting a plugin's music mapping parameters via a graphical user interface. A composer can create a new composition by writing a new plugin that uses a distinct algorithm for mapping game rules and states to music. A composer can also write a new note-to-sound mapping program in the audio renderer language. This software is available at http://faculty.kutztown.edu/parson/music/ParsonMusic.html. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {algorithmic composition, chess, ChucK, improvisation, Max/MSP, SuperCollider.  },
pages = {157--158},
}
@inproceedings{Partridge2009,
author = {Partridge, Grant and Irani, Pourang and Fitzell, Gordon},
url = {http://www.nime.org/proceedings/2009/nime2009_078.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Let Loose with WallBalls, a Collaborative Tabletop Instrument for Tomorrow},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Tabletop computers, collaborative instruments, collaborative composition, group improvisation, spatial au- dio interfaces, customizable instruments. },
pages = {78--81},
}
@inproceedings{Pedrosa2009,
author = {Pedrosa, Ricardo and Maclean, Karon E.},
url = {http://www.nime.org/proceedings/2009/nime2009_019.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Evaluation of 3D Haptic Target Rendering to Support Timing in Music Tasks},
year = {2009},
abstract = {Haptic feedback is an important element that needs to be carefully designed in computer music interfaces. This paper presents an evaluation of several force renderings for target acquisition in space when used to support a music related task. The study presented here addresses only one musical aspect: the need to repeat elements accurately in time and in content. Several force scenarios will be rendered over a simple 3D target acquisition task and users' performance will be quantitatively and qualitatively evaluated. The results show how the users' subjective preference for a particular kind of force support does not always correlate to a quantitative measurement of performance enhancement. We describe a way in which a control mapping for a musical interface could be achieved without contradicting the users' preferences as obtained from the study. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {music interfaces, force feedback, tempo, comfort, target acquisition.  },
pages = {19--24},
}
@inproceedings{Peng2009,
author = {Peng, Lijuan and Gerhard, David},
url = {http://www.nime.org/proceedings/2009/nime2009_155.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Wii-Based Gestural Interface for Computer Conducting Systems},
year = {2009},
abstract = {With the increase of sales of Wii game consoles, it is becoming commonplace for the Wii remote to be used as analternative input device for other computer systems. In thispaper, we present a system which makes use of the infraredcamera within the Wii remote to capture the gestures of aconductor using a baton with an infrared LED and battery.Our system then performs data analysis with gesture classification and following, and finally displays the gestures using visual baton trajectories and audio feedback. Gesturetrajectories are displayed in real time and can be comparedto the corresponding diagram shown in a textbook. In addition, since a conductor normally does not look at a screenwhile conducting, tones are played to represent a certainbeat in a conducting gesture. Further, the system can be controlled entirely with the baton, removing the need to switchfrom baton to mouse. The interface is intended to be usedfor pedagogy purposes.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Conducting, Gesture, Infrared, Learning, Wii. },
pages = {155--156},
}
@inproceedings{Polfreman2009,
author = {Polfreman, Richard},
url = {http://www.nime.org/proceedings/2009/nime2009_226.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {FrameWorks 3D : Composition in the Third Dimension},
year = {2009},
abstract = {Music composition on computer is a challenging task, involving a range of data types to be managed within a single software tool. A composition typically comprises a complex arrangement of material, with many internal relationships between data in different locations repetition, inversion, retrograde, reversal and more sophisticated transformations. The creation of such complex artefacts is labour intensive, and current systems typically place a significant cognitive burden on the composer in terms of maintaining a work as a coherent whole. FrameWorks 3D is an attempt to improve support for composition tasks within a Digital Audio Workstation (DAW) style environment via a novel three-dimensional (3D) user-interface. In addition to the standard paradigm of tracks, regions and tape recording analogy, FrameWorks displays hierarchical and transformational information in a single, fully navigable workspace. The implementation combines Java with Max/MSP to create a cross-platform, user-extensible package and will be used to assess the viability of such a tool and to develop the ideas further. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Digital Audio Workstation, graphical user- interfaces, 3D graphics, Max/MSP, Java.  },
pages = {226--229},
}
@inproceedings{Reben2009,
author = {Reben, Alexander and Laibowitz, Mat and Paradiso, Joseph A.},
url = {http://www.nime.org/proceedings/2009/nime2009_037.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Responsive Music Interfaces for Performance},
year = {2009},
abstract = {In this project we have developed reactive instruments for performance. Reactive instruments provide feedback for the performer thereby providing a more dynamic experience. This is achieved through the use of haptics and robotics. Haptics provide a feedback system to the control surface. Robotics provides a way to actuate the instruments and their control surfaces. This allows a highly coordinated "dance" between performer and the instrument. An application for this idea is presented as a linear slide interface. Reactive interfaces represent a dynamic way for music to be portrayed in performance. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {haptics, robotics, dynamic interfaces  },
pages = {37--38},
}
@inproceedings{Rogers2009,
author = {Rogers, Troy and Kemper, Steven and Barton, Scott},
url = {http://www.nime.org/proceedings/2009/nime2009_323.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Study no. 1 for PAM and MADI},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {323--323},
}
@inproceedings{Schacher2009,
author = {Schacher, Jan C.},
url = {http://www.nime.org/proceedings/2009/nime2009_286.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Action and Perception in Interactive Sound Installations : An Ecological Approach},
year = {2009},
abstract = {In this paper mappings and adaptation in the context of interactive sound installations are discussed. Starting from an ecological perspective on non-expert audience interaction a brief overview and discussion of mapping strategies with a special focus on adaptive systems using machine learning algorithms is given. An audio-visual interactive installation is analyzed and its implementation used to illustrate the issues of audience engagement and to discuss the efficiency of adaptive mappings. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Interaction, adaptive mapping, machine learning, audience engagement },
pages = {286--289},
}
@inproceedings{Schiesser2009,
author = {Schiesser, S\'{e}bastien},
url = {http://www.nime.org/proceedings/2009/nime2009_165.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {midOSC : a Gumstix-Based MIDI-to-OSC Converter},
year = {2009},
abstract = {A MIDI-to-OSC converter is implemented on a commercially available embedded linux system, tighly integratedwith a microcontroller. A layered method is developed whichpermits the conversion of serial data such as MIDI to OSCformatted network packets with an overall system latencybelow 5 milliseconds for common MIDI messages.The Gumstix embedded computer provide an interesting and modular platform for the development of such anembedded applications. The project shows great potentialto evolve into a generic sensors-to-OSC ethernet converterwhich should be very useful for artistic purposes and couldbe used as a fast prototyping interface for gesture acquisitiondevices.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {MIDI, Open Sound Control, converter, gumstix },
pages = {165--168},
}
@inproceedings{Schlessinger2009,
author = {Schlessinger, Daniel and Smith, Julius O.},
url = {http://www.nime.org/proceedings/2009/nime2009_098.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Kalichord : A Physically Modeled Electro-Acoustic Plucked String Instrument},
year = {2009},
abstract = { We present the Kalichord: a small, handheld electro/acoustic instrument in which the player's right hand plucks virtual strings while his left hand uses buttons to play independent bass lines. The Kalichord uses the analog signal from plucked acoustic tines to excite a physical string model, allowing a nuanced and intuitive plucking experience. First, we catalog instruments related to the Kalichord. Then we examine the use of analog signals to excite a physical string model and discuss the expressiveness and form factors that this technique affords. We then describe the overall construction of the Kalichord and possible playing styles, and finally we consider ways we hope to improve upon the current prototype. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Kalichord, physical model, tine, piezo, plucked string, electro-acoustic instruments, kalimba, accordion },
pages = {98--101},
}
@inproceedings{Schmeder2009,
author = {Schmeder, Andrew and Freed, Adrian},
url = {http://www.nime.org/proceedings/2009/nime2009_121.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Low-level Embedded Service Architecture for Rapid DIY Design of Real-time Musical Instruments},
year = {2009},
abstract = {An on-the-fly reconfigurable low-level embedded servicearchitecture is presented as a means to improve scalability, improve conceptual comprehensibility, reduce humanerror and reduce development time when designing newsensor-based electronic musical instruments with real-timeresponsiveness. The implementation of the concept ina project called micro-OSC is described. Other sensorinterfacing products are evaluated in the context of DIYprototyping of musical instruments. The capabilities ofthe micro-OSC platform are demonstrated through a set ofexamples including resistive sensing, mixed digital-analogsystems, many-channel sensor interfaces and time-basedmeasurement methods.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {real-time musical interface, DIY design, em- bedded web services, rapid prototyping, reconfigurable firmware },
pages = {121--124},
}
@inproceedings{Siwiak2009,
author = {Siwiak, Diana and Berger, Jonathan and Yang, Yao},
url = {http://www.nime.org/proceedings/2009/nime2009_153.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Catch Your Breath - Musical Biofeedback for Breathing Regulation},
year = {2009},
abstract = {Catch Your Breath is an interactive audiovisual bio-feedbacksystem adapted from a project designed to reduce respiratory irregularity in patients undergoing 4D CT scans for oncological diagnosis. The system is currently implementedand assessed as a potential means to reduce motion-induceddistortion in CT images.A museum installation based on the same principle wascreated in which an inexpensive wall-mounted web camera tracks an IR sensor embedded into a pendant worn bythe user. The motion of the subjects breathing is trackedand interpreted as a real-time variable tempo adjustment toa stored musical file. The subject can then adjust his/herbreathing to synchronize with a separate accompanimentline. When the breathing is regular and is at the desiredtempo, the audible result sounds synchronous and harmonious. The accompaniment's tempo progresses and gradually decrease which causes the breathing to synchronize andslow down, thus increasing relaxation.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {sensor, music, auditory display. },
pages = {153--154},
}
@inproceedings{Smallwood2009,
author = {Smallwood, Scott},
url = {http://www.nime.org/proceedings/2009/nime2009_340.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sound Lanterns},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {340--340},
}
@inproceedings{Smallwood2009a,
author = {Smallwood, Scott and Cook, Perry R. and Trueman, Dan and McIntyre, Lawrence},
url = {http://www.nime.org/proceedings/2009/nime2009_110.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Don ’ t Forget the Loudspeaker — A History of Hemispherical Speakers at Princeton , Plus a DIY Guide},
year = {2009},
abstract = {This paper gives a historical overview of the development of alternative sonic display systems at Princeton University; in particular, the design, construction, and use in live performance of a series of spherical and hemispherical speaker systems. We also provide a DIY guide to constructing the latest series of loudspeakers that we are currently using in our research and music making. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {loudspeakers, hemispherical speakers, sonic display systems, laptop orchestras.  },
pages = {110--115},
}
@inproceedings{Solis2009,
author = {Solis, Jorge and Ninomiya, Takeshi and Petersen, Klaus and Takeuchi, Masaki and Takanishi, Atsuo},
url = {http://www.nime.org/proceedings/2009/nime2009_064.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Anthropomorphic Musical Performance Robots at Waseda University : Increasing Understanding of the Nature of Human Musical Interaction Abstract},
year = {2009},
abstract = {During several decades, the research at Waseda University has been focused on developing anthropomorphic robots capable performing musical instruments. As a result of our research efforts, the Waseda Flutist Robot WF-4RIV and the Waseda Saxophonist Robot WAS-1 have been designed to reproduce the human player performance. As a long-term goal, we are proposing to enable the interaction between musical performance robots as well as with human players. In general the communication of humans within a band is a special case of conventional human social behavior. Rhythm, harmony and timbre of the music played represent the emotional states of the musicians. So the development of an artificial entity that participates in such an interaction may contribute to the better understanding of some of the mechanisms that enable the communication of humans in musical terms. Therefore, we are not considering a musical performance robot (MPR) just as a mere sophisticated MIDI instrument. Instead, its human-like design and the integration of perceptual capabilities may enable to act on its own autonomous initiative based on models which consider its own physical constrains. In this paper, we present an overview of our research approaches towards enabling the interaction between musical performance robots as well as with musicians. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {64--69},
}
@inproceedings{Spowage2009,
author = {Spowage, Neal},
url = {http://www.nime.org/proceedings/2009/nime2009_029.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Ghetto Bastard : A Portable Noise Instrument},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {29--30},
}
@inproceedings{StClair2009,
author = {St. Clair, Michael and Leitman, Sasha},
url = {http://www.nime.org/proceedings/2009/nime2009_293.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {PlaySoundGround : An Interactive Musical Playground},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {expression,in doing so,installation,interactive,it also opens up,music,new territories for,nime09,play,playful physical motions into,playground,radical collaboration,real-time,the realm of artistic},
pages = {293--296},
}
@inproceedings{Stearns2009,
author = {Stearns, Phillip},
url = {http://www.nime.org/proceedings/2009/nime2009_341.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {AANN: Artificial Analog Neural Network},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {341--341},
}
@inproceedings{Steiner2009,
author = {Steiner, Hans-Christoph},
url = {http://www.nime.org/proceedings/2009/nime2009_125.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Firmata : Towards Making Microcontrollers Act Like Extensions of the Computer},
year = {2009},
abstract = {Firmata is a generic protocol for communicating with microcontrollers from software on a host computer. The central goal is to make the microcontroller an extension of theprogramming environment on the host computer in a manner that feels natural in that programming environment. Itwas designed to be open and flexible so that any programming environment can support it, and simple to implementboth on the microcontroller and the host computer to ensurea wide range of implementations. The current reference implementation is a library for Arduino/Wiring and is includedwith Arduino software package since version 0012. Thereare matching software modules for a number of languages,like Pd, OpenFrameworks, Max/MSP, and Processing.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {arduino,microcontroller,nime09,processing,pure data},
pages = {125--130},
}
@inproceedings{Todoroff2009,
author = {Todoroff, Todor and Bettens, Fr\'{e}d\'{e}ric and Reboursi\`{e}re, Lo\"{\i}c and Chu, Wen-Yang},
url = {http://www.nime.org/proceedings/2009/nime2009_141.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {"Extension du Corps Sonore" - Dancing Viola},
year = {2009},
abstract = {"Extension du corps sonore" is long-term project initiatedby Musiques Nouvelles [4], a contemporary music ensemble in Mons. It aims at giving instrumental music performers an extended control over the sound of their instrument byextending the understanding of the sound body from the instrument only to the combination of the instrument and thewhole body of the performer. The development started atARTeM and got the benefit of a three month numediartresearch project [1] that focused on three axes of research:pre-processing of sensor data, gesture recognition and mapping through interpolation. The objectives were the development of computing methods and flexible Max/MSP externals to be later integrated in the ARTeM software framework for the concerts with viola player Dominica Eyckmans. They could be used in a variety of other artistic worksand will be made available on the numediart website [1],where more detailed information can be found in the Quarterly Progress Scientific Report #4.},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Sensor data pre-processing, gesture recognition, mapping, interpolation, extension du corps sonore },
pages = {141--146},
}
@inproceedings{Toenjes2009,
author = {Toenjes, John},
url = {http://www.nime.org/proceedings/2009/nime2009_052.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Natural Materials on Stage : Custom Controllers for Aesthetic Effect},
year = {2009},
abstract = {This article describes the implications of design and materials of computer controllers used in the context of interactive dance performance. Size, shape, and layout all influence audience perception of the performer, and materials imply context for further interpretation of the interactive performance work. It describes the construction of the "Control/Recorder" and the "VideoLyre," two custom computer control surfaces made for Leonardo's Chimes, a work by Toenjes, Marchant and Smith, and how these controllers contribute to theatrical aesthetic intent. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {control surface, interface, tactile, natural, organic, interactive dance.  },
pages = {52--53},
}
@inproceedings{Torre2009,
author = {Torre, Giuseppe and Sazdov, Robert and Konczewska, Dorota},
url = {http://www.nime.org/proceedings/2009/nime2009_330.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {MOLITVA — Composition for Voice, Live Electronics, Pointing-At Glove Device and 3-D Setup of Speakers},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {330--330},
}
@inproceedings{Wang2009,
author = {Wang, Ge},
url = {http://www.nime.org/proceedings/2009/nime2009_303.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Designing Smule’s Ocarina : The iPhone’s Magic Flute},
year = {2009},
abstract = {The Smule Ocarina is a wind instrument designed for the iPhone, fully leveraging its wide array of technologies: microphone input (for breath input), multitouch (for fingering), accelerometer, real-time sound synthesis, highperformance graphics, GPS/location, and persistent data connection. In this mobile musical artifact, the interactions of the ancient flute-like instrument are both preserved and transformed via breath-control and multitouch finger-holes, while the onboard global positioning and persistent data connection provide the opportunity to create a new social experience, allowing the users of Ocarina to listen to one another. In this way, Ocarina is also a type of social instrument that enables a different, perhaps even magical, sense of global connectivity. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {chuck,design,in,in real-time,interface,iphone,mobile music,multitouch,nime09,ocarina,pulsing waves,social,sonically and onscreen and,sound synthesis takes place,the breath is visualized},
pages = {303--307},
}
@inproceedings{Wang2009a,
author = {Wang, Ge and Fiebrink, Rebecca},
url = {http://www.nime.org/proceedings/2009/nime2009_334.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {PLOrk Beat Science 2.0},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {334--334},
}
@inproceedings{Wechsler2009,
author = {Wechsler, Robert},
url = {http://www.nime.org/proceedings/2009/nime2009_320.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Oklo Phenomenon},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {320--320},
}
@inproceedings{Weinberg2009,
author = {Weinberg, Gil and Beck, Andrew and Godfrey, Mark},
url = {http://www.nime.org/proceedings/2009/nime2009_312.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {ZooZBeat : a Gesture-based Mobile Music Studio},
year = {2009},
abstract = {ZooZBeat is a gesture-based mobile music studio. It is designed to provide users with expressive and creative access to music making on the go. ZooZBeat users shake the phone or tap the screen to enter notes. The result is quantized, mapped onto a musical scale, and looped. Users can then use tilt and shake movements to manipulate and share their creation in a group. Emphasis is placed on finding intuitive metaphors for mobile music creation and maintaining a balance between control and ease-of-use that allows non-musicians to begin creating music with the application immediately. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {mobile music, gestural control  },
pages = {312--315},
}
@inproceedings{Weinberg2009a,
author = {Weinberg, Gil and Blosser, Brian and Mallikarjuna, Trishul and Raman, Aparna},
url = {http://www.nime.org/proceedings/2009/nime2009_070.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Creation of a Multi-Human, Multi-Robot Interactive Jam Session},
year = {2009},
abstract = {This paper presents an interactive and improvisational jam session, including human players and two robotic musicians. The project was developed in an effort to create novel and inspiring music through human-robot collaboration. The jam session incorporates Shimon, a newly-developed socially-interactive robotic marimba player, and Haile, a perceptual robotic percussionist developed in previous work. The paper gives an overview of the musical perception modules, adaptive improvisation modes and human-robot musical interaction models that were developed for the session. The paper also addresses the musical output that can be created from increased interconnections in an expanded multiple-robot multiplehuman ensemble, and suggests directions for future work. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Robotic musicianship, Shimon, Haile.  },
pages = {70--73},
}
@inproceedings{Wessel2009,
author = {Wessel, David},
url = {http://www.nime.org/proceedings/2009/nime2009_335.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Hands On - A New Work from SLABS Controller and Generative Algorithms},
year = {2009},
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {nime09},
pages = {335--335},
}
@inproceedings{Wiley2009,
author = {Wiley, Meason and Kapur, Ajay},
url = {http://www.nime.org/proceedings/2009/nime2009_043.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Multi-Laser Gestural Interface — Solutions for Cost-Effective and Open Source Controllers},
year = {2009},
abstract = {This paper describes a cost-effective, modular, open source framework for a laser interface design that is open to community development, interaction and user modification. The following paper highlights ways in which we are implementing the multi-laser gestural interface in musical, visual, and robotic contexts. },
editor = {Zahler, Noel and Dannenberg, Roger B. and Sullivan, Tom},
address = {Pittsburgh, PA, United States},
keywords = {Lasers, photocell sensor, UltraSound, Open Source controller design, digital gamelan, digital tanpura  },
pages = {43--44},
}
