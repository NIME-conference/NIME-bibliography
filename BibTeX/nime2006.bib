% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{dAlessandro2006,
  Title                    = {Real-time CALM Synthesizer: New Approaches in Hands-Controlled Voice Synthesis},
  Author                   = {d'Alessandro, Nicolas and d'Alessandro, Christophe and {Le Beux}, Sylvain and Doval, Boris},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {266--271},

  Keywords                 = {Singing synthesis, voice source, voice quality, spectral model, formant synthesis, instrument, gestural control. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_266.pdf}
}

@InProceedings{Aylward2006,
  Title                    = {Sensemble: A Wireless, Compact, Multi-User Sensor System for Interactive Dance},
  Author                   = {Aylward, Ryan and Paradiso, Joseph A.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {134--139},

  Abstract                 = {We describe the design of a system of compact, wireless sensor modules meant to capture expressive motion whenworn at the wrists and ankles of a dancer. The sensors form ahigh-speed RF network geared toward real-time dataacquisition from multiple devices simultaneously, enabling asmall dance ensemble to become a collective interface formusic control. Each sensor node includes a 6-axis inertialmeasurement unit (IMU) comprised of three orthogonalgyroscopes and accelerometers in order to capture localdynamics, as well as a capacitive sensor to measure closerange node-to-node proximity. The nodes may also beaugmented with other digital or analog sensors. This paperdescribes application goals, presents the prototype hardwaredesign, introduces concepts for feature extraction andinterpretation, and discusses early test results.},
  Keywords                 = {Interactive dance, wearable sensor networks, inertial gesture tracking, collective motion analysis, multi-user interface },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_134.pdf}
}

@InProceedings{Beilharz2006,
  Title                    = {Hyper-shaku (Border-crossing): Towards the Multi-modal Gesture-controlled Hyper-Instrument},
  Author                   = {Beilharz, Kirsty and Jakovich, Joanne and Ferguson, Sam},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {352--357},

  Abstract                 = {Hyper-shaku (Border-Crossing) is an interactive sensor environment that uses motion sensors to trigger immediate responses and generative processes augmenting the Japanese bamboo shakuhachi in both the auditory and visual domain. The latter differentiates this process from many hyper-instruments by building a performance of visual design as well as electronic music on top of the acoustic performance. It utilizes a combination of computer vision and wireless sensing technologies conflated from preceding works. This paper outlines the use of gesture in these preparatory sound and audio-visual performative, installation and sonification works, leading to a description of the Hyper-shaku environment integrating sonification and generative elements. },
  Keywords                 = {Gesture-controllers, sonification, hyper-instrument },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_352.pdf}
}

@InProceedings{Bennett2006,
  Title                    = {{PET}ECUBE: a Multimodal Feedback Interface},
  Author                   = {Bennett, Peter},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {81--84},

  Abstract                 = {The PETECUBE project consists of a series of musical interfaces designed to explore multi-modal feedback. This paper will briefly describe the definition of multimodal feedback, the aim of the project, the development of the first PETECUBE and proposed further work. },
  Keywords                 = {Multi-modal Feedback. Haptics. Musical Instrument. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_081.pdf}
}

@InProceedings{Bevilacqua2006,
  Title                    = {The Augmented Violin Project: Research, Composition and Performance Report},
  Author                   = {Bevilacqua, Fr\'{e}d\'{e}ric and Rasamimanana, Nicolas and Fl\'{e}ty, Emmanuel and Lemouton, Serge and Baschet, Florence},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {402--406},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_402.pdf}
}

@InProceedings{Birchfield2006,
  Title                    = {Interactive Public Sound Art: a case study},
  Author                   = {Birchfield, David and Phillips, Kelly and Kidan\'{e}, Assegid and Lorig, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {43--48},

  Abstract                 = {Physically situated public art poses significant challenges for the design and realization of interactive, electronic sound works. Consideration of diverse audiences, environmental sensitivity, exhibition conditions, and logistics must guide the artwork. We describe our work in this area, using a recently installed public piece, Transition Soundings, as a case study that reveals a specialized interface and open-ended approach to interactive music making. This case study serves as a vehicle for examination of the real world challenges posed by public art and its outcomes. },
  Keywords                 = {Music, Sound, Interactivity, Arts, Public Art, Network Systems, Sculpture, Installation Art, Embedded Electronics. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_043.pdf}
}

@InProceedings{Bonardi2006,
  Title                    = {Towards a Virtual Assistant for Performers and Stage Directors},
  Author                   = {Bonardi, Alain and Truck, Isis and Akdag, Herman},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {326--329},

  Abstract                 = {In this article, we present the first step of our research work todesign a Virtual Assistant for Performers and Stage Directors,able to give a feedback from performances. We use amethodology to automatically construct fuzzy rules in a FuzzyRule-Based System that detects contextual emotions from anactor's performance during a show.We collect video data from a lot of performances of the sameshow from which it should be possible to visualize all theemotions and intents or more precisely "intent graphs". Toperform this, the collected data defining low-level descriptorsare aggregated and converted into high-level characterizations.Then, depending on the retrieved data and on their distributionon the axis, we partition the universes into classes. The last stepis the building of the fuzzy rules that are obtained from theclasses and that permit to give conclusions to label the detectedemotions.},
  Keywords                 = {Virtual Assistant, Intents, Emotion detector, Fuzzy Classes, Stage Director, Performance. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_326.pdf}
}

@InProceedings{Borchers2006,
  Title                    = {MICON A Music Stand for Interactive Conducting},
  Author                   = {Borchers, Jan and Hadjakos, Aristotelis and M\"{u}hlh\"{a}user, Max},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {254--259},

  Abstract                 = {The MICON is an electronic music stand extending Maestro!, the latest in a series of interactive conducting exhibits that use real orchestral audio and video recordings. The MICON uses OpenGL-based rendering to display and animate score pages with a high degree of realism. It offers three different score display formats to match the user's level of expertise. A realtime animated visual cueing system helps users with their conducting. The MICON has been evaluated with music students. },
  Keywords                 = {Music stand, score display, exhibit, conducting. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_254.pdf}
}

@InProceedings{Bottoni2006,
  Title                    = {Mapping with Planning Agents in the Max/MSP Environment: the GO/Max Language},
  Author                   = {Bottoni, Paolo and Faralli, Stefano and Labella, Anna and Pierro, Mario},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {322--325},

  Keywords                 = {mapping, planning, agent, Max/MSP },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_322.pdf}
}

@InProceedings{Bowers2006,
  Title                    = {Creating Ad Hoc Instruments with Pin\&Play\&Perform},
  Author                   = {Bowers, John and Villar, Nicolas},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {234--239},

  Keywords                 = {Ad hoc instruments, Pin&Play, physical interfaces, music performance, new interfaces for musical expression. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_234.pdf}
}

@InProceedings{Breinbjerg2006,
  Title                    = {An Acousmatic Composition Environment},
  Author                   = {Breinbjerg, Morten and Caprani, Ole and Lunding, Rasmus and Kramhoft, Line},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {334--337},

  Abstract                 = {In this paper we describe the intentions, the design and functionality of an Acousmatic Composition Environment that allows children or musical novices to educate their auditory curiosity by recording, manipulating and mixing sounds of everyday life. The environment consists of three stands: A stand for sound recording with a soundproof box that ensure good recording facilities in a noisy environment; a stand for sound manipulation with five simple, tangible interfaces; a stand for sound mixing with a graphical computer interface presented on two touch screens. },
  Keywords                 = {Acousmatic listening, aesthetics, tangible interfaces. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_334.pdf}
}

@InProceedings{BryanKinns2006,
  Title                    = {Decay in Collaborative Music Making},
  Author                   = {Bryan-Kinns, Nick and Healey, Patrick G.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {114--117},

  Abstract                 = {This paper reports on ongoing studies of the design and use ofsupport for remote group music making. In this paper weoutline the initial findings of a recent study focusing on thefunction of decay of contributions in collaborative musicmaking. Findings indicate that persistent contributions lendthemselves to individual musical composition and learningnovel interfaces, whilst contributions that quickly decayengender a more focused musical interaction in experiencedparticipants.},
  Keywords                 = {creativity,design,group interaction,music improvisation},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_114.pdf}
}

@InProceedings{Burns2006,
  Title                    = {Visual Methods for the Retrieval of Guitarist Fingering},
  Author                   = {Burns, Anne-Marie and Wanderley, Marcelo M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {196--199},

  Keywords                 = {finger-tracking,gesture,guitar fingering,hough transform},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_196.pdf}
}

@InProceedings{Burtner2006,
  Title                    = {Perturbation Techniques for Multi-Performer or Multi- Agent Interactive Musical Interfaces},
  Author                   = {Burtner, Matthew},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {129--133},

  Abstract                 = {This paper explores the use of perturbation in designing multiperformer or multi-agent interactive musical interfaces. A problem with the multi-performer approach is how to cohesively organize the independent data inputs into useable control information for synthesis engines. Perturbation has proven useful for navigating multi-agent NIMEs. The ,
,
author's Windtree is discussed as an example multi-performer instrument in which perturbation is used for multichannel ecological modeling. The Windtree uses a physical system turbulence model controlled in real time by four performers. },
  Keywords                 = {interface,mapping,movement,multi-agent,multi-performer,music composition,perturbation},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_129.pdf}
}

@InProceedings{Crevoisier2006,
  Title                    = {Sound Rose: Creating Music and Images with a Touch Table},
  Author                   = {Crevoisier, Alain and Bornand, C\'{e}dric and Guichard, Arnaud and Matsumura, Seiichiro and Arakawa, Chuichi},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {212--215},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_212.pdf}
}

@InProceedings{Davidson2006,
  Title                    = {Synthesis and Control on Large Scale Multi-Touch Sensing Displays},
  Author                   = {Davidson, Philip L. and Han, Jefferson Y.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {216--219},

  Abstract                 = {In this paper, we describe our experience in musical interface design for a large scale, high-resolution, multi-touch display surface. We provide an overview of historical and presentday context in multi-touch audio interaction, and describe our approach to analysis of tracked multi-finger, multi-hand data for controlling live audio synthesis.},
  Keywords                 = {multi-touch, touch, tactile, bi-manual, multi-user, synthesis, dynamic patching },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_216.pdf}
}

@InProceedings{Dimitrov2006,
  Title                    = {A Simple Practical Approach to a Wireless Data Acquisition Board},
  Author                   = {Dimitrov, Smilen and Serafin, Stefania},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {184--187},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_184.pdf}
}

@InProceedings{Dobrian2006,
  Title                    = {The E in NIME: Musical Expression with New Computer Interfaces},
  Author                   = {Dobrian, Christopher and Koppelman, Daniel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {277--282},

  Abstract                 = {Is there a distinction between New Interfaces for MusicalExpression and New Interfaces for Controlling Sound? Thisarticle begins with a brief overview of expression in musicalperformance, and examines some of the characteristics ofeffective "expressive" computer music instruments. Itbecomes apparent that sophisticated musical expressionrequires not only a good control interface but also virtuosicmastery of the instrument it controls. By studying effectiveacoustic instruments, choosing intuitive but complexgesture-sound mappings that take advantage of establishedinstrumental skills, designing intelligent characterizationsof performance gestures, and promoting long-term dedicatedpractice on a new interface, computer music instrumentdesigners can enhance the expressive quality of computermusic performance.},
  Keywords                 = {Expression, instrument design, performance, virtuosity. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_277.pdf}
}

@InProceedings{Farwell2006,
  Title                    = {Adapting the Trombone: a Suite of Electro-acoustic Interventions for the Piece},
  Author                   = {Farwell, Neal},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {358--363},

  Abstract                 = {Three electro-acoustic systems were devised for a newtrombone work, Rouse. This paper presents the technicalsystems and outlines their musical context and motivation. TheuSlide measures trombone slide-extension by a minimalhardware ultrasonic technique. An easy calibration proceduremaps linear extension to the slide "positions" of the player. TheeMouth is a driver that replaces the mouthpiece, with softwareemulation of trombone tone and algorithmic musical lines,allowing the trombone to appear to play itself. The eMute isbuilt around a loudspeaker unit, driven so that it affects stronglythe player's embouchure, allowing fine control of complex beatpatterns. eMouth and eMute, under control of the uSlide, set upimprovisatory worlds that are part of the composed architectureof Rouse.},
  Keywords                 = {composition,electro-acoustic adaptation,emulation,illusion,improvisation,mapping,mute,trombone,ultrasonic},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_358.pdf}
}

@InProceedings{Favilla2006,
  Title                    = {Children of Grainger: Leather Instruments for Free Music},
  Author                   = {Favilla, Stuart and Cannon, Joanne},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {370--375},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_370.pdf}
}

@InProceedings{Ferguson2006,
  Title                    = {Learning Musical Instrument Skills Through Interactive Sonification},
  Author                   = {Ferguson, Sam},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {384--389},

  Keywords                 = {interactive sonification,music,sonification,sound visualization},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_384.pdf}
}

@InProceedings{Francois2006,
  Title                    = {An Architectural Framework for Interactive Music Systems},
  Author                   = {Francois, Alexander R. and Chew, Elaine},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {150--155},

  Keywords                 = {Software Architecture, Interactive Systems, Music soft- ware },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_150.pdf}
}

@InProceedings{Freed2006,
  Title                    = {Beyond 0-5{V}: Expanding Sensor Integration Architectures},
  Author                   = {Freed, Adrian and Avizienis, Rimas and Wright, Matthew},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {97--100},

  Abstract                 = {A new sensor integration system and its first incarnation i sdescribed. As well as supporting existing analog sensorarrays a new architecture allows for easy integration of thenew generation of low-cost digital sensors used in computermusic performance instruments and installation art.},
  Keywords                 = {Gesture, sensor, MEMS, FPGA, network, OSC, configurability },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_097.pdf}
}

@InProceedings{Freed2006a,
  Title                    = {Augmenting the Cello},
  Author                   = {Freed, Adrian and Wessel, David and Zbyszynski, Michael and Uitti, Frances M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {409--413},

  Abstract                 = {Software and hardware enhancements to an electric 6-stringcello are described with a focus on a new mechanical tuningdevice, a novel rotary sensor for bow interaction and controlstrategies to leverage a suite of polyphonic soundprocessing effects.},
  Keywords                 = {Cello, chordophone, FSR, Rotary Absolute Position Encoder, Double Bowing, triple stops, double stops, convolution. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_409.pdf}
}

@InProceedings{Gaye2006,
  Title                    = {Mobile Music Technology: Report on an Emerging Community},
  Author                   = {Gaye, Lalya and Holmquist, Lars E. and Behrendt, Frauke and Tanaka, Atau},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {22--25},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_022.pdf}
}

@InProceedings{Geiger2006,
  Title                    = {Using the Touch Screen as a Controller for Portable Computer Music Instruments},
  Author                   = {Geiger, G\"{u}nter},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {61--64},

  Keywords                 = {touch screen, PDA, Pure Data, controller, mobile musical instrument, human computer interaction },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_061.pdf}
}

@InProceedings{Goto2006,
  Title                    = {The Case Study of An Application of The System, `BodySuit' and `RoboticMusic': Its Introduction and Aesthetics},
  Author                   = {Goto, Suguru},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {292--295},

  Abstract                 = {This paper is intended to introduce the system, whichcombines "BodySuit" and "RoboticMusic," as well as itspossibilities and its uses in an artistic application."BodySuit" refers to a gesture controller in a Data Suit type."RoboticMusic" refers to percussion robots, which are appliedto a humanoid robot type. In this paper, I will discuss theiraesthetics and the concept, as well as the idea of the "ExtendedBody".},
  Keywords                 = {Robot, Gesture Controller, Humanoid Robot, Artificial Intelligence, Interaction },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_292.pdf}
}

@InProceedings{Gurevich2006,
  Title                    = {JamSpace: Designing A Collaborative Networked Music Space for Novices},
  Author                   = {Gurevich, Michael},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {118--123},

  Keywords                 = {Collaborative interface, remote jamming, network music, interaction design, novice, media space INTRODUCTION Most would agree that music is an inherently social ac- tivity [30], but since the },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_118.pdf}
}

@InProceedings{Hamel2006,
  Title                    = {Integrated Interactive Music Performance Environment},
  Author                   = {Hamel, Keith},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {380--383},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_380.pdf}
}

@InProceedings{Hamilton2006,
  Title                    = {Bioinformatic Feedback: Performer Bio-data as a Driver for Real-time Composition},
  Author                   = {Hamilton, Robert},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {338--341},

  Keywords                 = {Bioinformatics, composition, real-time score generation. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_338.pdf}
}

@InProceedings{Hansen2006,
  Title                    = {Mapping Strategies in DJ Scratching},
  Author                   = {Hansen, Kjetil F. and Bresin, Roberto},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {188--191},

  Keywords                 = {controllers,dj,instrument mapping,scratching,virtual},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_188.pdf}
}

@InProceedings{Hindman2006,
  Title                    = {Modal Kombat: Competition and Choreography in Synesthetic Musical Performance},
  Author                   = {Hindman, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {296--299},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_296.pdf}
}

@InProceedings{Holm2006,
  Title                    = {Using MIDI to Modify Video Game Content},
  Author                   = {Holm, Jukka and Arrasvuori, Juha and Havukainen, Kai},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {65--70},

  Abstract                 = {This paper discusses the concept of using background music to control video game parameters and thus actions on the screen. Each song selected by the player makes the game look different and behave variedly. The concept is explored by modifying an existing video game and playtesting it with different kinds of MIDI music. Several examples of mapping MIDI parameters to game events are presented. As mobile phones' MIDI players do not usually have a dedicated callback API, a real-time MIDI analysis software for Symbian OS was implemented. Future developments including real-time group performance as a way to control game content are also considered. },
  Keywords                 = {Games, MIDI, music, rhythm games, background music reactive games, musically controlled games, MIDI-controlled games, Virtual Sequencer. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_065.pdf}
}

@InProceedings{Hsu2006,
  Title                    = {Managing Gesture and Timbre for Analysis and Instrument Control in an Interactive Environment},
  Author                   = {Hsu, William},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {376--379},

  Abstract                 = {This paper describes recent enhancements in an interactive system designed to improvise with saxophonist John Butcher [1]. In addition to musical parameters such as pitch and loudness, our system is able to analyze timbral characteristics of the saxophone tone in real-time, and use timbral information to guide the generation of response material. We capture each saxophone gesture on the fly, extract a set of gestural and timbral contours, and store them in a repository. Improvising agents can consult the repository when generating responses. The gestural or timbral progression of a saxophone phrase can be remapped or transformed; this enables a variety of response material that also references audible contours of the original saxophone gestures. A single simple framework is used to manage gestural and timbral information extracted from analysis, and for expressive control of virtual instruments in a free improvisation context. },
  Keywords                 = {Interactive music systems, timbre analysis, instrument control. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_376.pdf}
}

@InProceedings{Jacquemin2006,
  Title                    = {Transmodal Feedback as a New Perspective for Audio-visual Effects},
  Author                   = {Jacquemin, Christian and de Laubier, Serge},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {156--161},

  Keywords                 = {audio-visual composition,feedback,transmodality},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_156.pdf}
}

@InProceedings{Jensenius2006a,
  Title                    = {Towards a Gesture Description Interchange Format},
  Author                   = {Jensenius, Alexander Refsum and Kvifte, Tellef and Godøy, Rolf Inge},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {176--179},
  Abstract = {This paper presents our need for a Gesture Description Interchange Format (GDIF) for storing, retrieving and sharing information about music-related gestures. Ideally, it should be possible to store all sorts of data from various commercial and custom made controllers, motion capture and computer vision systems, as well as results from different types of gesture analysis, in a coherent and consistent way. This would make it possible to use the information with different software, platforms and devices, and also allow for sharing data between research institutions. We present some of the data types that should be included, and discuss issues which need to be resolved.},
  Keywords                 = {Gesture description, gesture analysis, standards },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_176.pdf}
}

@InProceedings{Johnson2006,
  Title                    = {Timbre Interfaces using Adjectives and Adverbs},
  Author                   = {Johnson, Colin G. and Gounaropoulos, Alex},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {101--102},

  Abstract                 = {How can we provide interfaces to synthesis algorithms thatwill allow us to manipulate timbre directly, using the sametimbre-words that are used by human musicians to communicate about timbre? This paper describes ongoingwork that uses machine learning methods (principally genetic algorithms and neural networks) to learn (1) to recognise timbral characteristics of sound and (2) to adjust timbral characteristics of existing synthesized sounds.},
  Keywords                 = {timbre; natural language; neural networks },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_101.pdf}
}

@InProceedings{DeJong2006,
  Title                    = {A Tactile Closed-Loop Device for Musical Interaction},
  Author                   = {de Jong, Staas},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {79--80},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_079.pdf}
}

@InProceedings{Jorda2006,
  Title                    = {Mary Had a Little scoreTable* or the reacTable* Goes Melodic},
  Author                   = {Jord\`{a}, Sergi and Alonso, Marcos},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {208--211},

  Abstract                 = {This paper introduces the scoreTable*, a tangible interactive music score editor which started as a simple application for demoing "traditional" approaches to music creation, using the reacTable* technology, and which has evolved into an independent research project on its own. After a brief discussion on the role of pitch in music, we present a brief overview of related tangible music editors, and discuss several paradigms in computer music creation, contrasting synchronous with asynchronous approaches. The final part of the paper describes the current state of the scoreTable* as well as its future lines of research.},
  Keywords                 = {Musical instrument, Collaborative Music, Computer Supported Collaborative Work, Tangible User Interface, Music Theory. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_208.pdf}
}

@InProceedings{Kartadinata2006,
  Title                    = {The Gluion Advantages of an {FPGA}-based Sensor Interface},
  Author                   = {Kartadinata, Sukandar},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {93--96},

  Abstract                 = {The gluion is a sensor interface that was designed to overcomesome of the limitations of more traditional designs based onmicrocontrollers, which only provide a small, fixed number ofdigital modules such as counters and serial interfaces. These areoften required to handle sensors where the physical parametercannot easily be converted into a voltage. Other sensors arepacked into modules that include converters and communicatevia SPI or I2C. Finallly, many designs require outputcapabilities beyond simple on/off.The gluion approaches these challenges thru its FPGA-baseddesign which allows for a large number of digital I/O modules.It also provides superior flexibility regarding theirconfiguration, resolution, and functionality. In addition, theFPGA enables a software implementation of the host link - inthe case of the gluion the OSC protocol as well as theunderlying Ethernet layers.},
  Keywords                 = {actuators,digital sensors,fpga,osc,sensor interfaces},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_093.pdf}
}

@InProceedings{Kessous2006,
  Title                    = {'GXtar', an Interface Using Guitar Techniques},
  Author                   = {Kessous, Lo\"{\i}c and Castet, Julien and Arfib, Daniel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {192--195},

  Abstract                 = {In this paper we describe a new guitar-like musical controller. The 'GXtar' is an instrument which takes as a starting point a guitar but his role is to bring different and new musical possibilities while preserving the spirit and techniques of guitar. Therefore, it was conceived and carried out starting from the body of an electric guitar. The fingerboard of this guitar was equipped with two lines of sensors: linear position sensors, and tactile pressure sensors. These two lines of sensors are used as two virtual strings. Their two ends are the bridge and the nut of the guitar. The design of the instrument is made in a way that the position of a finger, on one of these virtual strings, corresponds to the note, which would have been played on a real and vibrating string. On the soundboard of the guitar, a controller, with 3 degrees of freedom, allows to drive other synthesis parameters. We then describe how this interface is integrated in a musical audio system and serves as a musical instrument. },
  Keywords                 = {Guitar, alternate controller, sensors, synthesizer, multidimensional control. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_192.pdf}
}

@InProceedings{Kimura2006,
  Title                    = {Auditory Illusion and Violin: Demonstration of a Work by Jean-Claude Risset Written for Mari Kimura},
  Author                   = {Kimura, Mari and Risset, Jean-Claude},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {407--408},

  Abstract                 = {This is a description of a demonstration, regarding theuse of auditory illusions and psycho-acoustic phenomenonused in the interactive work of Jean-Claude Risset, writtenfor violinist Mari Kimura.},
  Keywords                 = {Violin, psycho-acoustic phenomena, auditory illusions, sig- nal processing, subharmonics, Risset, Kimura. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_407.pdf}
}

@InProceedings{Kiser2006,
  Title                    = {spinCycle: a Color-Tracking Turntable Sequencer},
  Author                   = {Kiser, Spencer},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {75--76},

  Abstract                 = {This report presents an interface for musical performance called the spinCycle. spinCycle enables performers to make visual patterns with brightly colored objects on a spinning turntable platter that get translated into musical arrangements in realtime. I will briefly describe the hardware implementation and the sound generation logic used, as well as provide a historical background for the project.},
  Keywords                 = {Color-tracking, turntable, visualization, interactivity, synesthesia },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_075.pdf}
}

@InProceedings{Knapp2006,
  Title                    = {Creating a Network of Integral Music Controllers},
  Author                   = {Knapp, Benjamin and Cook, Perry R.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {124--128},

  Abstract                 = {In this paper, we describe the networking of multiple Integral Music Controllers (IMCs) to enable an entirely new method for creating music by tapping into the composite gestures and emotions of not just one, but many performers. The concept and operation of an IMC is reviewed as well as its use in a network of IMC controllers. We then introduce a new technique of Integral Music Control by assessing the composite gesture(s) and emotion(s) of a group of performers through the use of a wireless mesh network. The Telemuse, an IMC designed precisely for this kind of performance, is described and its use in a new musical performance project under development by the ,
,
authors is discussed. },
  Keywords                 = {Community-Institutional Relations,Health Services Accessibility,Medically Uninsured,Organizational Case Studies,Primary Health Care,Public-Private Sector Partnerships,San Francisco},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_124.pdf}
}

@InProceedings{Kobayashi2006,
  Title                    = {GAINER: A Reconfigurable {I/O} Module and Software Libraries for Education},
  Author                   = {Kobayashi, Shigeru and Endo, Takanori and Harada, Katsuhiko and Oishi, Shosei},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {346--351},

  Keywords                 = {learning,rapid prototyping,reconfigurable,sensor interface},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_346.pdf}
}

@InProceedings{Kobori2006,
  Title                    = {LINE: Interactive Sound and Light Installation},
  Author                   = {Kobori, Daisuke and Kagawa, Kojiro and Iida, Makoto and Arakawa, Chuichi},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {110--113},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_110.pdf}
}

@InProceedings{Koehly2006,
  Title                    = {Paper FSRs and Latex/Fabric Traction Sensors: Methods for the Development of Home-Made Touch Sensors},
  Author                   = {Koehly, Rodolphe and Curtil, Denis and Wanderley, Marcelo M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {230--233},

  Abstract                 = {This paper presents the development of novel "home-made" touch sensors using conductive pigments and various substrate materials. We show that it is possible to build one's own position, pressure and bend sensors with various electrical characteristics, sizes and shapes, and this for a very competitive price. We give examples and provide results from experimental tests of such developments. },
  Keywords                 = {Touch sensors, piezoresistive technology, conductive pigments, sensitive materials, interface design },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_230.pdf}
}

@InProceedings{Kvifte2006,
  Title                    = {Towards a Coherent Terminology and Model of Instrument Description and Design},
  Author                   = {Kvifte, Tellef and Jensenius, Alexander Refsum},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {220--225},
Abstract = {This paper discusses the need for a framework for describing musical instruments and their design, and discusses some possible elements in such a framework. The framework is meant as an aid in the development of a coherent terminology for describing, comparing and discussing different musical instruments and musical instrument designs. Three different perspectives are presented; that of the listener, the performer, and the constructor, and various levels of descriptions are introduced.},
  Keywords                 = {Musical instrument design, mapping, gestures, organology. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_220.pdf}
}

@InProceedings{DeLaubier2006,
  Title                    = {Meta-Instrument 3: a Look over 17 Years of Practice},
  Author                   = {de Laubier, Serge and Goudard, Vincent},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {288--291},

  Keywords                 = {1,audio-graphic portable instrument,ethernet,from 1983 to 1988,genesis of the project,on,puce muse studios,r\'{e}pertoire,we worked at the,wifi},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_288.pdf}
}

@InProceedings{Lebel2006,
  Title                    = {The G-Spring Controller},
  Author                   = {Lebel, Denis and Malloch, Joseph},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {85--88},

  Keywords                 = {Digital musical instrument, kinesthetic feedback },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_085.pdf}
}

@InProceedings{Lee2006,
  Title                    = {conga: A Framework for Adaptive Conducting Gesture Analysis},
  Author                   = {Lee, Eric and Gr\"{u}ll, Ingo and Keil, Henning and Borchers, Jan},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {260--265},

  Abstract                 = {Designing a conducting gesture analysis system for public spacesposes unique challenges. We present conga, a software framework that enables automatic recognition and interpretation ofconducting gestures. conga is able to recognize multiple types ofgestures with varying levels of difficulty for the user to perform,from a standard four-beat pattern, to simplified up-down conducting movements, to no pattern at all. conga provides an extendablelibrary of feature detectors linked together into a directed acyclicgraph; these graphs represent the various conducting patterns asgesture profiles. At run-time, conga searches for the best profileto match a user's gestures in real-time, and uses a beat prediction algorithm to provide results at the sub-beat level, in additionto output values such as tempo, gesture size, and the gesture'sgeometric center. Unlike some previous approaches, conga doesnot need to be trained with sample data before use. Our preliminary user tests show that conga has a beat recognition rate ofover 90%. conga is deployed as the gesture recognition systemfor Maestro!, an interactive conducting exhibit that opened in theBetty Brinn Children's Museum in Milwaukee, USA in March2006.},
  Keywords                 = {gesture recognition, conducting, software gesture frameworks },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_260.pdf}
}

@InProceedings{Lee2006a,
  Title                    = {The Chopping Board: Real-time Sample Editor},
  Author                   = {Lee, Jason},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {77--78},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_077.pdf}
}

@InProceedings{Lehrman2006,
  Title                    = {A "Ballet M\'{e}canique" for the 21{s}t Century: Performing George Antheil's Dadaist Masterpiece with Robots},
  Author                   = {Lehrman, Paul D. and Singer, Eric},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {300--303},

  Keywords                 = {Robotics, computer control, MIDI, player pianos, mechanical music, percussion, sound effects, Dadaism. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_300.pdf}
}

@InProceedings{Lemouton2006,
  Title                    = {Using the Augmented Trombone in "I will not kiss your f.ing flag"},
  Author                   = {Lemouton, Serge and Stroppa, Marco and Sluchin, Benny},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {304--307},

  Abstract                 = {This paper deals with the first musical usage of anexperimental system dedicated to the optical detection ofthe position of a trombone's slide.},
  Keywords                 = {1,augmented instrument,chamber electronics,computer,interaction,musical motivation,performer,trombone},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_304.pdf}
}

@InProceedings{Leroy2006,
  Title                    = {Reflective Optical Pickup For Violin},
  Author                   = {Leroy, Nicolas and Fl\'{e}ty, Emmanuel and Bevilacqua, Fr\'{e}d\'{e}ric},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {204--207},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_204.pdf}
}

@InProceedings{Lippit2006,
  Title                    = {Turntable Music in the Digital Era: Designing Alternative Tools for New Turntable Expression},
  Author                   = {Lippit, Takuro M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {71--74},

  Abstract                 = {Turntable musicians have yet to explore new expressions with digital technology. New higher-level development tools open possibilities for these artists to build their own instruments that can achieve artistic goals commercial products cannot. This paper will present a rough overview on the practice and recent development of turntable music, followed by descriptions of two projects by the ,
,
author. },
  Keywords                 = {Turntable music, DJ, turntablist, improvisation, Max/MSP, PIC Microcontroller, Physical Computing },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_071.pdf}
}

@InProceedings{Lock2006,
  Title                    = {Orbophone: a New Interface for Radiating Sound and Image},
  Author                   = {Lock, Damien and Schiemer, Greg},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {89--92},

  Abstract                 = {The Orbophone is a new interface that radiates rather thanprojects sound and image. It provides a cohesive platformfor audio and visual presentation in situations where bothmedia are transmitted from the same location andlocalization in both media is perceptually correlated. Thispaper discusses the advantages of radiation overconventional sound and image projection for certain kindsof interactive public multimedia exhibits and describes theartistic motivation for its development against a historicalbackdrop of sound systems used in public spaces. Oneexhibit using the Orbophone is described in detail togetherwith description and critique of the prototype, discussingaspects of its design and construction. The paper concludeswith an outline of the Orbophone version 2.},
  Keywords                 = {Immersive Sound; Multi-channel Sound; Loud-speaker Array; Multimedia; Streaming Media; Real-Time Media Performance; Sound Installation. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_089.pdf}
}

@InProceedings{Magnusson2006,
  Title                    = {Screen-Based Musical Interfaces as Semiotic Machines},
  Author                   = {Magnusson, Thor},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {162--167},

  Abstract                 = {The ixi software project started in 2000 with the intention to explore new interactive patterns and virtual interfaces in computer music software. The aim of this paper is not to describe these programs, as they have been described elsewhere [14][15], but rather explicate the theoretical background that underlies the design of these screen-based instruments. After an analysis of the similarities and differences in the design of acoustic and screen-based instruments, the paper describes how the creation of an interface is essentially the creation of a semiotic system that affects and influences the musician and the composer. Finally the terminology of this semiotics is explained as an interaction model. },
  Keywords                 = {Interfaces, interaction design, HCI, semiotics, actors, OSC, mapping, interaction models, creative tools. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_162.pdf}
}

@InProceedings{MakiPatola2006,
  Title                    = {The Augmented Djembe Drum - Sculpting Rhythms},
  Author                   = {Maki-Patola, Teemu and H\"{a}m\"{a}l\"{a}inen, Perttu and Kanerva, Aki},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {364--369},

  Keywords                 = {1,2,2 9,3897,39,425,43,7,8,9},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_364.pdf}
}

@InProceedings{Marshall2006,
  Title                    = {Vibrotactile Feedback in Digital Musical Instruments},
  Author                   = {Marshall, Mark T. and Wanderley, Marcelo M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {226--229},

  Keywords                 = {digital musical instruments,tactile feedback,vibro-tactile},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_226.pdf}
}

@InProceedings{Naef2006,
  Title                    = {A VR Interface for Collaborative {3D} Audio Performance},
  Author                   = {Naef, Martin and Collicott, Daniel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {57--60},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_057.pdf}
}

@InProceedings{Nagashima2006,
  Title                    = {Students' Projects of Interactive Media-installations in SUAC},
  Author                   = {Nagashima, Yoichi},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {330--333},

  Abstract                 = {This is a studio report of researches and projects in SUAC(Shizuoka University of Art and Culture). SUAC was foundedin April 2000, and organized NIME04 as you know. SUAChas "Faculty of Design" and "Department of Art and Science"and all students study interactive systems and media arts.SUAC has organized Media Art Festival (MAF) from 2001 to2005. Domestic/overseas artists participated in SUAC MAF,and SUAC students' projects also joined and exhibited theirworks in MAF. I will introduce the production cases withinteractive media-installations by SUAC students' projectsfrom the aspect "experiences with novel interfaces ineducation and entertainment" and "reports on students projectsin the framework of NIME related courses".},
  Keywords                 = {Interactive Installation, Sensors, Media Arts, Studio Reports },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_330.pdf}
}

@InProceedings{Nishibori2006,
  Title                    = {TENORI-ON},
  Author                   = {Nishibori, Yu and Iwai, Toshio},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {172--175},

  Abstract                 = {Development of a musical interface which allows people to play music intuitively and create music visibly. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_172.pdf}
}

@InProceedings{Nixdorf2006,
  Title                    = {Real-time Sound Source Spatialization as Used in Challenging Bodies: Implementation and Performance},
  Author                   = {Nixdorf, Joshua J. and Gerhard, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {318--321},

  Abstract                 = {In this paper we will report on the use of real-time soundspatialization in Challenging Bodies, a trans-disciplinaryperformance project at the University of Regina. Usingwell-understood spatialization techniques mapped to a custom interface, a computer system was built that allowedlive spatial control of ten sound signals from on-stage performers. This spatial control added a unique dynamic element to an already ultramodern performance. The systemis described in detail, including the main advantages overexisting spatialization systems: simplicity, usability, customization and scalability},
  Keywords                 = {gem,live systems,pd,performance sys-,real-time systems,sound architecture,sound localization,sound spatialization,surround sound,tems},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_318.pdf}
}

@InProceedings{Pak2006,
  Title                    = {The Light Matrix: An Interface for Musical Expression and Performance},
  Author                   = {Pak, Jonathan},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {342--345},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_342.pdf}
}

@InProceedings{Poepel2006,
  Title                    = {Recent Developments in Violin-related Digital Musical Instruments: Where Are We and Where Are We Going?},
  Author                   = {Poepel, Cornelius and Overholt, Dan},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {390--395},

  Abstract                 = {In this paper, some of the more recent developments in musical instruments related to the violin family are described, and analyzed according to several criteria adapted from other publications. While it is impossible to cover all such developments, we have tried to sample a variety of instruments from the last decade or so, with a greater focus on those published in the computer music literature. Experiences in the field of string players focusing on such developments are presented. Conclusions are drawn in which further research into violin-related digital instruments for string players may benefit from the presented criteria as well as the experiences. },
  Keywords                 = {Violin, viola, cello, bass, digital, electronic, synthesis, controller. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_390.pdf}
}

@InProceedings{Pritchard2006,
  Title                    = {GRASSP: Gesturally-Realized Audio, Speech and Song Performance},
  Author                   = {Pritchard, Bob and Fels, Sidney S.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {272--276},

  Abstract                 = {We describe the implementation of an environment for Gesturally-Realized Audio, Speech and Song Performance (GRASSP), which includes a glove-based interface, a mapping/training interface, and a collection of Max/MSP/Jitter bpatchers that allow the user to improvise speech, song, sound synthesis, sound processing, sound localization, and video processing. The mapping/training interface provides a framework for performers to specify by example the mapping between gesture and sound or video controls. We demonstrate the effectiveness of the GRASSP environment for gestural control of musical expression by creating a gesture-to-voice system that is currently being used by performers. },
  Keywords                 = {Speech synthesis, parallel formant speech synthesizer, gesture control, Max/MSP, Jitter, Cyberglove, Polhemus, sound diffusion, UBC Toolbox, Glove-Talk, },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_272.pdf}
}

@InProceedings{Remus2006,
  Title                    = {Non Haptic Control of Music by Video Analysis of Hand Movements: 14 Years of Experience with the `Cam\'{e}ra Musicale'},
  Author                   = {R\'{e}mus, Jacques},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {250--253},

  Keywords                 = {camera musicale,interface,jacques r\'{e}mus,machines,musical camera,musical hand,non haptic instrument,s mappings,sculptures and mechanical musical,sound},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_250.pdf}
}

@InProceedings{Ramakrishnan2006,
  Title                    = {The ZKM Klangdom},
  Author                   = {Ramakrishnan, Chandrasekhar and Go\ss man, Joachim and Br\"{u}mmer, Ludger},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {140--143},

  Keywords                 = {Sound Spatialization, Ambisonics, Vector Based Additive Panning (VBAP), Wave Field Synthesis, Acousmatic Music },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_140.pdf}
}

@InProceedings{Rebelo2006,
  Title                    = {The Frequencyliator -- Distributing Structures for Networked Laptop Improvisation},
  Author                   = {Rebelo, Pedro and Renaud, Alain B.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {53--56},

  Abstract                 = {The culture of laptop improvisation has grown tremendously in recent years. The development of personalized software instruments presents interesting issues in the context of improvised group performances. This paper examines an approach that is aimed at increasing the modes of interactivity between laptop performers and at the same time suggests ways in which audiences can better discern and identify the sonic characteristics of each laptop performer. We refer to software implementation that was developed for the BLISS networked laptop ensemble with view to designing a shared format for the exchange of messages within local and internet based networks. },
  Keywords                 = {Networked audio technologies, laptop ensemble, centralized audio server, improvisation },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_053.pdf}
}

@InProceedings{Richards2006,
  Title                    = {32kg: Performance Systems for a Post-Digital Age},
  Author                   = {Richards, John},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {283--287},

  Abstract                 = {Why is a seemingly mundane issue such as airline baggageallowance of great significance in regards to the performancepractice of electronic music? This paper discusses how aperformance practice has evolved that seeks to question thebinary and corporate digital world. New 'instruments' andapproaches have emerged that explore 'dirty electronics' and'punktronics': DIY electronic instruments made from junk.These instruments are not instruments in the traditionalsense, defined by physical dimensions or by a set number ofparameters, but modular systems, constantly evolving, nevercomplete, infinitely variable and designed to be portable. Acombination of lo- and hi-fi, analogue and digital,synchronous and asynchronous devices offer new modes ofexpression. The development of these new interfaces formusical expression run side-by-side with an emerging postdigital aesthetic.},
  Keywords                 = {bastardisation,dirty electronics,diy,ebay,live,modular,performance,portability,post-digital,punktronics},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_283.pdf}
}

@InProceedings{Rohs2006,
  Title                    = {CaMus: Live Music Performance using Camera Phones and Visual Grid Tracking},
  Author                   = {Rohs, Michael and Essl, Georg and Roth, Martin},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {31--36},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_031.pdf}
}

@InProceedings{Schiemer2006,
  Title                    = {Pocket Gamelan: Tuneable Trajectories for Flying Sources in Mandala 3 and Mandala 4},
  Author                   = {Schiemer, Greg and Havryliv, Mark},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {37--42},

  Abstract                 = {This paper describes two new live performance scenarios for performing music using bluetooth-enabled mobile phones. Interaction between mobile phones via wireless link is a key feature of the performance interface for each scenario. Both scenarios are discussed in the context of two publicly performed works for an ensemble of players in which mobile phone handsets are used both as sound sources and as hand-held controllers. In both works mobile phones are mounted in a specially devised pouch attached to a cord and physically swung to produce audio chorusing. During performance some players swing phones while others operate phones as hand-held controllers. Wireless connectivity enables interaction between flying and hand-held phones. Each work features different bluetooth implementations. In one a dedicated mobile phone acts as a server that interconnects multiple clients, while in the other point to point communication takes place between clients on an ad hoc basis. The paper summarises bluetooth tools designed for live performance realisation and concludes with a comparative evaluation of both scenarios for future implementation of performance by large ensembles of nonexpert players performing microtonal music using ubiquitous technology. },
  Keywords                 = {Java 2 Micro Edition; j2me; Pure Data; PD; Real-Time Media Performance; Just Intonation. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_037.pdf}
}

@InProceedings{Schiesser2006,
  Title                    = {On Making and Playing an Electronically-augmented Saxophone},
  Author                   = {Schiesser, S\'{e}bastien and Traube, Caroline},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {308--313},

  Keywords                 = {saxophone, augmented instrument, live electronics, perfor- mance, gestural control },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_308.pdf}
}

@InProceedings{Schoonderwaldt2006,
  Title                    = {Combining Accelerometer and Video Camera: Reconstruction of Bow Velocity Profiles},
  Author                   = {Schoonderwaldt, Erwin and Rasamimanana, Nicolas and Bevilacqua, Fr\'{e}d\'{e}ric},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {200--203},

  Abstract                 = {A cost-effective method was developed for the estimation of the bow velocity in violin playing, using an accelerometer on the bow in combination with point tracking using a standard video camera. The video data are used to detect the moments of bow direction changes. This information is used for piece-wise integration of the accelerometer signal, resulting in a drift-free reconstructed velocity signal with a high temporal resolution. The method was evaluated using a 3D motion capturing system, providing a reliable reference of the actual bow velocity. The method showed good results when the accelerometer and video stream are synchronized. Additional latency and jitter of the camera stream can importantly decrease the performance of the method, depending on the bow stroke type. },
  Keywords                 = {Bowing gestures, bowed string, violin, bow velocity, accelerometer, video tracking. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_200.pdf}
}

@InProceedings{Serafin2006,
  Title                    = {Synthesis and Control of Everyday Sounds Reconstructing Russolo's Intonarumori},
  Author                   = {Serafin, Stefania and de G\"{o}tzen, Amalia and B\"{o}ttcher, Niels and Gelineck, Steven},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {240--245},

  Abstract                 = {In this paper we introduce the Croaker, a novel input deviceinspired by Russolo's Intonarumori. We describe the components of the controller and the sound synthesis engine whichallows to reproduce several everyday sounds.},
  Keywords                 = {Noise machines, everyday sounds, physical models. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_240.pdf}
}

@InProceedings{Smyth2006,
  Title                    = {Handheld Acoustic Filter Bank for Musical Control},
  Author                   = {Smyth, Tamara},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {314--317},

  Keywords                 = {khaen, sound synthesis control, mapping, musical acoustics },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_314.pdf}
}

@InProceedings{Steiner2006,
  Title                    = {Towards a Catalog and Software Library of Mapping Methods},
  Author                   = {Steiner, Hans-Christoph},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {106--109},

  Url                      = {http://www.nime.org/proceedings/2006/nime2006_106.pdf}
}

@InProceedings{Stewart2006,
  Title                    = {SonicJumper Composer},
  Author                   = {Stewart, D. Andrew},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {103--105},

  Keywords                 = {composition, process, materials, gesture, controller, cross- modal interaction },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_103.pdf}
}

@InProceedings{Tanaka2006,
  Title                    = {A Framework for Spatial Interaction in Locative Media},
  Author                   = {Tanaka, Atau and Gemeinboeck, Petra},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {26--30},

  Abstract                 = {This paper presents the concepts and techniques used in afamily of location based multimedia works. The paper hasthree main sections: 1.) to describe the architecture of anaudio-visual hardware/software framework we havedeveloped for the realization of a series of locative mediaartworks, 2.) to discuss the theoretical and conceptualunderpinnings motivating the design of the technicalframework, and 3.) to elicit from this, fundamental issuesand questions that can be generalized and applicable to thegrowing practice of locative media.},
  Keywords                 = {Mobile music, urban fiction, locative media. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_026.pdf}
}

@InProceedings{Wanderley2006,
  Title                    = {SensorWiki.org: A Collaborative Resource for Researchers and Interface Designers},
  Author                   = {Wanderley, Marcelo M. and Birnbaum, David and Malloch, Joseph and Sinyor, Elliot and Boissinot, Julien},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {180--183},

  Keywords                 = {sensors, Wiki, collaborative website, open content },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_180.pdf}
}

@InProceedings{Wang2006,
  Title                    = {Building Collaborative Graphical interFaces in the Audicle},
  Author                   = {Wang, Ge and Misra, Ananya and Cook, Perry R.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {49--52},

  Keywords                 = {Graphical interfaces, collaborative performance, networking, computer music ensemble, emergence, visualization, education. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_049.pdf}
}

@InProceedings{Weinberg2006,
  Title                    = {Interactive Sonification of Neural Activity},
  Author                   = {Weinberg, Gil and Thatcher, Travis},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {246--249},

  Keywords                 = {1,background and motivations,biological research,interactive auditory display,neural patterns,scholars are,sonification,with new developments in},
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_246.pdf}
}

@InProceedings{Wozniewski2006,
  Title                    = {A Framework for Immersive Spatial Audio Performance},
  Author                   = {Wozniewski, Mike and Settel, Zack and Cooperstock, Jeremy R.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {144--149},

  Abstract                 = {Traditional uses of virtual audio environments tend to focus onperceptually accurate acoustic representations. Though spatialization of sound sources is important, it is necessary to leveragecontrol of the sonic representation when considering musical applications. The proposed framework allows for the creation ofperceptually immersive scenes that function as musical instruments. Loudspeakers and microphones are modeled within thescene along with the listener/performer, creating a navigable 3Dsonic space where sound sources and sinks process audio according to user-defined spatial mappings.},
  Keywords                 = {Control paradigms, 3D audio, spatialization, immersive audio environments, auditory display, acoustic modeling, spatial inter- faces, virtual instrument design },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_144.pdf}
}

@InProceedings{Young2006,
  Title                    = {Composing for Hyperbow: A Collaboration Between {MIT} and the Royal Academy of Music},
  Author                   = {Young, Diana and Nunn, Patrick and Vassiliev, Artem},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {396--401},

  Abstract                 = {In this paper we present progress of an ongoingcollaboration between researchers at the MIT MediaLaboratory and the Royal Academy of Music (RAM). The aimof this project is to further explore the expressive musicalpotential of the Hyperbow, a custom music controller firstdesigned for use in violin performance. Through the creationof new repertoire, we hope to stimulate the evolution of thisinterface, advancing its usability and refining itscapabilities. In preparation for this work, the Hyperbowsystem has been adapted for cello (acoustic and electric)performance. The structure of our collaboration is described,and two of the pieces currently in progress are presented.Feedback from the performers is also discussed, as well asfuture plans.},
  Keywords                 = {Cello, bow, controller, electroacoustic music, composition. },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_396.pdf}
}

@InProceedings{Zadel2006,
  Title                    = {Different Strokes: a Prototype Software System for Laptop Performance and Improvisation},
  Author                   = {Zadel, Mark and Scavone, Gary},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2006},

  Address                  = {Paris, France},
  Pages                    = {168--171},

  Keywords                 = {Software control of computer music, laptop performance, graphical interfaces, freehand input, dynamic simulation },
  Url                      = {http://www.nime.org/proceedings/2006/nime2006_168.pdf}
}

